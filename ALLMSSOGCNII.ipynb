{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25e4c6e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T11:55:12.500686Z",
     "iopub.status.busy": "2024-04-21T11:55:12.500315Z",
     "iopub.status.idle": "2024-04-21T11:55:14.344637Z",
     "shell.execute_reply": "2024-04-21T11:55:14.343508Z"
    },
    "papermill": {
     "duration": 1.853911,
     "end_time": "2024-04-21T11:55:14.347090",
     "exception": false,
     "start_time": "2024-04-21T11:55:12.493179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'GCNII'...\r\n",
      "remote: Enumerating objects: 242, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (109/109), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (58/58), done.\u001b[K\r\n",
      "remote: Total 242 (delta 67), reused 80 (delta 50), pack-reused 133\u001b[K\r\n",
      "Receiving objects: 100% (242/242), 5.53 MiB | 25.60 MiB/s, done.\r\n",
      "Resolving deltas: 100% (91/91), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jack0713323/GCNII.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5047dec5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T11:55:14.360816Z",
     "iopub.status.busy": "2024-04-21T11:55:14.360497Z",
     "iopub.status.idle": "2024-04-21T11:55:14.366811Z",
     "shell.execute_reply": "2024-04-21T11:55:14.365927Z"
    },
    "papermill": {
     "duration": 0.015327,
     "end_time": "2024-04-21T11:55:14.368781",
     "exception": false,
     "start_time": "2024-04-21T11:55:14.353454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/GCNII\n"
     ]
    }
   ],
   "source": [
    "%cd GCNII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc265967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T11:55:14.381831Z",
     "iopub.status.busy": "2024-04-21T11:55:14.381588Z",
     "iopub.status.idle": "2024-04-21T11:55:15.325847Z",
     "shell.execute_reply": "2024-04-21T11:55:15.324937Z"
    },
    "papermill": {
     "duration": 0.953227,
     "end_time": "2024-04-21T11:55:15.328066",
     "exception": false,
     "start_time": "2024-04-21T11:55:14.374839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111034507linzijie.txt\tfull-supervisedtest10.py  pretrained  train3.py\r\n",
      "PyG\t\t\tfull.sh\t\t\t  process.py  trainTEST.py\r\n",
      "README.md\t\tmodel.py\t\t  semi.sh     trainshow.py\r\n",
      "cora25.ipynb\t\tmodelnew.py\t\t  splits      utils.py\r\n",
      "data\t\t\tnew_data\t\t  train.py\r\n",
      "full-supervised.py\tppi.py\t\t\t  train1.py\r\n",
      "full-supervisedtest.py\tppi.sh\t\t\t  train2.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e921cf45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T11:55:15.342358Z",
     "iopub.status.busy": "2024-04-21T11:55:15.342065Z",
     "iopub.status.idle": "2024-04-21T11:55:15.346374Z",
     "shell.execute_reply": "2024-04-21T11:55:15.345555Z"
    },
    "papermill": {
     "duration": 0.013675,
     "end_time": "2024-04-21T11:55:15.348277",
     "exception": false,
     "start_time": "2024-04-21T11:55:15.334602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "repeat=1\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc31217",
   "metadata": {
    "papermill": {
     "duration": 0.005881,
     "end_time": "2024-04-21T11:55:15.360340",
     "exception": false,
     "start_time": "2024-04-21T11:55:15.354459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "for cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ba360f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T11:55:15.373416Z",
     "iopub.status.busy": "2024-04-21T11:55:15.373169Z",
     "iopub.status.idle": "2024-04-21T11:55:15.377635Z",
     "shell.execute_reply": "2024-04-21T11:55:15.376808Z"
    },
    "papermill": {
     "duration": 0.013324,
     "end_time": "2024-04-21T11:55:15.379658",
     "exception": false,
     "start_time": "2024-04-21T11:55:15.366334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a=(34, 0, 0, 0, 56, 949, 9, 0, 0.3489076699438276, 0.661000220102601, 0.49805857303652107, 0.0070093416540903675, 0.0450432794537762, 0.0003689346079284098)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a7e6f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T11:55:15.392875Z",
     "iopub.status.busy": "2024-04-21T11:55:15.392638Z",
     "iopub.status.idle": "2024-04-21T11:55:15.398409Z",
     "shell.execute_reply": "2024-04-21T11:55:15.397584Z"
    },
    "papermill": {
     "duration": 0.014473,
     "end_time": "2024-04-21T11:55:15.400277",
     "exception": false,
     "start_time": "2024-04-21T11:55:15.385804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_num_layers = int(a[0])\n",
    "best_optim = int(a[1])\n",
    "best_al = int(a[2])\n",
    "best_act = int(a[3])\n",
    "best_earlystop = int(a[4])\n",
    "best_epoch1 = int(a[5])\n",
    "best_hidden_dim = int(a[6])\n",
    "best_variant = a[7]\n",
    "\n",
    "best_alpha = a[8]\n",
    "best_lamda = a[9]\n",
    "best_dropout = a[10]\n",
    "best_lr = a[11]\n",
    "best_weight_decay_1 = a[12]\n",
    "best_weight_decay_2 = a[13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c915ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T11:55:15.413267Z",
     "iopub.status.busy": "2024-04-21T11:55:15.413007Z",
     "iopub.status.idle": "2024-04-21T11:55:15.419720Z",
     "shell.execute_reply": "2024-04-21T11:55:15.418677Z"
    },
    "papermill": {
     "duration": 0.015499,
     "end_time": "2024-04-21T11:55:15.421754",
     "exception": false,
     "start_time": "2024-04-21T11:55:15.406255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_num_layers: 34\n",
      "best_optim: 0\n",
      "best_al: 0\n",
      "best_act: 0\n",
      "best_earlystop: 56\n",
      "best_epoch1: 949\n",
      "best_hidden_dim: 9\n",
      "best_variant: 0\n",
      "---------\n",
      "best_alpha: 0.3489076699438276\n",
      "best_lamda: 0.661000220102601\n",
      "best_dropout: 0.49805857303652107\n",
      "best_lr: 0.0070093416540903675\n",
      "best_weight_decay_1: 0.0450432794537762\n",
      "best_weight_decay_2: 0.0003689346079284098\n"
     ]
    }
   ],
   "source": [
    "print(f\"best_num_layers: {best_num_layers}\")\n",
    "print(f\"best_optim: {best_optim}\")\n",
    "print(f\"best_al: {best_al}\")\n",
    "print(f\"best_act: {best_act}\")\n",
    "print(f\"best_earlystop: {best_earlystop}\")\n",
    "print(f\"best_epoch1: {best_epoch1}\")\n",
    "print(f\"best_hidden_dim: {best_hidden_dim}\")\n",
    "print(f\"best_variant: {best_variant}\")\n",
    "print(\"---------\")\n",
    "print(f\"best_alpha: {best_alpha}\")\n",
    "print(f\"best_lamda: {best_lamda}\")\n",
    "print(f\"best_dropout: {best_dropout}\")\n",
    "print(f\"best_lr: {best_lr}\")\n",
    "print(f\"best_weight_decay_1: {best_weight_decay_1}\")\n",
    "print(f\"best_weight_decay_2: {best_weight_decay_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "622886ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T11:55:15.435078Z",
     "iopub.status.busy": "2024-04-21T11:55:15.434795Z",
     "iopub.status.idle": "2024-04-21T11:56:21.268462Z",
     "shell.execute_reply": "2024-04-21T11:56:21.267357Z"
    },
    "papermill": {
     "duration": 65.843001,
     "end_time": "2024-04-21T11:56:21.270944",
     "exception": false,
     "start_time": "2024-04-21T11:55:15.427943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0000 train loss:1.964 acc:13.57 | val loss:1.979 acc:11.40\r\n",
      "Epoch:0001 train loss:1.963 acc:15.00 | val loss:1.976 acc:11.40\r\n",
      "Epoch:0002 train loss:1.962 acc:18.57 | val loss:1.972 acc:16.60\r\n",
      "Epoch:0003 train loss:1.955 acc:17.14 | val loss:1.968 acc:25.40\r\n",
      "Epoch:0004 train loss:1.956 acc:15.00 | val loss:1.965 acc:26.00\r\n",
      "Epoch:0005 train loss:1.950 acc:18.57 | val loss:1.962 acc:25.80\r\n",
      "Epoch:0006 train loss:1.952 acc:17.86 | val loss:1.959 acc:25.80\r\n",
      "Epoch:0007 train loss:1.950 acc:16.43 | val loss:1.956 acc:26.40\r\n",
      "Epoch:0008 train loss:1.950 acc:18.57 | val loss:1.953 acc:25.40\r\n",
      "Epoch:0009 train loss:1.945 acc:22.14 | val loss:1.950 acc:24.80\r\n",
      "Epoch:0010 train loss:1.948 acc:17.86 | val loss:1.948 acc:24.00\r\n",
      "Epoch:0011 train loss:1.939 acc:18.57 | val loss:1.945 acc:23.60\r\n",
      "Epoch:0012 train loss:1.938 acc:17.14 | val loss:1.943 acc:23.60\r\n",
      "Epoch:0013 train loss:1.935 acc:20.71 | val loss:1.941 acc:23.60\r\n",
      "Epoch:0014 train loss:1.937 acc:17.86 | val loss:1.939 acc:23.60\r\n",
      "Epoch:0015 train loss:1.927 acc:22.14 | val loss:1.938 acc:23.60\r\n",
      "Epoch:0016 train loss:1.935 acc:18.57 | val loss:1.936 acc:24.20\r\n",
      "Epoch:0017 train loss:1.936 acc:18.57 | val loss:1.934 acc:24.00\r\n",
      "Epoch:0018 train loss:1.934 acc:26.43 | val loss:1.932 acc:24.00\r\n",
      "Epoch:0019 train loss:1.928 acc:21.43 | val loss:1.930 acc:24.00\r\n",
      "Epoch:0020 train loss:1.930 acc:17.14 | val loss:1.929 acc:24.00\r\n",
      "Epoch:0021 train loss:1.918 acc:25.71 | val loss:1.928 acc:24.60\r\n",
      "Epoch:0022 train loss:1.925 acc:19.29 | val loss:1.927 acc:25.20\r\n",
      "Epoch:0023 train loss:1.920 acc:22.14 | val loss:1.926 acc:26.20\r\n",
      "Epoch:0024 train loss:1.910 acc:29.29 | val loss:1.925 acc:28.20\r\n",
      "Epoch:0025 train loss:1.923 acc:30.00 | val loss:1.924 acc:29.60\r\n",
      "Epoch:0026 train loss:1.922 acc:22.86 | val loss:1.923 acc:31.60\r\n",
      "Epoch:0027 train loss:1.924 acc:22.14 | val loss:1.922 acc:34.40\r\n",
      "Epoch:0028 train loss:1.904 acc:28.57 | val loss:1.921 acc:37.80\r\n",
      "Epoch:0029 train loss:1.908 acc:27.14 | val loss:1.920 acc:38.80\r\n",
      "Epoch:0030 train loss:1.909 acc:31.43 | val loss:1.919 acc:38.20\r\n",
      "Epoch:0031 train loss:1.906 acc:30.00 | val loss:1.918 acc:35.20\r\n",
      "Epoch:0032 train loss:1.911 acc:27.86 | val loss:1.917 acc:33.20\r\n",
      "Epoch:0033 train loss:1.902 acc:31.43 | val loss:1.916 acc:30.80\r\n",
      "Epoch:0034 train loss:1.902 acc:21.43 | val loss:1.915 acc:29.40\r\n",
      "Epoch:0035 train loss:1.906 acc:30.00 | val loss:1.913 acc:31.60\r\n",
      "Epoch:0036 train loss:1.876 acc:34.29 | val loss:1.912 acc:31.20\r\n",
      "Epoch:0037 train loss:1.887 acc:33.57 | val loss:1.910 acc:32.80\r\n",
      "Epoch:0038 train loss:1.889 acc:30.00 | val loss:1.908 acc:35.40\r\n",
      "Epoch:0039 train loss:1.892 acc:30.71 | val loss:1.906 acc:36.80\r\n",
      "Epoch:0040 train loss:1.864 acc:32.86 | val loss:1.904 acc:38.00\r\n",
      "Epoch:0041 train loss:1.883 acc:23.57 | val loss:1.903 acc:39.00\r\n",
      "Epoch:0042 train loss:1.872 acc:32.14 | val loss:1.902 acc:40.20\r\n",
      "Epoch:0043 train loss:1.874 acc:35.00 | val loss:1.900 acc:44.40\r\n",
      "Epoch:0044 train loss:1.875 acc:32.86 | val loss:1.898 acc:46.20\r\n",
      "Epoch:0045 train loss:1.867 acc:33.57 | val loss:1.896 acc:49.40\r\n",
      "Epoch:0046 train loss:1.875 acc:30.00 | val loss:1.894 acc:53.40\r\n",
      "Epoch:0047 train loss:1.886 acc:27.86 | val loss:1.892 acc:57.60\r\n",
      "Epoch:0048 train loss:1.864 acc:25.71 | val loss:1.890 acc:62.00\r\n",
      "Epoch:0049 train loss:1.861 acc:32.14 | val loss:1.887 acc:66.00\r\n",
      "Epoch:0050 train loss:1.859 acc:35.00 | val loss:1.884 acc:69.00\r\n",
      "Epoch:0051 train loss:1.841 acc:34.29 | val loss:1.882 acc:71.20\r\n",
      "Epoch:0052 train loss:1.866 acc:34.29 | val loss:1.879 acc:72.60\r\n",
      "Epoch:0053 train loss:1.855 acc:39.29 | val loss:1.877 acc:73.00\r\n",
      "Epoch:0054 train loss:1.832 acc:32.86 | val loss:1.874 acc:73.40\r\n",
      "Epoch:0055 train loss:1.841 acc:36.43 | val loss:1.872 acc:73.80\r\n",
      "Epoch:0056 train loss:1.840 acc:26.43 | val loss:1.869 acc:73.00\r\n",
      "Epoch:0057 train loss:1.838 acc:35.71 | val loss:1.867 acc:72.20\r\n",
      "Epoch:0058 train loss:1.863 acc:29.29 | val loss:1.865 acc:71.60\r\n",
      "Epoch:0059 train loss:1.839 acc:32.14 | val loss:1.863 acc:71.00\r\n",
      "Epoch:0060 train loss:1.822 acc:34.29 | val loss:1.861 acc:70.20\r\n",
      "Epoch:0061 train loss:1.807 acc:34.29 | val loss:1.859 acc:69.60\r\n",
      "Epoch:0062 train loss:1.811 acc:30.71 | val loss:1.857 acc:70.00\r\n",
      "Epoch:0063 train loss:1.809 acc:40.00 | val loss:1.854 acc:70.60\r\n",
      "Epoch:0064 train loss:1.811 acc:37.86 | val loss:1.851 acc:71.60\r\n",
      "Epoch:0065 train loss:1.801 acc:34.29 | val loss:1.848 acc:72.00\r\n",
      "Epoch:0066 train loss:1.796 acc:39.29 | val loss:1.844 acc:72.60\r\n",
      "Epoch:0067 train loss:1.824 acc:25.71 | val loss:1.841 acc:74.00\r\n",
      "Epoch:0068 train loss:1.784 acc:42.14 | val loss:1.837 acc:74.80\r\n",
      "Epoch:0069 train loss:1.804 acc:37.14 | val loss:1.833 acc:74.40\r\n",
      "Epoch:0070 train loss:1.777 acc:40.00 | val loss:1.830 acc:75.40\r\n",
      "Epoch:0071 train loss:1.789 acc:42.86 | val loss:1.827 acc:75.20\r\n",
      "Epoch:0072 train loss:1.761 acc:41.43 | val loss:1.823 acc:75.80\r\n",
      "Epoch:0073 train loss:1.800 acc:31.43 | val loss:1.820 acc:76.00\r\n",
      "Epoch:0074 train loss:1.840 acc:27.14 | val loss:1.817 acc:76.40\r\n",
      "Epoch:0075 train loss:1.801 acc:33.57 | val loss:1.815 acc:76.00\r\n",
      "Epoch:0076 train loss:1.830 acc:27.14 | val loss:1.812 acc:76.00\r\n",
      "Epoch:0077 train loss:1.781 acc:35.00 | val loss:1.808 acc:75.40\r\n",
      "Epoch:0078 train loss:1.746 acc:39.29 | val loss:1.805 acc:75.40\r\n",
      "Epoch:0079 train loss:1.775 acc:35.00 | val loss:1.802 acc:75.80\r\n",
      "Epoch:0080 train loss:1.793 acc:32.86 | val loss:1.800 acc:76.20\r\n",
      "Epoch:0081 train loss:1.792 acc:38.57 | val loss:1.798 acc:75.60\r\n",
      "Epoch:0082 train loss:1.789 acc:36.43 | val loss:1.797 acc:76.00\r\n",
      "Epoch:0083 train loss:1.712 acc:47.14 | val loss:1.795 acc:76.60\r\n",
      "Epoch:0084 train loss:1.800 acc:25.71 | val loss:1.794 acc:76.20\r\n",
      "Epoch:0085 train loss:1.709 acc:41.43 | val loss:1.793 acc:76.00\r\n",
      "Epoch:0086 train loss:1.735 acc:37.14 | val loss:1.791 acc:75.00\r\n",
      "Epoch:0087 train loss:1.735 acc:40.71 | val loss:1.790 acc:75.00\r\n",
      "Epoch:0088 train loss:1.771 acc:27.14 | val loss:1.788 acc:74.80\r\n",
      "Epoch:0089 train loss:1.741 acc:37.86 | val loss:1.787 acc:75.20\r\n",
      "Epoch:0090 train loss:1.720 acc:46.43 | val loss:1.785 acc:75.60\r\n",
      "Epoch:0091 train loss:1.739 acc:34.29 | val loss:1.782 acc:74.00\r\n",
      "Epoch:0092 train loss:1.779 acc:31.43 | val loss:1.780 acc:73.60\r\n",
      "Epoch:0093 train loss:1.738 acc:42.14 | val loss:1.777 acc:73.60\r\n",
      "Epoch:0094 train loss:1.722 acc:37.86 | val loss:1.775 acc:73.60\r\n",
      "Epoch:0095 train loss:1.772 acc:37.14 | val loss:1.773 acc:73.40\r\n",
      "Epoch:0096 train loss:1.697 acc:41.43 | val loss:1.771 acc:73.80\r\n",
      "Epoch:0097 train loss:1.721 acc:39.29 | val loss:1.768 acc:74.20\r\n",
      "Epoch:0098 train loss:1.697 acc:40.00 | val loss:1.764 acc:76.40\r\n",
      "Epoch:0099 train loss:1.693 acc:36.43 | val loss:1.759 acc:77.00\r\n",
      "Epoch:0100 train loss:1.663 acc:42.86 | val loss:1.755 acc:77.40\r\n",
      "Epoch:0101 train loss:1.692 acc:37.14 | val loss:1.750 acc:78.00\r\n",
      "Epoch:0102 train loss:1.684 acc:35.71 | val loss:1.746 acc:77.80\r\n",
      "Epoch:0103 train loss:1.719 acc:38.57 | val loss:1.742 acc:77.20\r\n",
      "Epoch:0104 train loss:1.716 acc:39.29 | val loss:1.738 acc:77.00\r\n",
      "Epoch:0105 train loss:1.670 acc:39.29 | val loss:1.735 acc:77.00\r\n",
      "Epoch:0106 train loss:1.675 acc:43.57 | val loss:1.732 acc:76.60\r\n",
      "Epoch:0107 train loss:1.680 acc:42.86 | val loss:1.730 acc:76.40\r\n",
      "Epoch:0108 train loss:1.726 acc:39.29 | val loss:1.728 acc:76.40\r\n",
      "Epoch:0109 train loss:1.714 acc:42.14 | val loss:1.725 acc:76.40\r\n",
      "Epoch:0110 train loss:1.742 acc:32.86 | val loss:1.722 acc:76.80\r\n",
      "Epoch:0111 train loss:1.693 acc:36.43 | val loss:1.719 acc:77.80\r\n",
      "Epoch:0112 train loss:1.714 acc:38.57 | val loss:1.715 acc:78.60\r\n",
      "Epoch:0113 train loss:1.641 acc:44.29 | val loss:1.713 acc:78.40\r\n",
      "Epoch:0114 train loss:1.747 acc:39.29 | val loss:1.711 acc:78.40\r\n",
      "Epoch:0115 train loss:1.724 acc:37.86 | val loss:1.709 acc:78.00\r\n",
      "Epoch:0116 train loss:1.684 acc:40.00 | val loss:1.708 acc:77.60\r\n",
      "Epoch:0117 train loss:1.654 acc:44.29 | val loss:1.706 acc:76.80\r\n",
      "Epoch:0118 train loss:1.671 acc:40.00 | val loss:1.704 acc:77.20\r\n",
      "Epoch:0119 train loss:1.641 acc:45.71 | val loss:1.703 acc:77.20\r\n",
      "Epoch:0120 train loss:1.637 acc:37.86 | val loss:1.701 acc:77.60\r\n",
      "Epoch:0121 train loss:1.604 acc:42.86 | val loss:1.699 acc:78.40\r\n",
      "Epoch:0122 train loss:1.668 acc:35.71 | val loss:1.698 acc:78.20\r\n",
      "Epoch:0123 train loss:1.629 acc:42.86 | val loss:1.696 acc:78.40\r\n",
      "Epoch:0124 train loss:1.636 acc:49.29 | val loss:1.694 acc:78.80\r\n",
      "Epoch:0125 train loss:3.733 acc:43.57 | val loss:1.690 acc:78.00\r\n",
      "Epoch:0126 train loss:1.684 acc:37.14 | val loss:1.686 acc:78.00\r\n",
      "Epoch:0127 train loss:1.581 acc:44.29 | val loss:1.681 acc:77.80\r\n",
      "Epoch:0128 train loss:1.651 acc:36.43 | val loss:1.677 acc:77.60\r\n",
      "Epoch:0129 train loss:1.588 acc:45.71 | val loss:1.672 acc:77.40\r\n",
      "Epoch:0130 train loss:1.633 acc:42.14 | val loss:1.668 acc:77.40\r\n",
      "Epoch:0131 train loss:1.589 acc:47.86 | val loss:1.663 acc:77.80\r\n",
      "Epoch:0132 train loss:1.653 acc:37.86 | val loss:1.660 acc:78.00\r\n",
      "Epoch:0133 train loss:1.628 acc:46.43 | val loss:1.656 acc:77.80\r\n",
      "Epoch:0134 train loss:1.607 acc:45.71 | val loss:1.653 acc:77.80\r\n",
      "Epoch:0135 train loss:1.632 acc:42.86 | val loss:1.649 acc:78.00\r\n",
      "Epoch:0136 train loss:1.570 acc:42.86 | val loss:1.645 acc:78.60\r\n",
      "Epoch:0137 train loss:1.609 acc:41.43 | val loss:1.642 acc:78.20\r\n",
      "Epoch:0138 train loss:1.608 acc:41.43 | val loss:1.639 acc:78.60\r\n",
      "Epoch:0139 train loss:1.600 acc:41.43 | val loss:1.638 acc:79.00\r\n",
      "Epoch:0140 train loss:1.598 acc:41.43 | val loss:1.637 acc:79.80\r\n",
      "Epoch:0141 train loss:1.625 acc:37.86 | val loss:1.636 acc:79.60\r\n",
      "Epoch:0142 train loss:1.585 acc:48.57 | val loss:1.635 acc:79.20\r\n",
      "Epoch:0143 train loss:1.669 acc:35.00 | val loss:1.634 acc:79.20\r\n",
      "Epoch:0144 train loss:1.588 acc:44.29 | val loss:1.632 acc:78.40\r\n",
      "Epoch:0145 train loss:1.587 acc:47.14 | val loss:1.631 acc:78.80\r\n",
      "Epoch:0146 train loss:1.594 acc:45.71 | val loss:1.629 acc:78.00\r\n",
      "Epoch:0147 train loss:1.735 acc:39.29 | val loss:1.628 acc:77.80\r\n",
      "Epoch:0148 train loss:1.576 acc:48.57 | val loss:1.626 acc:77.60\r\n",
      "Epoch:0149 train loss:1.656 acc:40.71 | val loss:1.625 acc:77.40\r\n",
      "Epoch:0150 train loss:1.579 acc:51.43 | val loss:1.624 acc:78.80\r\n",
      "Epoch:0151 train loss:1.565 acc:50.71 | val loss:1.622 acc:79.00\r\n",
      "Epoch:0152 train loss:1.643 acc:35.71 | val loss:1.620 acc:78.80\r\n",
      "Epoch:0153 train loss:1.612 acc:42.86 | val loss:1.619 acc:79.00\r\n",
      "Epoch:0154 train loss:1.480 acc:51.43 | val loss:1.617 acc:79.80\r\n",
      "Epoch:0155 train loss:1.622 acc:40.00 | val loss:1.615 acc:79.00\r\n",
      "Epoch:0156 train loss:1.504 acc:47.14 | val loss:1.613 acc:78.80\r\n",
      "Epoch:0157 train loss:1.599 acc:45.71 | val loss:1.611 acc:78.80\r\n",
      "Epoch:0158 train loss:1.554 acc:45.00 | val loss:1.609 acc:78.60\r\n",
      "Epoch:0159 train loss:1.621 acc:40.00 | val loss:1.607 acc:78.60\r\n",
      "Epoch:0160 train loss:1.509 acc:51.43 | val loss:1.604 acc:78.40\r\n",
      "Epoch:0161 train loss:1.575 acc:46.43 | val loss:1.601 acc:78.00\r\n",
      "Epoch:0162 train loss:1.529 acc:50.71 | val loss:1.598 acc:78.00\r\n",
      "Epoch:0163 train loss:1.541 acc:45.00 | val loss:1.594 acc:77.80\r\n",
      "Epoch:0164 train loss:1.515 acc:49.29 | val loss:1.590 acc:77.60\r\n",
      "Epoch:0165 train loss:1.579 acc:46.43 | val loss:1.587 acc:77.80\r\n",
      "Epoch:0166 train loss:1.547 acc:45.71 | val loss:1.584 acc:78.00\r\n",
      "Epoch:0167 train loss:1.593 acc:48.57 | val loss:1.581 acc:78.00\r\n",
      "Epoch:0168 train loss:1.621 acc:41.43 | val loss:1.579 acc:77.80\r\n",
      "Epoch:0169 train loss:1.592 acc:37.14 | val loss:1.577 acc:77.60\r\n",
      "Epoch:0170 train loss:1.558 acc:42.14 | val loss:1.575 acc:78.00\r\n",
      "Epoch:0171 train loss:1.579 acc:41.43 | val loss:1.573 acc:78.00\r\n",
      "Epoch:0172 train loss:1.543 acc:44.29 | val loss:1.571 acc:77.80\r\n",
      "Epoch:0173 train loss:1.533 acc:50.71 | val loss:1.569 acc:77.80\r\n",
      "Epoch:0174 train loss:1.505 acc:45.71 | val loss:1.567 acc:78.40\r\n",
      "Epoch:0175 train loss:1.519 acc:47.86 | val loss:1.564 acc:79.00\r\n",
      "Epoch:0176 train loss:1.525 acc:45.71 | val loss:1.560 acc:79.00\r\n",
      "Epoch:0177 train loss:1.497 acc:48.57 | val loss:1.557 acc:78.80\r\n",
      "Epoch:0178 train loss:1.515 acc:42.86 | val loss:1.553 acc:78.40\r\n",
      "Epoch:0179 train loss:1.585 acc:37.86 | val loss:1.550 acc:77.80\r\n",
      "Epoch:0180 train loss:1.559 acc:38.57 | val loss:1.549 acc:78.40\r\n",
      "Epoch:0181 train loss:1.484 acc:47.14 | val loss:1.547 acc:79.00\r\n",
      "Epoch:0182 train loss:1.611 acc:37.86 | val loss:1.547 acc:79.40\r\n",
      "Epoch:0183 train loss:1.581 acc:40.00 | val loss:1.548 acc:79.80\r\n",
      "Epoch:0184 train loss:1.540 acc:43.57 | val loss:1.547 acc:79.40\r\n",
      "Epoch:0185 train loss:1.491 acc:44.29 | val loss:1.547 acc:79.20\r\n",
      "Epoch:0186 train loss:1.532 acc:46.43 | val loss:1.546 acc:79.00\r\n",
      "Epoch:0187 train loss:1.442 acc:47.86 | val loss:1.544 acc:79.40\r\n",
      "Epoch:0188 train loss:1.507 acc:46.43 | val loss:1.543 acc:79.20\r\n",
      "Epoch:0189 train loss:1.495 acc:45.00 | val loss:1.541 acc:79.00\r\n",
      "Epoch:0190 train loss:1.539 acc:50.71 | val loss:1.539 acc:79.60\r\n",
      "Epoch:0191 train loss:1.507 acc:45.71 | val loss:1.537 acc:79.80\r\n",
      "Epoch:0192 train loss:1.501 acc:47.14 | val loss:1.536 acc:79.80\r\n",
      "Epoch:0193 train loss:1.534 acc:45.00 | val loss:1.535 acc:80.00\r\n",
      "Epoch:0194 train loss:1.498 acc:45.71 | val loss:1.533 acc:79.80\r\n",
      "Epoch:0195 train loss:1.456 acc:52.86 | val loss:1.531 acc:79.80\r\n",
      "Epoch:0196 train loss:1.534 acc:47.14 | val loss:1.530 acc:80.20\r\n",
      "Epoch:0197 train loss:1.473 acc:47.14 | val loss:1.529 acc:79.80\r\n",
      "Epoch:0198 train loss:1.486 acc:47.86 | val loss:1.526 acc:79.60\r\n",
      "Epoch:0199 train loss:1.473 acc:47.86 | val loss:1.525 acc:79.60\r\n",
      "Epoch:0200 train loss:1.471 acc:48.57 | val loss:1.523 acc:79.40\r\n",
      "Epoch:0201 train loss:1.466 acc:49.29 | val loss:1.520 acc:79.20\r\n",
      "Epoch:0202 train loss:1.569 acc:38.57 | val loss:1.518 acc:79.60\r\n",
      "Epoch:0203 train loss:1.490 acc:44.29 | val loss:1.516 acc:80.00\r\n",
      "Epoch:0204 train loss:1.454 acc:49.29 | val loss:1.512 acc:79.80\r\n",
      "Epoch:0205 train loss:1.508 acc:47.86 | val loss:1.509 acc:79.80\r\n",
      "Epoch:0206 train loss:1.479 acc:47.86 | val loss:1.506 acc:80.00\r\n",
      "Epoch:0207 train loss:1.471 acc:50.71 | val loss:1.504 acc:80.00\r\n",
      "Epoch:0208 train loss:1.471 acc:45.00 | val loss:1.501 acc:80.20\r\n",
      "Epoch:0209 train loss:1.409 acc:52.86 | val loss:1.498 acc:80.20\r\n",
      "Epoch:0210 train loss:1.468 acc:41.43 | val loss:1.496 acc:80.40\r\n",
      "Epoch:0211 train loss:1.537 acc:40.71 | val loss:1.494 acc:80.00\r\n",
      "Epoch:0212 train loss:1.585 acc:37.14 | val loss:1.494 acc:80.40\r\n",
      "Epoch:0213 train loss:1.442 acc:53.57 | val loss:1.494 acc:80.00\r\n",
      "Epoch:0214 train loss:1.524 acc:48.57 | val loss:1.494 acc:79.80\r\n",
      "Epoch:0215 train loss:1.455 acc:52.86 | val loss:1.493 acc:79.40\r\n",
      "Epoch:0216 train loss:1.477 acc:45.71 | val loss:1.492 acc:79.80\r\n",
      "Epoch:0217 train loss:1.462 acc:48.57 | val loss:1.490 acc:80.20\r\n",
      "Epoch:0218 train loss:1.442 acc:44.29 | val loss:1.489 acc:80.00\r\n",
      "Epoch:0219 train loss:1.470 acc:50.71 | val loss:1.487 acc:79.80\r\n",
      "Epoch:0220 train loss:1.507 acc:45.71 | val loss:1.487 acc:79.20\r\n",
      "Epoch:0221 train loss:1.442 acc:48.57 | val loss:1.485 acc:79.00\r\n",
      "Epoch:0222 train loss:1.448 acc:49.29 | val loss:1.483 acc:79.80\r\n",
      "Epoch:0223 train loss:1.455 acc:51.43 | val loss:1.481 acc:79.80\r\n",
      "Epoch:0224 train loss:1.466 acc:49.29 | val loss:1.478 acc:79.60\r\n",
      "Epoch:0225 train loss:1.443 acc:48.57 | val loss:1.475 acc:79.80\r\n",
      "Epoch:0226 train loss:1.437 acc:48.57 | val loss:1.472 acc:80.00\r\n",
      "Epoch:0227 train loss:1.431 acc:50.71 | val loss:1.468 acc:80.20\r\n",
      "Epoch:0228 train loss:1.417 acc:51.43 | val loss:1.465 acc:80.40\r\n",
      "Epoch:0229 train loss:1.443 acc:45.00 | val loss:1.461 acc:80.40\r\n",
      "Epoch:0230 train loss:1.361 acc:50.71 | val loss:1.456 acc:81.00\r\n",
      "Epoch:0231 train loss:1.471 acc:47.14 | val loss:1.453 acc:80.80\r\n",
      "Epoch:0232 train loss:1.385 acc:51.43 | val loss:1.450 acc:81.00\r\n",
      "Epoch:0233 train loss:1.474 acc:45.71 | val loss:1.447 acc:80.40\r\n",
      "Epoch:0234 train loss:1.472 acc:52.14 | val loss:1.446 acc:80.60\r\n",
      "Epoch:0235 train loss:1.466 acc:50.00 | val loss:1.445 acc:80.40\r\n",
      "Epoch:0236 train loss:1.390 acc:51.43 | val loss:1.445 acc:80.20\r\n",
      "Epoch:0237 train loss:1.502 acc:49.29 | val loss:1.445 acc:79.60\r\n",
      "Epoch:0238 train loss:1.440 acc:49.29 | val loss:1.447 acc:79.40\r\n",
      "Epoch:0239 train loss:1.450 acc:48.57 | val loss:1.448 acc:79.60\r\n",
      "Epoch:0240 train loss:1.429 acc:49.29 | val loss:1.449 acc:79.00\r\n",
      "Epoch:0241 train loss:1.442 acc:45.00 | val loss:1.449 acc:79.40\r\n",
      "Epoch:0242 train loss:1.402 acc:53.57 | val loss:1.449 acc:79.20\r\n",
      "Epoch:0243 train loss:1.478 acc:45.71 | val loss:1.451 acc:79.20\r\n",
      "Epoch:0244 train loss:1.451 acc:47.86 | val loss:1.450 acc:79.40\r\n",
      "Epoch:0245 train loss:1.377 acc:48.57 | val loss:1.449 acc:79.20\r\n",
      "Epoch:0246 train loss:1.434 acc:47.14 | val loss:1.447 acc:79.60\r\n",
      "Epoch:0247 train loss:1.450 acc:51.43 | val loss:1.444 acc:80.00\r\n",
      "Epoch:0248 train loss:1.381 acc:55.00 | val loss:1.441 acc:79.80\r\n",
      "Epoch:0249 train loss:1.449 acc:45.71 | val loss:1.437 acc:79.80\r\n",
      "Epoch:0250 train loss:1.408 acc:51.43 | val loss:1.432 acc:80.80\r\n",
      "Epoch:0251 train loss:1.429 acc:51.43 | val loss:1.428 acc:81.20\r\n",
      "Epoch:0252 train loss:1.419 acc:50.00 | val loss:1.425 acc:80.40\r\n",
      "Epoch:0253 train loss:1.368 acc:52.86 | val loss:1.421 acc:80.00\r\n",
      "Epoch:0254 train loss:1.454 acc:45.71 | val loss:1.417 acc:79.80\r\n",
      "Epoch:0255 train loss:1.403 acc:47.86 | val loss:1.417 acc:80.00\r\n",
      "Epoch:0256 train loss:1.452 acc:49.29 | val loss:1.416 acc:80.00\r\n",
      "Epoch:0257 train loss:1.400 acc:50.00 | val loss:1.416 acc:80.00\r\n",
      "Epoch:0258 train loss:1.392 acc:50.71 | val loss:1.417 acc:80.20\r\n",
      "Epoch:0259 train loss:1.486 acc:42.86 | val loss:1.418 acc:80.00\r\n",
      "Epoch:0260 train loss:1.470 acc:45.71 | val loss:1.418 acc:79.60\r\n",
      "Epoch:0261 train loss:1.410 acc:48.57 | val loss:1.418 acc:79.60\r\n",
      "Epoch:0262 train loss:1.451 acc:40.00 | val loss:1.419 acc:79.80\r\n",
      "Epoch:0263 train loss:1.381 acc:52.86 | val loss:1.418 acc:79.60\r\n",
      "Epoch:0264 train loss:1.347 acc:50.71 | val loss:1.418 acc:79.80\r\n",
      "Epoch:0265 train loss:1.468 acc:47.14 | val loss:1.417 acc:80.00\r\n",
      "Epoch:0266 train loss:1.469 acc:47.14 | val loss:1.417 acc:80.20\r\n",
      "Epoch:0267 train loss:1.484 acc:50.00 | val loss:1.418 acc:80.40\r\n",
      "Epoch:0268 train loss:1.377 acc:51.43 | val loss:1.419 acc:80.40\r\n",
      "Epoch:0269 train loss:1.404 acc:47.86 | val loss:1.419 acc:80.80\r\n",
      "Epoch:0270 train loss:1.346 acc:47.86 | val loss:1.419 acc:80.40\r\n",
      "Epoch:0271 train loss:1.432 acc:47.14 | val loss:1.419 acc:80.40\r\n",
      "Epoch:0272 train loss:1.423 acc:48.57 | val loss:1.419 acc:80.20\r\n",
      "Epoch:0273 train loss:1.404 acc:51.43 | val loss:1.418 acc:80.80\r\n",
      "Epoch:0274 train loss:1.381 acc:50.00 | val loss:1.417 acc:80.60\r\n",
      "Epoch:0275 train loss:1.393 acc:48.57 | val loss:1.415 acc:80.20\r\n",
      "Epoch:0276 train loss:1.382 acc:47.14 | val loss:1.414 acc:80.00\r\n",
      "Epoch:0277 train loss:1.453 acc:44.29 | val loss:1.411 acc:80.60\r\n",
      "Epoch:0278 train loss:1.418 acc:43.57 | val loss:1.411 acc:80.40\r\n",
      "Epoch:0279 train loss:1.374 acc:51.43 | val loss:1.411 acc:80.20\r\n",
      "Epoch:0280 train loss:1.323 acc:52.86 | val loss:1.410 acc:80.20\r\n",
      "Epoch:0281 train loss:1.391 acc:52.14 | val loss:1.408 acc:80.40\r\n",
      "Epoch:0282 train loss:1.476 acc:42.14 | val loss:1.406 acc:80.40\r\n",
      "Epoch:0283 train loss:1.381 acc:52.14 | val loss:1.403 acc:80.40\r\n",
      "Epoch:0284 train loss:1.450 acc:42.86 | val loss:1.401 acc:80.00\r\n",
      "Epoch:0285 train loss:1.344 acc:52.14 | val loss:1.398 acc:80.60\r\n",
      "Epoch:0286 train loss:1.389 acc:50.00 | val loss:1.395 acc:81.00\r\n",
      "Epoch:0287 train loss:1.483 acc:42.86 | val loss:1.393 acc:80.40\r\n",
      "Epoch:0288 train loss:1.456 acc:42.86 | val loss:1.392 acc:80.20\r\n",
      "Epoch:0289 train loss:1.322 acc:60.71 | val loss:1.390 acc:79.60\r\n",
      "Epoch:0290 train loss:1.394 acc:50.00 | val loss:1.388 acc:79.40\r\n",
      "Epoch:0291 train loss:1.368 acc:55.71 | val loss:1.386 acc:79.60\r\n",
      "Epoch:0292 train loss:1.382 acc:49.29 | val loss:1.383 acc:79.80\r\n",
      "Epoch:0293 train loss:1.361 acc:50.71 | val loss:1.380 acc:79.60\r\n",
      "Epoch:0294 train loss:1.367 acc:52.14 | val loss:1.378 acc:80.00\r\n",
      "Epoch:0295 train loss:1.383 acc:55.00 | val loss:1.375 acc:80.00\r\n",
      "Epoch:0296 train loss:1.411 acc:44.29 | val loss:1.373 acc:80.60\r\n",
      "Epoch:0297 train loss:1.353 acc:57.14 | val loss:1.371 acc:80.60\r\n",
      "Epoch:0298 train loss:1.476 acc:45.00 | val loss:1.370 acc:81.20\r\n",
      "Epoch:0299 train loss:1.386 acc:51.43 | val loss:1.370 acc:81.00\r\n",
      "Epoch:0300 train loss:1.359 acc:52.86 | val loss:1.370 acc:81.80\r\n",
      "Epoch:0301 train loss:1.438 acc:49.29 | val loss:1.370 acc:82.20\r\n",
      "Epoch:0302 train loss:1.406 acc:47.14 | val loss:1.369 acc:81.60\r\n",
      "Epoch:0303 train loss:1.417 acc:43.57 | val loss:1.370 acc:82.00\r\n",
      "Epoch:0304 train loss:1.362 acc:52.86 | val loss:1.371 acc:81.80\r\n",
      "Epoch:0305 train loss:1.359 acc:47.86 | val loss:1.371 acc:82.40\r\n",
      "Epoch:0306 train loss:1.446 acc:45.71 | val loss:1.372 acc:82.40\r\n",
      "Epoch:0307 train loss:1.419 acc:47.86 | val loss:1.373 acc:82.20\r\n",
      "Epoch:0308 train loss:1.400 acc:45.71 | val loss:1.373 acc:82.20\r\n",
      "Epoch:0309 train loss:1.459 acc:43.57 | val loss:1.373 acc:82.20\r\n",
      "Epoch:0310 train loss:1.345 acc:52.86 | val loss:1.373 acc:82.20\r\n",
      "Epoch:0311 train loss:1.425 acc:45.00 | val loss:1.375 acc:82.20\r\n",
      "Epoch:0312 train loss:1.354 acc:50.00 | val loss:1.376 acc:82.20\r\n",
      "Epoch:0313 train loss:1.359 acc:53.57 | val loss:1.376 acc:81.20\r\n",
      "Epoch:0314 train loss:1.418 acc:52.86 | val loss:1.376 acc:80.80\r\n",
      "Epoch:0315 train loss:1.339 acc:52.14 | val loss:1.375 acc:80.60\r\n",
      "Epoch:0316 train loss:1.395 acc:47.14 | val loss:1.375 acc:80.00\r\n",
      "Epoch:0317 train loss:1.336 acc:52.86 | val loss:1.374 acc:79.80\r\n",
      "Epoch:0318 train loss:1.528 acc:47.14 | val loss:1.377 acc:80.00\r\n",
      "Epoch:0319 train loss:1.419 acc:52.86 | val loss:1.379 acc:80.00\r\n",
      "Epoch:0320 train loss:1.377 acc:53.57 | val loss:1.380 acc:80.20\r\n",
      "Epoch:0321 train loss:1.369 acc:51.43 | val loss:1.380 acc:80.40\r\n",
      "Epoch:0322 train loss:1.364 acc:50.00 | val loss:1.380 acc:80.00\r\n",
      "Epoch:0323 train loss:1.341 acc:50.00 | val loss:1.380 acc:80.00\r\n",
      "Epoch:0324 train loss:1.409 acc:45.00 | val loss:1.379 acc:80.40\r\n",
      "Epoch:0325 train loss:1.351 acc:46.43 | val loss:1.378 acc:80.40\r\n",
      "Epoch:0326 train loss:1.332 acc:55.71 | val loss:1.376 acc:80.60\r\n",
      "Epoch:0327 train loss:1.313 acc:52.14 | val loss:1.373 acc:80.60\r\n",
      "Epoch:0328 train loss:1.333 acc:52.86 | val loss:1.370 acc:81.00\r\n",
      "Epoch:0329 train loss:1.704 acc:52.14 | val loss:1.366 acc:80.60\r\n",
      "Epoch:0330 train loss:1.357 acc:52.86 | val loss:1.362 acc:80.80\r\n",
      "Epoch:0331 train loss:1.371 acc:52.14 | val loss:1.360 acc:81.00\r\n",
      "Epoch:0332 train loss:1.371 acc:50.71 | val loss:1.357 acc:81.20\r\n",
      "Epoch:0333 train loss:1.378 acc:47.86 | val loss:1.354 acc:82.00\r\n",
      "Epoch:0334 train loss:1.387 acc:46.43 | val loss:1.351 acc:81.60\r\n",
      "Epoch:0335 train loss:1.431 acc:49.29 | val loss:1.349 acc:81.40\r\n",
      "Epoch:0336 train loss:1.396 acc:48.57 | val loss:1.347 acc:81.20\r\n",
      "Epoch:0337 train loss:1.334 acc:48.57 | val loss:1.344 acc:80.40\r\n",
      "Epoch:0338 train loss:1.323 acc:54.29 | val loss:1.342 acc:80.60\r\n",
      "Epoch:0339 train loss:1.304 acc:55.00 | val loss:1.339 acc:80.80\r\n",
      "Epoch:0340 train loss:1.413 acc:45.00 | val loss:1.338 acc:80.80\r\n",
      "Epoch:0341 train loss:1.222 acc:57.14 | val loss:1.337 acc:81.40\r\n",
      "Epoch:0342 train loss:1.343 acc:55.00 | val loss:1.335 acc:81.60\r\n",
      "Epoch:0343 train loss:1.326 acc:51.43 | val loss:1.335 acc:82.40\r\n",
      "Epoch:0344 train loss:1.334 acc:53.57 | val loss:1.334 acc:82.40\r\n",
      "Epoch:0345 train loss:1.463 acc:44.29 | val loss:1.334 acc:82.00\r\n",
      "Epoch:0346 train loss:1.343 acc:54.29 | val loss:1.334 acc:81.60\r\n",
      "Epoch:0347 train loss:1.339 acc:54.29 | val loss:1.334 acc:81.80\r\n",
      "Epoch:0348 train loss:1.347 acc:45.71 | val loss:1.334 acc:81.40\r\n",
      "Epoch:0349 train loss:1.361 acc:49.29 | val loss:1.335 acc:82.00\r\n",
      "Epoch:0350 train loss:1.396 acc:47.86 | val loss:1.336 acc:82.00\r\n",
      "Epoch:0351 train loss:1.288 acc:52.14 | val loss:1.337 acc:82.00\r\n",
      "Epoch:0352 train loss:1.363 acc:52.86 | val loss:1.338 acc:82.40\r\n",
      "Epoch:0353 train loss:1.320 acc:57.14 | val loss:1.338 acc:82.20\r\n",
      "Epoch:0354 train loss:1.312 acc:52.14 | val loss:1.339 acc:81.80\r\n",
      "Epoch:0355 train loss:1.351 acc:49.29 | val loss:1.339 acc:82.00\r\n",
      "Epoch:0356 train loss:1.374 acc:50.00 | val loss:1.338 acc:82.20\r\n",
      "Epoch:0357 train loss:1.250 acc:54.29 | val loss:1.337 acc:82.40\r\n",
      "Epoch:0358 train loss:1.420 acc:53.57 | val loss:1.335 acc:82.60\r\n",
      "Epoch:0359 train loss:1.363 acc:46.43 | val loss:1.334 acc:82.40\r\n",
      "Epoch:0360 train loss:1.335 acc:49.29 | val loss:1.331 acc:82.60\r\n",
      "Epoch:0361 train loss:1.314 acc:50.00 | val loss:1.327 acc:82.00\r\n",
      "Epoch:0362 train loss:1.325 acc:53.57 | val loss:1.325 acc:81.60\r\n",
      "Epoch:0363 train loss:1.387 acc:52.14 | val loss:1.323 acc:81.60\r\n",
      "Epoch:0364 train loss:1.413 acc:45.71 | val loss:1.322 acc:81.20\r\n",
      "Epoch:0365 train loss:1.384 acc:48.57 | val loss:1.324 acc:81.80\r\n",
      "Epoch:0366 train loss:1.295 acc:53.57 | val loss:1.325 acc:81.60\r\n",
      "Epoch:0367 train loss:1.360 acc:55.00 | val loss:1.325 acc:81.60\r\n",
      "Epoch:0368 train loss:1.352 acc:48.57 | val loss:1.325 acc:81.60\r\n",
      "Epoch:0369 train loss:1.355 acc:52.14 | val loss:1.326 acc:81.60\r\n",
      "Epoch:0370 train loss:1.281 acc:51.43 | val loss:1.325 acc:81.60\r\n",
      "Epoch:0371 train loss:1.401 acc:46.43 | val loss:1.324 acc:81.60\r\n",
      "Epoch:0372 train loss:1.329 acc:46.43 | val loss:1.323 acc:81.60\r\n",
      "Epoch:0373 train loss:1.274 acc:61.43 | val loss:1.322 acc:81.40\r\n",
      "Epoch:0374 train loss:1.393 acc:50.00 | val loss:1.322 acc:81.40\r\n",
      "Epoch:0375 train loss:1.272 acc:57.86 | val loss:1.321 acc:81.60\r\n",
      "Epoch:0376 train loss:1.361 acc:49.29 | val loss:1.320 acc:81.80\r\n",
      "Epoch:0377 train loss:1.302 acc:50.00 | val loss:1.320 acc:81.60\r\n",
      "Epoch:0378 train loss:1.248 acc:62.14 | val loss:1.318 acc:82.00\r\n",
      "Epoch:0379 train loss:1.353 acc:49.29 | val loss:1.316 acc:82.00\r\n",
      "Epoch:0380 train loss:1.345 acc:52.14 | val loss:1.315 acc:82.20\r\n",
      "Epoch:0381 train loss:1.307 acc:56.43 | val loss:1.314 acc:82.00\r\n",
      "Epoch:0382 train loss:1.316 acc:51.43 | val loss:1.313 acc:82.60\r\n",
      "Epoch:0383 train loss:1.270 acc:55.71 | val loss:1.312 acc:82.80\r\n",
      "Epoch:0384 train loss:1.435 acc:44.29 | val loss:1.311 acc:82.40\r\n",
      "Epoch:0385 train loss:1.378 acc:49.29 | val loss:1.309 acc:82.40\r\n",
      "Epoch:0386 train loss:1.281 acc:55.00 | val loss:1.309 acc:82.40\r\n",
      "Epoch:0387 train loss:1.244 acc:56.43 | val loss:1.308 acc:82.60\r\n",
      "Epoch:0388 train loss:1.251 acc:53.57 | val loss:1.307 acc:83.00\r\n",
      "Epoch:0389 train loss:1.304 acc:52.86 | val loss:1.305 acc:82.80\r\n",
      "Epoch:0390 train loss:1.343 acc:50.00 | val loss:1.304 acc:83.00\r\n",
      "Epoch:0391 train loss:1.337 acc:52.14 | val loss:1.303 acc:82.60\r\n",
      "Epoch:0392 train loss:1.309 acc:52.86 | val loss:1.301 acc:82.60\r\n",
      "Epoch:0393 train loss:1.374 acc:52.14 | val loss:1.299 acc:82.40\r\n",
      "Epoch:0394 train loss:1.398 acc:49.29 | val loss:1.298 acc:82.40\r\n",
      "Epoch:0395 train loss:1.291 acc:50.71 | val loss:1.297 acc:81.80\r\n",
      "Epoch:0396 train loss:1.404 acc:50.71 | val loss:1.295 acc:82.20\r\n",
      "Epoch:0397 train loss:1.346 acc:47.86 | val loss:1.295 acc:82.00\r\n",
      "Epoch:0398 train loss:1.327 acc:47.14 | val loss:1.296 acc:81.80\r\n",
      "Epoch:0399 train loss:1.399 acc:51.43 | val loss:1.298 acc:81.20\r\n",
      "Epoch:0400 train loss:1.387 acc:44.29 | val loss:1.301 acc:81.40\r\n",
      "Epoch:0401 train loss:1.395 acc:46.43 | val loss:1.304 acc:81.20\r\n",
      "Epoch:0402 train loss:1.306 acc:55.71 | val loss:1.305 acc:81.40\r\n",
      "Epoch:0403 train loss:1.335 acc:50.71 | val loss:1.306 acc:81.60\r\n",
      "Epoch:0404 train loss:1.427 acc:41.43 | val loss:1.307 acc:82.00\r\n",
      "Epoch:0405 train loss:1.321 acc:53.57 | val loss:1.308 acc:82.20\r\n",
      "Epoch:0406 train loss:1.286 acc:52.86 | val loss:1.308 acc:82.40\r\n",
      "Epoch:0407 train loss:1.357 acc:53.57 | val loss:1.307 acc:82.00\r\n",
      "Epoch:0408 train loss:1.320 acc:56.43 | val loss:1.305 acc:82.00\r\n",
      "Epoch:0409 train loss:1.344 acc:46.43 | val loss:1.303 acc:82.00\r\n",
      "Epoch:0410 train loss:1.297 acc:49.29 | val loss:1.300 acc:82.20\r\n",
      "Epoch:0411 train loss:1.253 acc:55.00 | val loss:1.297 acc:82.40\r\n",
      "Epoch:0412 train loss:1.391 acc:43.57 | val loss:1.296 acc:82.40\r\n",
      "Epoch:0413 train loss:1.340 acc:50.00 | val loss:1.294 acc:82.20\r\n",
      "Epoch:0414 train loss:1.315 acc:56.43 | val loss:1.292 acc:81.80\r\n",
      "Epoch:0415 train loss:1.315 acc:58.57 | val loss:1.291 acc:81.80\r\n",
      "Epoch:0416 train loss:1.308 acc:50.00 | val loss:1.289 acc:82.00\r\n",
      "Epoch:0417 train loss:1.212 acc:57.14 | val loss:1.286 acc:82.00\r\n",
      "Epoch:0418 train loss:1.272 acc:56.43 | val loss:1.284 acc:81.80\r\n",
      "Epoch:0419 train loss:1.358 acc:50.00 | val loss:1.284 acc:82.00\r\n",
      "Epoch:0420 train loss:1.175 acc:57.86 | val loss:1.282 acc:82.00\r\n",
      "Epoch:0421 train loss:1.332 acc:51.43 | val loss:1.281 acc:81.60\r\n",
      "Epoch:0422 train loss:1.311 acc:55.71 | val loss:1.280 acc:81.60\r\n",
      "Epoch:0423 train loss:1.283 acc:55.71 | val loss:1.280 acc:81.60\r\n",
      "Epoch:0424 train loss:1.362 acc:50.00 | val loss:1.280 acc:81.60\r\n",
      "Epoch:0425 train loss:1.275 acc:52.14 | val loss:1.279 acc:81.60\r\n",
      "Epoch:0426 train loss:1.341 acc:43.57 | val loss:1.280 acc:81.40\r\n",
      "Epoch:0427 train loss:1.412 acc:44.29 | val loss:1.281 acc:81.60\r\n",
      "Epoch:0428 train loss:1.227 acc:52.86 | val loss:1.281 acc:81.80\r\n",
      "Epoch:0429 train loss:1.275 acc:55.00 | val loss:1.281 acc:81.80\r\n",
      "Epoch:0430 train loss:1.344 acc:53.57 | val loss:1.281 acc:81.60\r\n",
      "Epoch:0431 train loss:1.339 acc:52.86 | val loss:1.281 acc:81.60\r\n",
      "Epoch:0432 train loss:1.343 acc:48.57 | val loss:1.281 acc:81.60\r\n",
      "Epoch:0433 train loss:1.398 acc:45.00 | val loss:1.281 acc:81.40\r\n",
      "Epoch:0434 train loss:1.340 acc:51.43 | val loss:1.281 acc:81.80\r\n",
      "Epoch:0435 train loss:1.311 acc:52.86 | val loss:1.281 acc:82.00\r\n",
      "Epoch:0436 train loss:1.348 acc:51.43 | val loss:1.282 acc:82.00\r\n",
      "Epoch:0437 train loss:1.365 acc:50.00 | val loss:1.282 acc:81.60\r\n",
      "Epoch:0438 train loss:1.211 acc:52.86 | val loss:1.282 acc:82.00\r\n",
      "Epoch:0439 train loss:1.344 acc:50.00 | val loss:1.283 acc:82.20\r\n",
      "Epoch:0440 train loss:1.404 acc:44.29 | val loss:1.283 acc:82.00\r\n",
      "Epoch:0441 train loss:1.295 acc:52.86 | val loss:1.284 acc:82.20\r\n",
      "Epoch:0442 train loss:1.281 acc:56.43 | val loss:1.283 acc:82.20\r\n",
      "Epoch:0443 train loss:1.338 acc:47.86 | val loss:1.283 acc:82.20\r\n",
      "Epoch:0444 train loss:1.337 acc:50.00 | val loss:1.282 acc:81.60\r\n",
      "Epoch:0445 train loss:1.387 acc:47.14 | val loss:1.282 acc:81.60\r\n",
      "Epoch:0446 train loss:1.235 acc:55.71 | val loss:1.281 acc:81.80\r\n",
      "Epoch:0447 train loss:1.317 acc:55.00 | val loss:1.279 acc:82.00\r\n",
      "Epoch:0448 train loss:1.217 acc:52.14 | val loss:1.277 acc:81.80\r\n",
      "Epoch:0449 train loss:1.305 acc:50.71 | val loss:1.275 acc:81.60\r\n",
      "Epoch:0450 train loss:1.270 acc:52.14 | val loss:1.274 acc:81.60\r\n",
      "Epoch:0451 train loss:1.318 acc:53.57 | val loss:1.273 acc:81.80\r\n",
      "Epoch:0452 train loss:1.243 acc:62.86 | val loss:1.271 acc:81.80\r\n",
      "Epoch:0453 train loss:1.304 acc:52.86 | val loss:1.270 acc:81.60\r\n",
      "Epoch:0454 train loss:1.368 acc:43.57 | val loss:1.269 acc:81.80\r\n",
      "Epoch:0455 train loss:1.394 acc:38.57 | val loss:1.269 acc:82.20\r\n",
      "Epoch:0456 train loss:1.329 acc:47.86 | val loss:1.268 acc:82.80\r\n",
      "Epoch:0457 train loss:1.368 acc:49.29 | val loss:1.268 acc:82.40\r\n",
      "Epoch:0458 train loss:1.264 acc:54.29 | val loss:1.269 acc:81.80\r\n",
      "Epoch:0459 train loss:1.374 acc:45.71 | val loss:1.269 acc:81.80\r\n",
      "Epoch:0460 train loss:1.365 acc:45.71 | val loss:1.271 acc:82.00\r\n",
      "Epoch:0461 train loss:1.228 acc:53.57 | val loss:1.271 acc:82.00\r\n",
      "Epoch:0462 train loss:1.348 acc:52.14 | val loss:1.273 acc:81.80\r\n",
      "Epoch:0463 train loss:1.255 acc:55.71 | val loss:1.273 acc:82.20\r\n",
      "Epoch:0464 train loss:1.270 acc:56.43 | val loss:1.273 acc:82.20\r\n",
      "Epoch:0465 train loss:1.382 acc:47.86 | val loss:1.273 acc:82.20\r\n",
      "Epoch:0466 train loss:1.252 acc:53.57 | val loss:1.272 acc:82.20\r\n",
      "Epoch:0467 train loss:1.352 acc:48.57 | val loss:1.272 acc:82.00\r\n",
      "Epoch:0468 train loss:1.249 acc:50.71 | val loss:1.270 acc:81.80\r\n",
      "Epoch:0469 train loss:1.250 acc:60.00 | val loss:1.268 acc:82.20\r\n",
      "Epoch:0470 train loss:1.230 acc:58.57 | val loss:1.265 acc:82.20\r\n",
      "Epoch:0471 train loss:1.409 acc:46.43 | val loss:1.262 acc:82.40\r\n",
      "Epoch:0472 train loss:1.336 acc:47.86 | val loss:1.259 acc:82.00\r\n",
      "Epoch:0473 train loss:1.255 acc:52.14 | val loss:1.256 acc:81.40\r\n",
      "Epoch:0474 train loss:1.269 acc:54.29 | val loss:1.254 acc:81.40\r\n",
      "Epoch:0475 train loss:1.255 acc:59.29 | val loss:1.252 acc:81.00\r\n",
      "Epoch:0476 train loss:1.258 acc:53.57 | val loss:1.249 acc:81.00\r\n",
      "Epoch:0477 train loss:1.234 acc:54.29 | val loss:1.247 acc:80.80\r\n",
      "Epoch:0478 train loss:1.366 acc:50.71 | val loss:1.246 acc:81.60\r\n",
      "Epoch:0479 train loss:1.245 acc:56.43 | val loss:1.245 acc:81.40\r\n",
      "Epoch:0480 train loss:1.355 acc:50.00 | val loss:1.245 acc:81.60\r\n",
      "Epoch:0481 train loss:1.286 acc:55.00 | val loss:1.245 acc:81.40\r\n",
      "Epoch:0482 train loss:1.292 acc:53.57 | val loss:1.246 acc:81.40\r\n",
      "Epoch:0483 train loss:1.261 acc:52.86 | val loss:1.247 acc:82.00\r\n",
      "Epoch:0484 train loss:1.281 acc:54.29 | val loss:1.247 acc:82.20\r\n",
      "Epoch:0485 train loss:1.196 acc:52.14 | val loss:1.247 acc:82.20\r\n",
      "Epoch:0486 train loss:1.275 acc:57.86 | val loss:1.247 acc:82.40\r\n",
      "Epoch:0487 train loss:1.239 acc:55.00 | val loss:1.248 acc:82.20\r\n",
      "Epoch:0488 train loss:1.325 acc:45.71 | val loss:1.248 acc:82.20\r\n",
      "Epoch:0489 train loss:1.341 acc:47.86 | val loss:1.249 acc:82.20\r\n",
      "Epoch:0490 train loss:1.272 acc:54.29 | val loss:1.250 acc:81.80\r\n",
      "Epoch:0491 train loss:1.244 acc:57.86 | val loss:1.250 acc:82.00\r\n",
      "Epoch:0492 train loss:1.364 acc:50.00 | val loss:1.250 acc:82.00\r\n",
      "Epoch:0493 train loss:1.210 acc:60.00 | val loss:1.250 acc:81.60\r\n",
      "Epoch:0494 train loss:1.406 acc:46.43 | val loss:1.252 acc:81.20\r\n",
      "Epoch:0495 train loss:1.283 acc:51.43 | val loss:1.253 acc:81.40\r\n",
      "Epoch:0496 train loss:1.270 acc:53.57 | val loss:1.256 acc:81.40\r\n",
      "Epoch:0497 train loss:1.294 acc:49.29 | val loss:1.257 acc:81.00\r\n",
      "Epoch:0498 train loss:1.391 acc:46.43 | val loss:1.258 acc:81.80\r\n",
      "Epoch:0499 train loss:1.273 acc:53.57 | val loss:1.258 acc:81.60\r\n",
      "Epoch:0500 train loss:1.213 acc:56.43 | val loss:1.258 acc:81.40\r\n",
      "Epoch:0501 train loss:1.237 acc:52.86 | val loss:1.257 acc:81.60\r\n",
      "Epoch:0502 train loss:1.242 acc:60.71 | val loss:1.255 acc:81.60\r\n",
      "Epoch:0503 train loss:1.333 acc:49.29 | val loss:1.254 acc:81.80\r\n",
      "Epoch:0504 train loss:1.223 acc:59.29 | val loss:1.252 acc:81.80\r\n",
      "Epoch:0505 train loss:1.305 acc:57.14 | val loss:1.249 acc:81.60\r\n",
      "Epoch:0506 train loss:1.312 acc:48.57 | val loss:1.247 acc:81.60\r\n",
      "Epoch:0507 train loss:1.265 acc:50.00 | val loss:1.245 acc:81.80\r\n",
      "Epoch:0508 train loss:1.254 acc:52.86 | val loss:1.244 acc:81.40\r\n",
      "Epoch:0509 train loss:1.316 acc:52.86 | val loss:1.243 acc:81.80\r\n",
      "Epoch:0510 train loss:1.307 acc:55.00 | val loss:1.243 acc:82.20\r\n",
      "Epoch:0511 train loss:1.386 acc:48.57 | val loss:1.243 acc:82.20\r\n",
      "Epoch:0512 train loss:1.137 acc:58.57 | val loss:1.242 acc:82.40\r\n",
      "Epoch:0513 train loss:1.381 acc:51.43 | val loss:1.241 acc:82.80\r\n",
      "Epoch:0514 train loss:1.321 acc:52.86 | val loss:1.241 acc:82.20\r\n",
      "Epoch:0515 train loss:1.292 acc:50.71 | val loss:1.240 acc:82.20\r\n",
      "Epoch:0516 train loss:1.229 acc:55.71 | val loss:1.239 acc:82.40\r\n",
      "Epoch:0517 train loss:1.184 acc:59.29 | val loss:1.238 acc:82.40\r\n",
      "Epoch:0518 train loss:1.231 acc:56.43 | val loss:1.236 acc:82.20\r\n",
      "Epoch:0519 train loss:1.228 acc:60.00 | val loss:1.235 acc:82.40\r\n",
      "Epoch:0520 train loss:1.273 acc:52.86 | val loss:1.234 acc:82.20\r\n",
      "Epoch:0521 train loss:1.262 acc:57.14 | val loss:1.233 acc:82.20\r\n",
      "Epoch:0522 train loss:1.286 acc:55.71 | val loss:1.231 acc:82.40\r\n",
      "Epoch:0523 train loss:1.344 acc:51.43 | val loss:1.229 acc:82.40\r\n",
      "Epoch:0524 train loss:1.318 acc:48.57 | val loss:1.227 acc:82.20\r\n",
      "Epoch:0525 train loss:1.230 acc:52.14 | val loss:1.224 acc:82.20\r\n",
      "Epoch:0526 train loss:1.300 acc:50.00 | val loss:1.221 acc:82.40\r\n",
      "Epoch:0527 train loss:1.262 acc:50.71 | val loss:1.220 acc:82.40\r\n",
      "Epoch:0528 train loss:1.366 acc:48.57 | val loss:1.220 acc:82.20\r\n",
      "Epoch:0529 train loss:1.355 acc:42.14 | val loss:1.221 acc:82.00\r\n",
      "Epoch:0530 train loss:1.290 acc:49.29 | val loss:1.223 acc:82.00\r\n",
      "Epoch:0531 train loss:1.352 acc:55.71 | val loss:1.227 acc:82.20\r\n",
      "Epoch:0532 train loss:1.360 acc:46.43 | val loss:1.231 acc:82.40\r\n",
      "Epoch:0533 train loss:1.245 acc:56.43 | val loss:1.233 acc:82.40\r\n",
      "Epoch:0534 train loss:1.276 acc:57.14 | val loss:1.234 acc:82.20\r\n",
      "Epoch:0535 train loss:1.291 acc:50.00 | val loss:1.235 acc:82.20\r\n",
      "Epoch:0536 train loss:1.277 acc:54.29 | val loss:1.236 acc:82.20\r\n",
      "Epoch:0537 train loss:1.272 acc:58.57 | val loss:1.237 acc:82.40\r\n",
      "Epoch:0538 train loss:1.276 acc:48.57 | val loss:1.237 acc:82.40\r\n",
      "Epoch:0539 train loss:1.353 acc:50.00 | val loss:1.236 acc:83.00\r\n",
      "Epoch:0540 train loss:1.221 acc:57.86 | val loss:1.234 acc:82.80\r\n",
      "Epoch:0541 train loss:1.190 acc:57.86 | val loss:1.231 acc:82.80\r\n",
      "Epoch:0542 train loss:1.265 acc:52.86 | val loss:1.228 acc:83.20\r\n",
      "Epoch:0543 train loss:1.266 acc:49.29 | val loss:1.226 acc:83.00\r\n",
      "Epoch:0544 train loss:1.308 acc:49.29 | val loss:1.224 acc:83.20\r\n",
      "Epoch:0545 train loss:1.269 acc:52.86 | val loss:1.222 acc:83.00\r\n",
      "Epoch:0546 train loss:1.237 acc:55.71 | val loss:1.219 acc:83.00\r\n",
      "Epoch:0547 train loss:1.238 acc:57.14 | val loss:1.217 acc:82.60\r\n",
      "Epoch:0548 train loss:1.266 acc:50.00 | val loss:1.215 acc:82.40\r\n",
      "Epoch:0549 train loss:1.212 acc:55.71 | val loss:1.213 acc:82.20\r\n",
      "Epoch:0550 train loss:1.283 acc:56.43 | val loss:1.211 acc:82.20\r\n",
      "Epoch:0551 train loss:1.313 acc:50.00 | val loss:1.210 acc:82.40\r\n",
      "Epoch:0552 train loss:1.209 acc:55.00 | val loss:1.209 acc:82.20\r\n",
      "Epoch:0553 train loss:1.372 acc:50.00 | val loss:1.211 acc:81.60\r\n",
      "Epoch:0554 train loss:1.242 acc:52.86 | val loss:1.213 acc:82.00\r\n",
      "Epoch:0555 train loss:1.280 acc:52.86 | val loss:1.215 acc:82.00\r\n",
      "Epoch:0556 train loss:1.310 acc:47.86 | val loss:1.218 acc:82.40\r\n",
      "Epoch:0557 train loss:1.267 acc:52.86 | val loss:1.220 acc:82.00\r\n",
      "Epoch:0558 train loss:1.248 acc:55.71 | val loss:1.221 acc:81.40\r\n",
      "Epoch:0559 train loss:1.263 acc:52.14 | val loss:1.222 acc:81.60\r\n",
      "Epoch:0560 train loss:1.210 acc:51.43 | val loss:1.223 acc:81.40\r\n",
      "Epoch:0561 train loss:1.256 acc:59.29 | val loss:1.223 acc:81.40\r\n",
      "Epoch:0562 train loss:1.211 acc:58.57 | val loss:1.221 acc:81.60\r\n",
      "Epoch:0563 train loss:1.401 acc:49.29 | val loss:1.220 acc:82.20\r\n",
      "Epoch:0564 train loss:1.306 acc:55.00 | val loss:1.218 acc:83.20\r\n",
      "Epoch:0565 train loss:1.187 acc:60.00 | val loss:1.216 acc:83.40\r\n",
      "Epoch:0566 train loss:1.254 acc:55.00 | val loss:1.213 acc:83.60\r\n",
      "Epoch:0567 train loss:1.291 acc:52.86 | val loss:1.210 acc:83.80\r\n",
      "Epoch:0568 train loss:1.239 acc:57.14 | val loss:1.207 acc:83.40\r\n",
      "Epoch:0569 train loss:1.235 acc:55.71 | val loss:1.204 acc:82.80\r\n",
      "Epoch:0570 train loss:1.268 acc:55.00 | val loss:1.201 acc:82.40\r\n",
      "Epoch:0571 train loss:1.264 acc:52.14 | val loss:1.198 acc:82.20\r\n",
      "Epoch:0572 train loss:1.236 acc:53.57 | val loss:1.196 acc:81.80\r\n",
      "Epoch:0573 train loss:1.225 acc:50.00 | val loss:1.194 acc:81.60\r\n",
      "Epoch:0574 train loss:1.296 acc:51.43 | val loss:1.193 acc:81.40\r\n",
      "Epoch:0575 train loss:1.279 acc:49.29 | val loss:1.194 acc:81.20\r\n",
      "Epoch:0576 train loss:1.261 acc:55.71 | val loss:1.194 acc:81.20\r\n",
      "Epoch:0577 train loss:1.326 acc:48.57 | val loss:1.195 acc:81.60\r\n",
      "Epoch:0578 train loss:1.256 acc:57.14 | val loss:1.197 acc:81.60\r\n",
      "Epoch:0579 train loss:1.285 acc:57.14 | val loss:1.199 acc:81.80\r\n",
      "Epoch:0580 train loss:1.167 acc:58.57 | val loss:1.201 acc:81.60\r\n",
      "Epoch:0581 train loss:1.191 acc:54.29 | val loss:1.202 acc:81.60\r\n",
      "Epoch:0582 train loss:1.234 acc:55.00 | val loss:1.204 acc:81.80\r\n",
      "Epoch:0583 train loss:1.265 acc:54.29 | val loss:1.206 acc:82.00\r\n",
      "Epoch:0584 train loss:1.363 acc:42.14 | val loss:1.209 acc:82.60\r\n",
      "Epoch:0585 train loss:1.144 acc:62.14 | val loss:1.211 acc:82.40\r\n",
      "Epoch:0586 train loss:1.266 acc:52.86 | val loss:1.212 acc:82.20\r\n",
      "Epoch:0587 train loss:1.283 acc:48.57 | val loss:1.213 acc:82.20\r\n",
      "Epoch:0588 train loss:1.179 acc:58.57 | val loss:1.213 acc:82.00\r\n",
      "Epoch:0589 train loss:1.319 acc:47.86 | val loss:1.213 acc:82.20\r\n",
      "Epoch:0590 train loss:1.353 acc:55.71 | val loss:1.213 acc:82.40\r\n",
      "Epoch:0591 train loss:1.152 acc:58.57 | val loss:1.213 acc:82.40\r\n",
      "Epoch:0592 train loss:1.295 acc:50.00 | val loss:1.212 acc:82.80\r\n",
      "Epoch:0593 train loss:1.191 acc:58.57 | val loss:1.211 acc:82.80\r\n",
      "Epoch:0594 train loss:1.296 acc:51.43 | val loss:1.210 acc:82.60\r\n",
      "Epoch:0595 train loss:1.217 acc:56.43 | val loss:1.209 acc:82.60\r\n",
      "Epoch:0596 train loss:1.263 acc:48.57 | val loss:1.207 acc:82.60\r\n",
      "Epoch:0597 train loss:1.292 acc:58.57 | val loss:1.207 acc:82.00\r\n",
      "Epoch:0598 train loss:1.349 acc:52.86 | val loss:1.209 acc:81.40\r\n",
      "Epoch:0599 train loss:1.241 acc:50.71 | val loss:1.211 acc:81.20\r\n",
      "Epoch:0600 train loss:1.255 acc:57.14 | val loss:1.212 acc:80.80\r\n",
      "Epoch:0601 train loss:1.274 acc:53.57 | val loss:1.214 acc:81.00\r\n",
      "Epoch:0602 train loss:1.268 acc:59.29 | val loss:1.214 acc:81.00\r\n",
      "Epoch:0603 train loss:1.252 acc:55.71 | val loss:1.214 acc:80.60\r\n",
      "Epoch:0604 train loss:1.362 acc:52.14 | val loss:1.214 acc:80.60\r\n",
      "Epoch:0605 train loss:1.292 acc:49.29 | val loss:1.216 acc:80.40\r\n",
      "Epoch:0606 train loss:1.327 acc:55.71 | val loss:1.219 acc:80.60\r\n",
      "Epoch:0607 train loss:1.336 acc:50.71 | val loss:1.221 acc:80.60\r\n",
      "Epoch:0608 train loss:1.278 acc:52.14 | val loss:1.224 acc:81.00\r\n",
      "Epoch:0609 train loss:1.162 acc:62.14 | val loss:1.225 acc:81.20\r\n",
      "Epoch:0610 train loss:1.268 acc:55.71 | val loss:1.227 acc:81.40\r\n",
      "Epoch:0611 train loss:1.312 acc:53.57 | val loss:1.227 acc:81.60\r\n",
      "Epoch:0612 train loss:1.242 acc:50.00 | val loss:1.227 acc:81.60\r\n",
      "Epoch:0613 train loss:1.229 acc:57.14 | val loss:1.225 acc:81.60\r\n",
      "Epoch:0614 train loss:1.196 acc:57.14 | val loss:1.223 acc:82.20\r\n",
      "Epoch:0615 train loss:1.313 acc:51.43 | val loss:1.221 acc:82.40\r\n",
      "Epoch:0616 train loss:1.182 acc:55.71 | val loss:1.219 acc:82.20\r\n",
      "Epoch:0617 train loss:1.218 acc:54.29 | val loss:1.217 acc:82.20\r\n",
      "Epoch:0618 train loss:1.200 acc:58.57 | val loss:1.214 acc:82.20\r\n",
      "Epoch:0619 train loss:1.278 acc:48.57 | val loss:1.211 acc:82.40\r\n",
      "Epoch:0620 train loss:1.252 acc:60.71 | val loss:1.209 acc:82.40\r\n",
      "Epoch:0621 train loss:1.290 acc:55.00 | val loss:1.206 acc:82.20\r\n",
      "Epoch:0622 train loss:1.194 acc:56.43 | val loss:1.203 acc:82.20\r\n",
      "Epoch:0623 train loss:1.276 acc:52.14 | val loss:1.199 acc:82.60\r\n",
      "Epoch:0624 train loss:1.319 acc:50.00 | val loss:1.196 acc:82.40\r\n",
      "Epoch:0625 train loss:1.227 acc:53.57 | val loss:1.194 acc:82.60\r\n",
      "Epoch:0626 train loss:1.256 acc:51.43 | val loss:1.194 acc:82.40\r\n",
      "Epoch:0627 train loss:1.218 acc:56.43 | val loss:1.193 acc:82.40\r\n",
      "Epoch:0628 train loss:1.293 acc:45.71 | val loss:1.193 acc:82.40\r\n",
      "Epoch:0629 train loss:1.228 acc:50.00 | val loss:1.193 acc:82.20\r\n",
      "Epoch:0630 train loss:1.223 acc:54.29 | val loss:1.193 acc:82.00\r\n",
      "Epoch:0631 train loss:1.321 acc:50.00 | val loss:1.192 acc:82.00\r\n",
      "Epoch:0632 train loss:1.265 acc:56.43 | val loss:1.192 acc:81.80\r\n",
      "Epoch:0633 train loss:1.273 acc:56.43 | val loss:1.193 acc:81.80\r\n",
      "Epoch:0634 train loss:1.160 acc:57.14 | val loss:1.193 acc:82.00\r\n",
      "Epoch:0635 train loss:1.180 acc:57.86 | val loss:1.194 acc:82.20\r\n",
      "Epoch:0636 train loss:1.251 acc:54.29 | val loss:1.194 acc:82.20\r\n",
      "Epoch:0637 train loss:1.340 acc:49.29 | val loss:1.194 acc:82.00\r\n",
      "Epoch:0638 train loss:1.253 acc:52.14 | val loss:1.194 acc:82.40\r\n",
      "Epoch:0639 train loss:1.260 acc:49.29 | val loss:1.194 acc:82.80\r\n",
      "Epoch:0640 train loss:1.215 acc:55.71 | val loss:1.193 acc:82.60\r\n",
      "Epoch:0641 train loss:1.228 acc:57.14 | val loss:1.191 acc:82.60\r\n",
      "Epoch:0642 train loss:1.244 acc:55.71 | val loss:1.189 acc:82.20\r\n",
      "Epoch:0643 train loss:1.362 acc:44.29 | val loss:1.188 acc:81.80\r\n",
      "Epoch:0644 train loss:1.241 acc:59.29 | val loss:1.187 acc:81.80\r\n",
      "Epoch:0645 train loss:1.246 acc:56.43 | val loss:1.186 acc:82.00\r\n",
      "Epoch:0646 train loss:1.231 acc:55.00 | val loss:1.186 acc:82.20\r\n",
      "Epoch:0647 train loss:1.246 acc:60.00 | val loss:1.186 acc:81.80\r\n",
      "Epoch:0648 train loss:1.149 acc:61.43 | val loss:1.185 acc:81.80\r\n",
      "Epoch:0649 train loss:1.306 acc:51.43 | val loss:1.183 acc:81.60\r\n",
      "Epoch:0650 train loss:1.194 acc:54.29 | val loss:1.181 acc:82.00\r\n",
      "Epoch:0651 train loss:1.260 acc:55.71 | val loss:1.180 acc:82.00\r\n",
      "Epoch:0652 train loss:1.297 acc:47.14 | val loss:1.179 acc:81.60\r\n",
      "Epoch:0653 train loss:1.227 acc:50.00 | val loss:1.179 acc:81.40\r\n",
      "Epoch:0654 train loss:1.196 acc:55.71 | val loss:1.178 acc:81.40\r\n",
      "Epoch:0655 train loss:1.207 acc:62.14 | val loss:1.177 acc:81.40\r\n",
      "Epoch:0656 train loss:1.189 acc:55.71 | val loss:1.176 acc:81.40\r\n",
      "Epoch:0657 train loss:1.143 acc:68.57 | val loss:1.175 acc:81.40\r\n",
      "Epoch:0658 train loss:1.258 acc:58.57 | val loss:1.174 acc:81.40\r\n",
      "Epoch:0659 train loss:1.180 acc:61.43 | val loss:1.173 acc:81.40\r\n",
      "Epoch:0660 train loss:1.148 acc:59.29 | val loss:1.172 acc:82.00\r\n",
      "Epoch:0661 train loss:1.249 acc:53.57 | val loss:1.171 acc:82.20\r\n",
      "Epoch:0662 train loss:1.210 acc:54.29 | val loss:1.172 acc:82.60\r\n",
      "Epoch:0663 train loss:1.223 acc:52.14 | val loss:1.173 acc:82.60\r\n",
      "Epoch:0664 train loss:1.222 acc:58.57 | val loss:1.174 acc:82.60\r\n",
      "Epoch:0665 train loss:1.241 acc:52.14 | val loss:1.175 acc:82.60\r\n",
      "Epoch:0666 train loss:1.236 acc:54.29 | val loss:1.176 acc:82.80\r\n",
      "Epoch:0667 train loss:1.199 acc:50.00 | val loss:1.177 acc:82.60\r\n",
      "Epoch:0668 train loss:1.179 acc:55.71 | val loss:1.177 acc:83.00\r\n",
      "Epoch:0669 train loss:1.366 acc:50.00 | val loss:1.178 acc:82.80\r\n",
      "Epoch:0670 train loss:1.273 acc:52.14 | val loss:1.179 acc:82.20\r\n",
      "Epoch:0671 train loss:1.217 acc:58.57 | val loss:1.180 acc:82.20\r\n",
      "Epoch:0672 train loss:1.251 acc:49.29 | val loss:1.180 acc:82.00\r\n",
      "Epoch:0673 train loss:1.291 acc:54.29 | val loss:1.181 acc:82.20\r\n",
      "Epoch:0674 train loss:1.271 acc:52.14 | val loss:1.182 acc:82.00\r\n",
      "Epoch:0675 train loss:1.072 acc:59.29 | val loss:1.181 acc:82.00\r\n",
      "Epoch:0676 train loss:1.216 acc:53.57 | val loss:1.180 acc:81.80\r\n",
      "Epoch:0677 train loss:1.213 acc:53.57 | val loss:1.178 acc:81.80\r\n",
      "Epoch:0678 train loss:1.294 acc:47.86 | val loss:1.176 acc:81.80\r\n",
      "Epoch:0679 train loss:1.237 acc:55.00 | val loss:1.174 acc:82.00\r\n",
      "Epoch:0680 train loss:1.237 acc:51.43 | val loss:1.173 acc:82.00\r\n",
      "Epoch:0681 train loss:1.223 acc:55.71 | val loss:1.172 acc:81.80\r\n",
      "Epoch:0682 train loss:1.351 acc:47.86 | val loss:1.172 acc:81.80\r\n",
      "Epoch:0683 train loss:1.194 acc:55.71 | val loss:1.171 acc:82.20\r\n",
      "Epoch:0684 train loss:1.148 acc:56.43 | val loss:1.171 acc:82.60\r\n",
      "Epoch:0685 train loss:1.185 acc:62.14 | val loss:1.170 acc:83.00\r\n",
      "Epoch:0686 train loss:1.294 acc:48.57 | val loss:1.169 acc:82.80\r\n",
      "Epoch:0687 train loss:1.292 acc:55.00 | val loss:1.170 acc:82.60\r\n",
      "Epoch:0688 train loss:1.338 acc:47.86 | val loss:1.170 acc:82.40\r\n",
      "Epoch:0689 train loss:1.152 acc:56.43 | val loss:1.169 acc:82.20\r\n",
      "Epoch:0690 train loss:1.192 acc:50.00 | val loss:1.168 acc:82.00\r\n",
      "Epoch:0691 train loss:1.208 acc:56.43 | val loss:1.168 acc:82.00\r\n",
      "Epoch:0692 train loss:1.238 acc:49.29 | val loss:1.167 acc:82.00\r\n",
      "Epoch:0693 train loss:1.153 acc:62.14 | val loss:1.166 acc:82.20\r\n",
      "Epoch:0694 train loss:1.174 acc:61.43 | val loss:1.165 acc:82.60\r\n",
      "Epoch:0695 train loss:1.203 acc:54.29 | val loss:1.163 acc:82.80\r\n",
      "Epoch:0696 train loss:1.289 acc:50.71 | val loss:1.164 acc:82.80\r\n",
      "Epoch:0697 train loss:1.259 acc:51.43 | val loss:1.165 acc:83.40\r\n",
      "Epoch:0698 train loss:1.248 acc:52.86 | val loss:1.165 acc:83.20\r\n",
      "Epoch:0699 train loss:1.280 acc:51.43 | val loss:1.168 acc:83.20\r\n",
      "Epoch:0700 train loss:1.184 acc:61.43 | val loss:1.169 acc:83.00\r\n",
      "Epoch:0701 train loss:1.401 acc:47.14 | val loss:1.170 acc:83.00\r\n",
      "Epoch:0702 train loss:1.185 acc:58.57 | val loss:1.170 acc:83.20\r\n",
      "Epoch:0703 train loss:1.236 acc:58.57 | val loss:1.169 acc:83.00\r\n",
      "Epoch:0704 train loss:1.178 acc:57.86 | val loss:1.168 acc:83.00\r\n",
      "Epoch:0705 train loss:1.180 acc:57.14 | val loss:1.167 acc:83.60\r\n",
      "Epoch:0706 train loss:1.210 acc:57.86 | val loss:1.166 acc:83.40\r\n",
      "Epoch:0707 train loss:1.213 acc:57.86 | val loss:1.165 acc:83.40\r\n",
      "Epoch:0708 train loss:1.216 acc:55.71 | val loss:1.164 acc:83.00\r\n",
      "Epoch:0709 train loss:1.280 acc:57.86 | val loss:1.165 acc:83.00\r\n",
      "Epoch:0710 train loss:1.183 acc:57.14 | val loss:1.166 acc:83.20\r\n",
      "Epoch:0711 train loss:1.198 acc:59.29 | val loss:1.167 acc:83.40\r\n",
      "Epoch:0712 train loss:1.237 acc:56.43 | val loss:1.167 acc:82.80\r\n",
      "Epoch:0713 train loss:1.179 acc:52.14 | val loss:1.168 acc:82.60\r\n",
      "Epoch:0714 train loss:1.195 acc:55.00 | val loss:1.168 acc:82.20\r\n",
      "Epoch:0715 train loss:1.211 acc:62.14 | val loss:1.168 acc:82.00\r\n",
      "Epoch:0716 train loss:1.259 acc:52.86 | val loss:1.168 acc:82.20\r\n",
      "Epoch:0717 train loss:1.235 acc:51.43 | val loss:1.168 acc:82.20\r\n",
      "Epoch:0718 train loss:1.246 acc:55.71 | val loss:1.167 acc:82.20\r\n",
      "Epoch:0719 train loss:1.279 acc:52.14 | val loss:1.167 acc:82.20\r\n",
      "Epoch:0720 train loss:1.269 acc:52.14 | val loss:1.166 acc:82.60\r\n",
      "Epoch:0721 train loss:1.108 acc:63.57 | val loss:1.166 acc:82.40\r\n",
      "Epoch:0722 train loss:1.248 acc:57.86 | val loss:1.166 acc:82.40\r\n",
      "Epoch:0723 train loss:1.116 acc:64.29 | val loss:1.165 acc:82.40\r\n",
      "Epoch:0724 train loss:1.212 acc:55.71 | val loss:1.165 acc:82.40\r\n",
      "Epoch:0725 train loss:1.204 acc:56.43 | val loss:1.165 acc:82.60\r\n",
      "Epoch:0726 train loss:1.223 acc:52.14 | val loss:1.164 acc:82.60\r\n",
      "Epoch:0727 train loss:1.214 acc:57.86 | val loss:1.163 acc:82.60\r\n",
      "Epoch:0728 train loss:1.227 acc:55.00 | val loss:1.162 acc:82.60\r\n",
      "Epoch:0729 train loss:1.173 acc:58.57 | val loss:1.160 acc:82.40\r\n",
      "Epoch:0730 train loss:1.223 acc:59.29 | val loss:1.158 acc:82.40\r\n",
      "Epoch:0731 train loss:1.131 acc:56.43 | val loss:1.156 acc:82.80\r\n",
      "Epoch:0732 train loss:1.177 acc:57.86 | val loss:1.155 acc:82.80\r\n",
      "Epoch:0733 train loss:1.211 acc:50.71 | val loss:1.152 acc:82.80\r\n",
      "Epoch:0734 train loss:1.238 acc:54.29 | val loss:1.151 acc:82.40\r\n",
      "Epoch:0735 train loss:1.248 acc:54.29 | val loss:1.150 acc:82.60\r\n",
      "Epoch:0736 train loss:1.217 acc:52.86 | val loss:1.149 acc:82.80\r\n",
      "Epoch:0737 train loss:1.274 acc:45.71 | val loss:1.150 acc:82.80\r\n",
      "Epoch:0738 train loss:1.193 acc:56.43 | val loss:1.152 acc:82.80\r\n",
      "Epoch:0739 train loss:1.212 acc:55.00 | val loss:1.153 acc:82.40\r\n",
      "Epoch:0740 train loss:1.204 acc:58.57 | val loss:1.155 acc:82.60\r\n",
      "Epoch:0741 train loss:1.188 acc:51.43 | val loss:1.156 acc:82.80\r\n",
      "Epoch:0742 train loss:1.189 acc:54.29 | val loss:1.157 acc:82.40\r\n",
      "Epoch:0743 train loss:1.255 acc:56.43 | val loss:1.159 acc:82.80\r\n",
      "Epoch:0744 train loss:1.198 acc:57.86 | val loss:1.162 acc:82.40\r\n",
      "Epoch:0745 train loss:1.277 acc:50.00 | val loss:1.164 acc:82.20\r\n",
      "Epoch:0746 train loss:1.201 acc:58.57 | val loss:1.167 acc:81.80\r\n",
      "Epoch:0747 train loss:1.290 acc:49.29 | val loss:1.169 acc:81.60\r\n",
      "Epoch:0748 train loss:1.254 acc:55.71 | val loss:1.170 acc:82.40\r\n",
      "Epoch:0749 train loss:1.314 acc:49.29 | val loss:1.171 acc:82.00\r\n",
      "Epoch:0750 train loss:1.244 acc:60.00 | val loss:1.171 acc:82.20\r\n",
      "Epoch:0751 train loss:1.245 acc:58.57 | val loss:1.172 acc:82.20\r\n",
      "Epoch:0752 train loss:1.218 acc:54.29 | val loss:1.174 acc:82.40\r\n",
      "Epoch:0753 train loss:1.253 acc:54.29 | val loss:1.175 acc:82.40\r\n",
      "Epoch:0754 train loss:1.290 acc:55.71 | val loss:1.175 acc:82.60\r\n",
      "Epoch:0755 train loss:1.253 acc:55.71 | val loss:1.175 acc:82.60\r\n",
      "Epoch:0756 train loss:1.190 acc:54.29 | val loss:1.173 acc:82.40\r\n",
      "Epoch:0757 train loss:1.239 acc:53.57 | val loss:1.172 acc:83.20\r\n",
      "Epoch:0758 train loss:1.244 acc:55.00 | val loss:1.170 acc:83.60\r\n",
      "Epoch:0759 train loss:1.193 acc:58.57 | val loss:1.169 acc:84.00\r\n",
      "Epoch:0760 train loss:1.203 acc:60.00 | val loss:1.167 acc:84.20\r\n",
      "Epoch:0761 train loss:1.081 acc:62.86 | val loss:1.164 acc:84.00\r\n",
      "Epoch:0762 train loss:1.201 acc:64.29 | val loss:1.161 acc:83.60\r\n",
      "Epoch:0763 train loss:1.262 acc:56.43 | val loss:1.159 acc:83.60\r\n",
      "Epoch:0764 train loss:1.318 acc:47.86 | val loss:1.157 acc:83.20\r\n",
      "Epoch:0765 train loss:1.166 acc:56.43 | val loss:1.156 acc:83.60\r\n",
      "Epoch:0766 train loss:1.264 acc:51.43 | val loss:1.155 acc:83.20\r\n",
      "Epoch:0767 train loss:1.257 acc:52.14 | val loss:1.155 acc:83.40\r\n",
      "Epoch:0768 train loss:1.264 acc:50.00 | val loss:1.155 acc:83.20\r\n",
      "Epoch:0769 train loss:1.161 acc:58.57 | val loss:1.155 acc:83.00\r\n",
      "Epoch:0770 train loss:1.212 acc:52.86 | val loss:1.154 acc:83.40\r\n",
      "Epoch:0771 train loss:1.130 acc:62.86 | val loss:1.153 acc:83.80\r\n",
      "Epoch:0772 train loss:1.249 acc:54.29 | val loss:1.152 acc:83.60\r\n",
      "Epoch:0773 train loss:1.159 acc:55.00 | val loss:1.150 acc:83.80\r\n",
      "Epoch:0774 train loss:1.286 acc:53.57 | val loss:1.149 acc:83.80\r\n",
      "Epoch:0775 train loss:1.239 acc:52.86 | val loss:1.148 acc:83.80\r\n",
      "Epoch:0776 train loss:1.219 acc:52.14 | val loss:1.147 acc:83.60\r\n",
      "Epoch:0777 train loss:1.257 acc:53.57 | val loss:1.147 acc:83.40\r\n",
      "Epoch:0778 train loss:1.266 acc:50.71 | val loss:1.147 acc:83.40\r\n",
      "Epoch:0779 train loss:1.212 acc:57.14 | val loss:1.147 acc:83.00\r\n",
      "Epoch:0780 train loss:1.215 acc:54.29 | val loss:1.149 acc:83.00\r\n",
      "Epoch:0781 train loss:1.265 acc:55.00 | val loss:1.150 acc:82.80\r\n",
      "Epoch:0782 train loss:1.240 acc:53.57 | val loss:1.151 acc:82.80\r\n",
      "Epoch:0783 train loss:1.226 acc:58.57 | val loss:1.152 acc:83.20\r\n",
      "Epoch:0784 train loss:1.274 acc:52.14 | val loss:1.153 acc:83.00\r\n",
      "Epoch:0785 train loss:1.195 acc:58.57 | val loss:1.155 acc:82.80\r\n",
      "Epoch:0786 train loss:1.157 acc:59.29 | val loss:1.156 acc:82.80\r\n",
      "Epoch:0787 train loss:1.138 acc:59.29 | val loss:1.157 acc:82.60\r\n",
      "Epoch:0788 train loss:1.125 acc:62.14 | val loss:1.156 acc:82.00\r\n",
      "Epoch:0789 train loss:1.257 acc:49.29 | val loss:1.155 acc:82.00\r\n",
      "Epoch:0790 train loss:1.233 acc:52.14 | val loss:1.153 acc:82.80\r\n",
      "Epoch:0791 train loss:1.213 acc:55.71 | val loss:1.152 acc:83.00\r\n",
      "Epoch:0792 train loss:1.119 acc:62.14 | val loss:1.150 acc:83.20\r\n",
      "Epoch:0793 train loss:1.239 acc:57.86 | val loss:1.148 acc:83.00\r\n",
      "Epoch:0794 train loss:1.205 acc:59.29 | val loss:1.147 acc:82.80\r\n",
      "Epoch:0795 train loss:1.141 acc:60.71 | val loss:1.146 acc:82.60\r\n",
      "Epoch:0796 train loss:1.365 acc:55.00 | val loss:1.146 acc:82.80\r\n",
      "Epoch:0797 train loss:1.229 acc:55.71 | val loss:1.146 acc:82.60\r\n",
      "Epoch:0798 train loss:1.132 acc:59.29 | val loss:1.146 acc:82.80\r\n",
      "Epoch:0799 train loss:1.220 acc:52.86 | val loss:1.146 acc:82.80\r\n",
      "Epoch:0800 train loss:1.227 acc:58.57 | val loss:1.147 acc:82.80\r\n",
      "Epoch:0801 train loss:1.184 acc:53.57 | val loss:1.148 acc:82.20\r\n",
      "Epoch:0802 train loss:1.243 acc:54.29 | val loss:1.148 acc:82.40\r\n",
      "Epoch:0803 train loss:1.232 acc:55.71 | val loss:1.149 acc:82.40\r\n",
      "Epoch:0804 train loss:1.256 acc:56.43 | val loss:1.149 acc:82.60\r\n",
      "Epoch:0805 train loss:1.252 acc:53.57 | val loss:1.149 acc:82.60\r\n",
      "Epoch:0806 train loss:1.175 acc:55.71 | val loss:1.150 acc:82.60\r\n",
      "Epoch:0807 train loss:1.155 acc:56.43 | val loss:1.150 acc:82.60\r\n",
      "Epoch:0808 train loss:1.329 acc:47.14 | val loss:1.149 acc:82.60\r\n",
      "Epoch:0809 train loss:1.306 acc:47.86 | val loss:1.149 acc:82.80\r\n",
      "Epoch:0810 train loss:1.141 acc:60.00 | val loss:1.149 acc:83.40\r\n",
      "Epoch:0811 train loss:1.179 acc:57.14 | val loss:1.148 acc:83.40\r\n",
      "Epoch:0812 train loss:1.210 acc:50.71 | val loss:1.146 acc:83.80\r\n",
      "Epoch:0813 train loss:1.205 acc:50.71 | val loss:1.144 acc:83.60\r\n",
      "Epoch:0814 train loss:1.217 acc:53.57 | val loss:1.142 acc:82.80\r\n",
      "Epoch:0815 train loss:1.196 acc:54.29 | val loss:1.141 acc:82.40\r\n",
      "Epoch:0816 train loss:1.175 acc:56.43 | val loss:1.140 acc:82.40\r\n",
      "Epoch:0817 train loss:1.212 acc:53.57 | val loss:1.139 acc:82.00\r\n",
      "Epoch:0818 train loss:1.144 acc:57.14 | val loss:1.138 acc:82.20\r\n",
      "Epoch:0819 train loss:1.188 acc:55.71 | val loss:1.136 acc:82.20\r\n",
      "Epoch:0820 train loss:1.240 acc:55.00 | val loss:1.134 acc:82.00\r\n",
      "Epoch:0821 train loss:1.123 acc:62.86 | val loss:1.133 acc:82.20\r\n",
      "Epoch:0822 train loss:1.268 acc:53.57 | val loss:1.132 acc:82.20\r\n",
      "Epoch:0823 train loss:1.202 acc:55.71 | val loss:1.132 acc:82.20\r\n",
      "Epoch:0824 train loss:1.216 acc:57.86 | val loss:1.132 acc:82.60\r\n",
      "Epoch:0825 train loss:1.166 acc:58.57 | val loss:1.131 acc:82.80\r\n",
      "Epoch:0826 train loss:1.195 acc:58.57 | val loss:1.130 acc:82.80\r\n",
      "Epoch:0827 train loss:1.169 acc:57.14 | val loss:1.130 acc:82.80\r\n",
      "Epoch:0828 train loss:1.165 acc:55.00 | val loss:1.131 acc:82.80\r\n",
      "Epoch:0829 train loss:1.224 acc:54.29 | val loss:1.133 acc:83.00\r\n",
      "Epoch:0830 train loss:1.274 acc:52.14 | val loss:1.134 acc:83.00\r\n",
      "Epoch:0831 train loss:1.184 acc:59.29 | val loss:1.135 acc:83.40\r\n",
      "Epoch:0832 train loss:1.196 acc:59.29 | val loss:1.137 acc:83.80\r\n",
      "Epoch:0833 train loss:1.210 acc:52.14 | val loss:1.138 acc:84.00\r\n",
      "Epoch:0834 train loss:1.151 acc:57.86 | val loss:1.138 acc:84.60\r\n",
      "Epoch:0835 train loss:1.239 acc:50.71 | val loss:1.139 acc:84.20\r\n",
      "Epoch:0836 train loss:1.242 acc:55.00 | val loss:1.141 acc:84.00\r\n",
      "Epoch:0837 train loss:1.216 acc:55.00 | val loss:1.141 acc:83.80\r\n",
      "Epoch:0838 train loss:1.201 acc:55.71 | val loss:1.142 acc:83.60\r\n",
      "Epoch:0839 train loss:1.187 acc:59.29 | val loss:1.142 acc:83.80\r\n",
      "Epoch:0840 train loss:1.106 acc:60.00 | val loss:1.142 acc:83.60\r\n",
      "Epoch:0841 train loss:1.235 acc:53.57 | val loss:1.142 acc:83.80\r\n",
      "Epoch:0842 train loss:1.161 acc:64.29 | val loss:1.142 acc:83.80\r\n",
      "Epoch:0843 train loss:1.232 acc:58.57 | val loss:1.141 acc:83.80\r\n",
      "Epoch:0844 train loss:1.211 acc:55.71 | val loss:1.139 acc:84.00\r\n",
      "Epoch:0845 train loss:1.214 acc:52.14 | val loss:1.138 acc:84.00\r\n",
      "Epoch:0846 train loss:1.193 acc:52.86 | val loss:1.136 acc:83.40\r\n",
      "Epoch:0847 train loss:1.252 acc:54.29 | val loss:1.135 acc:83.20\r\n",
      "Epoch:0848 train loss:1.160 acc:62.14 | val loss:1.134 acc:83.00\r\n",
      "Epoch:0849 train loss:1.234 acc:53.57 | val loss:1.134 acc:82.80\r\n",
      "Epoch:0850 train loss:1.145 acc:59.29 | val loss:1.133 acc:82.60\r\n",
      "Epoch:0851 train loss:1.180 acc:61.43 | val loss:1.132 acc:83.00\r\n",
      "Epoch:0852 train loss:1.212 acc:55.71 | val loss:1.132 acc:82.40\r\n",
      "Epoch:0853 train loss:1.251 acc:53.57 | val loss:1.133 acc:81.80\r\n",
      "Epoch:0854 train loss:1.279 acc:52.86 | val loss:1.133 acc:81.60\r\n",
      "Epoch:0855 train loss:1.235 acc:55.71 | val loss:1.133 acc:81.60\r\n",
      "Epoch:0856 train loss:1.185 acc:57.86 | val loss:1.134 acc:81.80\r\n",
      "Epoch:0857 train loss:1.096 acc:59.29 | val loss:1.133 acc:81.60\r\n",
      "Epoch:0858 train loss:1.240 acc:61.43 | val loss:1.133 acc:82.20\r\n",
      "Epoch:0859 train loss:1.223 acc:57.14 | val loss:1.133 acc:82.20\r\n",
      "Epoch:0860 train loss:1.181 acc:57.14 | val loss:1.132 acc:82.20\r\n",
      "Epoch:0861 train loss:1.143 acc:59.29 | val loss:1.133 acc:82.00\r\n",
      "Epoch:0862 train loss:1.225 acc:55.00 | val loss:1.133 acc:81.60\r\n",
      "Epoch:0863 train loss:1.231 acc:55.00 | val loss:1.134 acc:81.40\r\n",
      "Epoch:0864 train loss:1.193 acc:54.29 | val loss:1.135 acc:81.60\r\n",
      "Epoch:0865 train loss:1.158 acc:58.57 | val loss:1.135 acc:81.80\r\n",
      "Epoch:0866 train loss:1.189 acc:60.00 | val loss:1.136 acc:81.80\r\n",
      "Epoch:0867 train loss:1.269 acc:55.00 | val loss:1.138 acc:81.80\r\n",
      "Epoch:0868 train loss:1.101 acc:64.29 | val loss:1.139 acc:82.00\r\n",
      "Epoch:0869 train loss:1.225 acc:53.57 | val loss:1.141 acc:82.40\r\n",
      "Epoch:0870 train loss:1.243 acc:52.14 | val loss:1.142 acc:82.60\r\n",
      "Epoch:0871 train loss:1.222 acc:48.57 | val loss:1.143 acc:82.80\r\n",
      "Epoch:0872 train loss:1.106 acc:57.86 | val loss:1.143 acc:83.20\r\n",
      "Epoch:0873 train loss:1.229 acc:57.14 | val loss:1.142 acc:82.80\r\n",
      "Epoch:0874 train loss:1.247 acc:50.00 | val loss:1.142 acc:82.60\r\n",
      "Epoch:0875 train loss:1.126 acc:56.43 | val loss:1.141 acc:82.20\r\n",
      "Epoch:0876 train loss:1.203 acc:56.43 | val loss:1.140 acc:82.60\r\n",
      "Epoch:0877 train loss:1.186 acc:57.86 | val loss:1.139 acc:82.60\r\n",
      "Epoch:0878 train loss:1.333 acc:55.00 | val loss:1.139 acc:82.20\r\n",
      "Epoch:0879 train loss:1.300 acc:50.00 | val loss:1.139 acc:82.40\r\n",
      "Epoch:0880 train loss:1.161 acc:60.00 | val loss:1.138 acc:82.20\r\n",
      "Epoch:0881 train loss:1.157 acc:57.86 | val loss:1.137 acc:82.20\r\n",
      "Epoch:0882 train loss:1.230 acc:52.86 | val loss:1.138 acc:81.80\r\n",
      "Epoch:0883 train loss:1.205 acc:57.86 | val loss:1.138 acc:82.00\r\n",
      "Load 827th epoch\r\n",
      "Test acc.:87.2\r\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "best_test_acc_list=[]\n",
    "for k in range(repeat):\n",
    "    if best_al==0 and best_variant==0:\n",
    "        !python -u trainshow.py --data cora --layer {best_num_layers} --hidden {best_hidden_dim} --dropout {best_dropout} --wd1 {best_weight_decay_1} --wd2 {best_weight_decay_2} --lr {best_lr} --op {best_optim}  --act_fn {best_act} --epochs  {best_epoch1} --patience {best_earlystop} --test  \n",
    "    elif best_al==1 and best_variant==0:\n",
    "        !python -u trainshow.py --data cora --layer {best_num_layers} --hidden {best_hidden_dim} --dropout {best_dropout} --wd1 {best_weight_decay_1} --wd2 {best_weight_decay_2} --lr {best_lr} --op {best_optim}  --act_fn {best_act} --epochs  {best_epoch1} --patience {best_earlystop} --lamda {best_lamda} --alpha {best_alpha} --test  \n",
    "    elif best_al==0 and best_variant==1:\n",
    "        !python -u trainshow.py --data cora --layer {best_num_layers} --hidden {best_hidden_dim} --dropout {best_dropout} --wd1 {best_weight_decay_1} --wd2 {best_weight_decay_2} --lr {best_lr} --op {best_optim}  --act_fn {best_act} --epochs  {best_epoch1} --patience {best_earlystop} --test --variant  \n",
    "    else:\n",
    "        !python -u trainshow.py --data cora --layer {best_num_layers} --hidden {best_hidden_dim} --dropout {best_dropout} --wd1 {best_weight_decay_1} --wd2 {best_weight_decay_2} --lr {best_lr} --op {best_optim}  --act_fn {best_act} --epochs  {best_epoch1} --patience {best_earlystop} --lamda {best_lamda} --alpha {best_alpha} --test --variant  \n",
    "end_time=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2444fca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T11:56:21.423807Z",
     "iopub.status.busy": "2024-04-21T11:56:21.423433Z",
     "iopub.status.idle": "2024-04-21T11:56:21.431403Z",
     "shell.execute_reply": "2024-04-21T11:56:21.430580Z"
    },
    "papermill": {
     "duration": 0.089182,
     "end_time": "2024-04-21T11:56:21.433687",
     "exception": false,
     "start_time": "2024-04-21T11:56:21.344505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora\n",
      "best_num_layers: 34\n",
      "best_optim: 0\n",
      "best_al: 0\n",
      "best_act: 0\n",
      "best_earlystop: 56\n",
      "best_epoch1: 949\n",
      "best_hidden_dim: 9\n",
      "best_variant: 0\n",
      "---------\n",
      "best_alpha: 0.3489076699438276\n",
      "best_lamda: 0.661000220102601\n",
      "best_dropout: 0.49805857303652107\n",
      "best_lr: 0.0070093416540903675\n",
      "best_weight_decay_1: 0.0450432794537762\n",
      "best_weight_decay_2: 0.0003689346079284098\n",
      "---------\n",
      ": 65.81245994567871\n"
     ]
    }
   ],
   "source": [
    "print(\"cora\")\n",
    "print(f\"best_num_layers: {best_num_layers}\")\n",
    "print(f\"best_optim: {best_optim}\")\n",
    "print(f\"best_al: {best_al}\")\n",
    "print(f\"best_act: {best_act}\")\n",
    "print(f\"best_earlystop: {best_earlystop}\")\n",
    "print(f\"best_epoch1: {best_epoch1}\")\n",
    "print(f\"best_hidden_dim: {best_hidden_dim}\")\n",
    "print(f\"best_variant: {best_variant}\")\n",
    "print(\"---------\")\n",
    "print(f\"best_alpha: {best_alpha}\")\n",
    "print(f\"best_lamda: {best_lamda}\")\n",
    "print(f\"best_dropout: {best_dropout}\")\n",
    "print(f\"best_lr: {best_lr}\")\n",
    "print(f\"best_weight_decay_1: {best_weight_decay_1}\")\n",
    "print(f\"best_weight_decay_2: {best_weight_decay_2}\")\n",
    "print(\"---------\")\n",
    "import numpy as np\n",
    "print(\":\", (end_time-start_time)/repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ad610f",
   "metadata": {
    "papermill": {
     "duration": 0.081588,
     "end_time": "2024-04-21T11:56:21.592763",
     "exception": false,
     "start_time": "2024-04-21T11:56:21.511175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "for citeseer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9240c474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T11:56:21.796159Z",
     "iopub.status.busy": "2024-04-21T11:56:21.795780Z",
     "iopub.status.idle": "2024-04-21T11:56:21.801037Z",
     "shell.execute_reply": "2024-04-21T11:56:21.800140Z"
    },
    "papermill": {
     "duration": 0.129821,
     "end_time": "2024-04-21T11:56:21.803096",
     "exception": false,
     "start_time": "2024-04-21T11:56:21.673275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a=(62, 0, 1, 0, 552, 1554, 121, 1, 0.195334309177027, 0.48615645105443256, 0.7386975650911543, 0.020170958845385403, 0.01569140756748541, 0.0005012998933592893)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e83f7749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T11:56:21.960936Z",
     "iopub.status.busy": "2024-04-21T11:56:21.960599Z",
     "iopub.status.idle": "2024-04-21T11:58:23.980638Z",
     "shell.execute_reply": "2024-04-21T11:58:23.979654Z"
    },
    "papermill": {
     "duration": 122.101948,
     "end_time": "2024-04-21T11:58:23.982965",
     "exception": false,
     "start_time": "2024-04-21T11:56:21.881017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0000 train loss:1.791 acc:15.00 | val loss:1.793 acc:17.20\r\n",
      "Epoch:0001 train loss:1.793 acc:19.17 | val loss:1.789 acc:30.40\r\n",
      "Epoch:0002 train loss:1.784 acc:15.83 | val loss:1.786 acc:18.80\r\n",
      "Epoch:0003 train loss:1.788 acc:18.33 | val loss:1.783 acc:30.60\r\n",
      "Epoch:0004 train loss:1.784 acc:28.33 | val loss:1.780 acc:34.60\r\n",
      "Epoch:0005 train loss:1.806 acc:22.50 | val loss:1.779 acc:35.80\r\n",
      "Epoch:0006 train loss:1.782 acc:25.00 | val loss:1.777 acc:39.80\r\n",
      "Epoch:0007 train loss:1.777 acc:23.33 | val loss:1.775 acc:40.40\r\n",
      "Epoch:0008 train loss:1.792 acc:23.33 | val loss:1.773 acc:48.20\r\n",
      "Epoch:0009 train loss:1.792 acc:26.67 | val loss:1.772 acc:33.20\r\n",
      "Epoch:0010 train loss:1.820 acc:25.00 | val loss:1.770 acc:28.40\r\n",
      "Epoch:0011 train loss:1.825 acc:29.17 | val loss:1.768 acc:33.00\r\n",
      "Epoch:0012 train loss:1.764 acc:23.33 | val loss:1.765 acc:41.20\r\n",
      "Epoch:0013 train loss:1.769 acc:29.17 | val loss:1.762 acc:50.60\r\n",
      "Epoch:0014 train loss:1.747 acc:30.00 | val loss:1.759 acc:50.00\r\n",
      "Epoch:0015 train loss:1.744 acc:30.83 | val loss:1.755 acc:48.80\r\n",
      "Epoch:0016 train loss:1.756 acc:26.67 | val loss:1.752 acc:53.20\r\n",
      "Epoch:0017 train loss:1.721 acc:30.00 | val loss:1.750 acc:58.20\r\n",
      "Epoch:0018 train loss:1.742 acc:31.67 | val loss:1.747 acc:60.20\r\n",
      "Epoch:0019 train loss:1.698 acc:43.33 | val loss:1.744 acc:57.60\r\n",
      "Epoch:0020 train loss:1.748 acc:35.83 | val loss:1.740 acc:59.80\r\n",
      "Epoch:0021 train loss:1.717 acc:36.67 | val loss:1.735 acc:58.20\r\n",
      "Epoch:0022 train loss:1.719 acc:43.33 | val loss:1.730 acc:55.20\r\n",
      "Epoch:0023 train loss:1.696 acc:36.67 | val loss:1.725 acc:50.40\r\n",
      "Epoch:0024 train loss:1.734 acc:33.33 | val loss:1.723 acc:49.20\r\n",
      "Epoch:0025 train loss:1.688 acc:27.50 | val loss:1.721 acc:46.40\r\n",
      "Epoch:0026 train loss:1.745 acc:35.00 | val loss:1.718 acc:43.00\r\n",
      "Epoch:0027 train loss:1.695 acc:36.67 | val loss:1.714 acc:45.00\r\n",
      "Epoch:0028 train loss:1.735 acc:32.50 | val loss:1.708 acc:52.00\r\n",
      "Epoch:0029 train loss:1.668 acc:45.00 | val loss:1.700 acc:59.20\r\n",
      "Epoch:0030 train loss:1.692 acc:43.33 | val loss:1.691 acc:66.80\r\n",
      "Epoch:0031 train loss:1.684 acc:35.83 | val loss:1.681 acc:67.00\r\n",
      "Epoch:0032 train loss:1.774 acc:40.00 | val loss:1.674 acc:66.20\r\n",
      "Epoch:0033 train loss:1.669 acc:38.33 | val loss:1.669 acc:63.40\r\n",
      "Epoch:0034 train loss:1.635 acc:42.50 | val loss:1.665 acc:63.80\r\n",
      "Epoch:0035 train loss:1.680 acc:45.00 | val loss:1.663 acc:66.20\r\n",
      "Epoch:0036 train loss:1.628 acc:44.17 | val loss:1.663 acc:69.00\r\n",
      "Epoch:0037 train loss:1.663 acc:35.83 | val loss:1.663 acc:67.00\r\n",
      "Epoch:0038 train loss:1.637 acc:35.00 | val loss:1.661 acc:63.00\r\n",
      "Epoch:0039 train loss:1.590 acc:42.50 | val loss:1.657 acc:63.00\r\n",
      "Epoch:0040 train loss:1.553 acc:47.50 | val loss:1.651 acc:63.60\r\n",
      "Epoch:0041 train loss:1.585 acc:47.50 | val loss:1.643 acc:65.60\r\n",
      "Epoch:0042 train loss:1.575 acc:53.33 | val loss:1.635 acc:66.00\r\n",
      "Epoch:0043 train loss:1.578 acc:47.50 | val loss:1.624 acc:69.20\r\n",
      "Epoch:0044 train loss:1.542 acc:52.50 | val loss:1.617 acc:70.00\r\n",
      "Epoch:0045 train loss:1.546 acc:46.67 | val loss:1.610 acc:70.20\r\n",
      "Epoch:0046 train loss:1.601 acc:46.67 | val loss:1.605 acc:69.60\r\n",
      "Epoch:0047 train loss:1.609 acc:47.50 | val loss:1.601 acc:69.20\r\n",
      "Epoch:0048 train loss:1.535 acc:47.50 | val loss:1.598 acc:69.40\r\n",
      "Epoch:0049 train loss:1.520 acc:50.00 | val loss:1.595 acc:69.40\r\n",
      "Epoch:0050 train loss:1.532 acc:42.50 | val loss:1.591 acc:68.60\r\n",
      "Epoch:0051 train loss:1.581 acc:46.67 | val loss:1.588 acc:68.00\r\n",
      "Epoch:0052 train loss:1.711 acc:47.50 | val loss:1.583 acc:68.20\r\n",
      "Epoch:0053 train loss:1.520 acc:45.00 | val loss:1.576 acc:68.80\r\n",
      "Epoch:0054 train loss:1.517 acc:45.83 | val loss:1.570 acc:68.00\r\n",
      "Epoch:0055 train loss:1.446 acc:51.67 | val loss:1.565 acc:67.00\r\n",
      "Epoch:0056 train loss:1.492 acc:48.33 | val loss:1.560 acc:67.40\r\n",
      "Epoch:0057 train loss:1.456 acc:47.50 | val loss:1.551 acc:68.80\r\n",
      "Epoch:0058 train loss:1.421 acc:53.33 | val loss:1.541 acc:70.80\r\n",
      "Epoch:0059 train loss:1.479 acc:49.17 | val loss:1.531 acc:71.80\r\n",
      "Epoch:0060 train loss:1.522 acc:52.50 | val loss:1.520 acc:71.40\r\n",
      "Epoch:0061 train loss:1.517 acc:47.50 | val loss:1.512 acc:70.20\r\n",
      "Epoch:0062 train loss:1.514 acc:52.50 | val loss:1.505 acc:69.00\r\n",
      "Epoch:0063 train loss:1.500 acc:45.00 | val loss:1.498 acc:68.20\r\n",
      "Epoch:0064 train loss:1.529 acc:53.33 | val loss:1.493 acc:68.20\r\n",
      "Epoch:0065 train loss:1.501 acc:50.00 | val loss:1.490 acc:67.80\r\n",
      "Epoch:0066 train loss:1.458 acc:52.50 | val loss:1.489 acc:69.20\r\n",
      "Epoch:0067 train loss:1.519 acc:50.83 | val loss:1.492 acc:69.00\r\n",
      "Epoch:0068 train loss:1.437 acc:54.17 | val loss:1.496 acc:69.00\r\n",
      "Epoch:0069 train loss:1.463 acc:53.33 | val loss:1.500 acc:68.00\r\n",
      "Epoch:0070 train loss:1.380 acc:52.50 | val loss:1.501 acc:67.40\r\n",
      "Epoch:0071 train loss:1.465 acc:51.67 | val loss:1.499 acc:66.20\r\n",
      "Epoch:0072 train loss:1.322 acc:58.33 | val loss:1.498 acc:65.80\r\n",
      "Epoch:0073 train loss:1.348 acc:56.67 | val loss:1.494 acc:67.20\r\n",
      "Epoch:0074 train loss:1.355 acc:55.83 | val loss:1.486 acc:67.80\r\n",
      "Epoch:0075 train loss:1.425 acc:48.33 | val loss:1.478 acc:67.80\r\n",
      "Epoch:0076 train loss:1.397 acc:48.33 | val loss:1.471 acc:68.60\r\n",
      "Epoch:0077 train loss:1.350 acc:52.50 | val loss:1.464 acc:68.20\r\n",
      "Epoch:0078 train loss:1.581 acc:57.50 | val loss:1.461 acc:67.40\r\n",
      "Epoch:0079 train loss:1.431 acc:49.17 | val loss:1.457 acc:67.40\r\n",
      "Epoch:0080 train loss:1.446 acc:51.67 | val loss:1.455 acc:68.40\r\n",
      "Epoch:0081 train loss:1.384 acc:53.33 | val loss:1.457 acc:68.20\r\n",
      "Epoch:0082 train loss:1.452 acc:47.50 | val loss:1.460 acc:68.00\r\n",
      "Epoch:0083 train loss:1.518 acc:50.83 | val loss:1.464 acc:68.20\r\n",
      "Epoch:0084 train loss:1.300 acc:48.33 | val loss:1.467 acc:68.40\r\n",
      "Epoch:0085 train loss:1.398 acc:54.17 | val loss:1.472 acc:68.60\r\n",
      "Epoch:0086 train loss:1.353 acc:58.33 | val loss:1.473 acc:68.40\r\n",
      "Epoch:0087 train loss:1.454 acc:45.00 | val loss:1.477 acc:67.60\r\n",
      "Epoch:0088 train loss:1.318 acc:59.17 | val loss:1.476 acc:67.00\r\n",
      "Epoch:0089 train loss:1.359 acc:63.33 | val loss:1.475 acc:67.20\r\n",
      "Epoch:0090 train loss:1.423 acc:51.67 | val loss:1.473 acc:67.20\r\n",
      "Epoch:0091 train loss:1.352 acc:57.50 | val loss:1.470 acc:67.60\r\n",
      "Epoch:0092 train loss:1.400 acc:58.33 | val loss:1.471 acc:67.00\r\n",
      "Epoch:0093 train loss:1.352 acc:55.00 | val loss:1.467 acc:67.20\r\n",
      "Epoch:0094 train loss:1.516 acc:48.33 | val loss:1.462 acc:67.00\r\n",
      "Epoch:0095 train loss:1.387 acc:57.50 | val loss:1.454 acc:67.40\r\n",
      "Epoch:0096 train loss:1.332 acc:51.67 | val loss:1.445 acc:67.80\r\n",
      "Epoch:0097 train loss:1.321 acc:60.83 | val loss:1.433 acc:70.00\r\n",
      "Epoch:0098 train loss:1.956 acc:54.17 | val loss:1.428 acc:71.20\r\n",
      "Epoch:0099 train loss:1.308 acc:59.17 | val loss:1.424 acc:70.80\r\n",
      "Epoch:0100 train loss:1.371 acc:53.33 | val loss:1.421 acc:71.80\r\n",
      "Epoch:0101 train loss:1.292 acc:54.17 | val loss:1.418 acc:71.00\r\n",
      "Epoch:0102 train loss:1.345 acc:55.00 | val loss:1.412 acc:71.80\r\n",
      "Epoch:0103 train loss:1.362 acc:53.33 | val loss:1.409 acc:72.40\r\n",
      "Epoch:0104 train loss:2.059 acc:56.67 | val loss:1.408 acc:72.60\r\n",
      "Epoch:0105 train loss:1.298 acc:57.50 | val loss:1.410 acc:72.40\r\n",
      "Epoch:0106 train loss:1.309 acc:61.67 | val loss:1.414 acc:71.60\r\n",
      "Epoch:0107 train loss:1.265 acc:61.67 | val loss:1.417 acc:71.20\r\n",
      "Epoch:0108 train loss:1.257 acc:58.33 | val loss:1.420 acc:69.80\r\n",
      "Epoch:0109 train loss:1.419 acc:62.50 | val loss:1.428 acc:68.80\r\n",
      "Epoch:0110 train loss:1.401 acc:65.00 | val loss:1.436 acc:66.80\r\n",
      "Epoch:0111 train loss:1.362 acc:54.17 | val loss:1.443 acc:66.20\r\n",
      "Epoch:0112 train loss:1.336 acc:55.00 | val loss:1.448 acc:65.80\r\n",
      "Epoch:0113 train loss:1.214 acc:64.17 | val loss:1.449 acc:65.60\r\n",
      "Epoch:0114 train loss:1.341 acc:59.17 | val loss:1.446 acc:67.40\r\n",
      "Epoch:0115 train loss:1.340 acc:57.50 | val loss:1.434 acc:68.20\r\n",
      "Epoch:0116 train loss:1.308 acc:60.83 | val loss:1.422 acc:68.40\r\n",
      "Epoch:0117 train loss:1.355 acc:66.67 | val loss:1.414 acc:69.20\r\n",
      "Epoch:0118 train loss:1.314 acc:58.33 | val loss:1.409 acc:69.60\r\n",
      "Epoch:0119 train loss:1.205 acc:65.83 | val loss:1.403 acc:70.40\r\n",
      "Epoch:0120 train loss:1.235 acc:60.83 | val loss:1.399 acc:70.40\r\n",
      "Epoch:0121 train loss:1.217 acc:59.17 | val loss:1.394 acc:69.80\r\n",
      "Epoch:0122 train loss:1.330 acc:55.00 | val loss:1.386 acc:71.80\r\n",
      "Epoch:0123 train loss:1.246 acc:54.17 | val loss:1.380 acc:71.00\r\n",
      "Epoch:0124 train loss:1.312 acc:53.33 | val loss:1.377 acc:71.00\r\n",
      "Epoch:0125 train loss:1.287 acc:50.00 | val loss:1.372 acc:71.40\r\n",
      "Epoch:0126 train loss:1.160 acc:58.33 | val loss:1.367 acc:71.80\r\n",
      "Epoch:0127 train loss:1.267 acc:60.00 | val loss:1.362 acc:71.80\r\n",
      "Epoch:0128 train loss:1.391 acc:49.17 | val loss:1.358 acc:71.80\r\n",
      "Epoch:0129 train loss:1.496 acc:55.00 | val loss:1.356 acc:72.00\r\n",
      "Epoch:0130 train loss:1.186 acc:65.83 | val loss:1.354 acc:71.80\r\n",
      "Epoch:0131 train loss:1.291 acc:53.33 | val loss:1.356 acc:72.00\r\n",
      "Epoch:0132 train loss:1.396 acc:53.33 | val loss:1.360 acc:72.60\r\n",
      "Epoch:0133 train loss:1.210 acc:60.83 | val loss:1.366 acc:72.40\r\n",
      "Epoch:0134 train loss:1.506 acc:56.67 | val loss:1.382 acc:71.20\r\n",
      "Epoch:0135 train loss:1.302 acc:55.83 | val loss:1.396 acc:69.40\r\n",
      "Epoch:0136 train loss:1.216 acc:59.17 | val loss:1.407 acc:68.00\r\n",
      "Epoch:0137 train loss:1.263 acc:57.50 | val loss:1.415 acc:67.20\r\n",
      "Epoch:0138 train loss:1.276 acc:55.83 | val loss:1.422 acc:66.60\r\n",
      "Epoch:0139 train loss:1.246 acc:63.33 | val loss:1.422 acc:66.60\r\n",
      "Epoch:0140 train loss:1.216 acc:65.83 | val loss:1.419 acc:66.40\r\n",
      "Epoch:0141 train loss:1.246 acc:55.83 | val loss:1.418 acc:65.80\r\n",
      "Epoch:0142 train loss:1.255 acc:60.00 | val loss:1.414 acc:66.40\r\n",
      "Epoch:0143 train loss:1.266 acc:56.67 | val loss:1.407 acc:68.40\r\n",
      "Epoch:0144 train loss:1.250 acc:66.67 | val loss:1.396 acc:70.20\r\n",
      "Epoch:0145 train loss:1.314 acc:54.17 | val loss:1.391 acc:70.40\r\n",
      "Epoch:0146 train loss:1.177 acc:65.00 | val loss:1.386 acc:70.00\r\n",
      "Epoch:0147 train loss:1.255 acc:58.33 | val loss:1.382 acc:70.40\r\n",
      "Epoch:0148 train loss:1.348 acc:65.00 | val loss:1.386 acc:69.20\r\n",
      "Epoch:0149 train loss:1.285 acc:60.83 | val loss:1.391 acc:69.40\r\n",
      "Epoch:0150 train loss:1.492 acc:63.33 | val loss:1.389 acc:69.20\r\n",
      "Epoch:0151 train loss:1.210 acc:56.67 | val loss:1.382 acc:68.20\r\n",
      "Epoch:0152 train loss:1.492 acc:52.50 | val loss:1.374 acc:69.00\r\n",
      "Epoch:0153 train loss:1.309 acc:57.50 | val loss:1.369 acc:69.60\r\n",
      "Epoch:0154 train loss:1.213 acc:67.50 | val loss:1.365 acc:71.00\r\n",
      "Epoch:0155 train loss:1.164 acc:62.50 | val loss:1.361 acc:72.00\r\n",
      "Epoch:0156 train loss:1.314 acc:51.67 | val loss:1.361 acc:70.80\r\n",
      "Epoch:0157 train loss:1.238 acc:60.00 | val loss:1.359 acc:70.60\r\n",
      "Epoch:0158 train loss:1.195 acc:65.00 | val loss:1.358 acc:70.80\r\n",
      "Epoch:0159 train loss:1.254 acc:60.00 | val loss:1.359 acc:69.80\r\n",
      "Epoch:0160 train loss:1.424 acc:55.00 | val loss:1.364 acc:69.60\r\n",
      "Epoch:0161 train loss:1.261 acc:61.67 | val loss:1.368 acc:68.80\r\n",
      "Epoch:0162 train loss:1.220 acc:56.67 | val loss:1.371 acc:68.00\r\n",
      "Epoch:0163 train loss:1.197 acc:58.33 | val loss:1.375 acc:66.80\r\n",
      "Epoch:0164 train loss:1.262 acc:62.50 | val loss:1.378 acc:66.00\r\n",
      "Epoch:0165 train loss:1.212 acc:61.67 | val loss:1.379 acc:66.40\r\n",
      "Epoch:0166 train loss:1.210 acc:61.67 | val loss:1.382 acc:67.40\r\n",
      "Epoch:0167 train loss:1.254 acc:61.67 | val loss:1.383 acc:67.40\r\n",
      "Epoch:0168 train loss:1.258 acc:56.67 | val loss:1.381 acc:68.60\r\n",
      "Epoch:0169 train loss:1.278 acc:57.50 | val loss:1.379 acc:69.00\r\n",
      "Epoch:0170 train loss:1.234 acc:60.83 | val loss:1.378 acc:69.00\r\n",
      "Epoch:0171 train loss:1.261 acc:60.00 | val loss:1.374 acc:68.60\r\n",
      "Epoch:0172 train loss:1.214 acc:62.50 | val loss:1.369 acc:69.40\r\n",
      "Epoch:0173 train loss:1.193 acc:60.00 | val loss:1.364 acc:69.20\r\n",
      "Epoch:0174 train loss:1.134 acc:69.17 | val loss:1.358 acc:69.00\r\n",
      "Epoch:0175 train loss:1.158 acc:66.67 | val loss:1.351 acc:70.20\r\n",
      "Epoch:0176 train loss:1.195 acc:67.50 | val loss:1.346 acc:70.40\r\n",
      "Epoch:0177 train loss:1.399 acc:58.33 | val loss:1.340 acc:71.00\r\n",
      "Epoch:0178 train loss:1.242 acc:64.17 | val loss:1.335 acc:70.60\r\n",
      "Epoch:0179 train loss:1.227 acc:60.00 | val loss:1.330 acc:70.60\r\n",
      "Epoch:0180 train loss:1.166 acc:66.67 | val loss:1.327 acc:70.20\r\n",
      "Epoch:0181 train loss:1.129 acc:68.33 | val loss:1.322 acc:69.60\r\n",
      "Epoch:0182 train loss:1.280 acc:56.67 | val loss:1.318 acc:69.80\r\n",
      "Epoch:0183 train loss:1.176 acc:62.50 | val loss:1.316 acc:70.00\r\n",
      "Epoch:0184 train loss:1.182 acc:56.67 | val loss:1.318 acc:70.80\r\n",
      "Epoch:0185 train loss:1.246 acc:61.67 | val loss:1.321 acc:70.80\r\n",
      "Epoch:0186 train loss:1.222 acc:60.83 | val loss:1.326 acc:69.00\r\n",
      "Epoch:0187 train loss:1.193 acc:62.50 | val loss:1.333 acc:68.00\r\n",
      "Epoch:0188 train loss:1.201 acc:62.50 | val loss:1.339 acc:67.60\r\n",
      "Epoch:0189 train loss:1.196 acc:60.00 | val loss:1.345 acc:66.40\r\n",
      "Epoch:0190 train loss:1.149 acc:61.67 | val loss:1.346 acc:66.20\r\n",
      "Epoch:0191 train loss:1.328 acc:60.00 | val loss:1.349 acc:66.80\r\n",
      "Epoch:0192 train loss:1.137 acc:60.83 | val loss:1.354 acc:67.40\r\n",
      "Epoch:0193 train loss:1.169 acc:59.17 | val loss:1.357 acc:67.00\r\n",
      "Epoch:0194 train loss:1.475 acc:52.50 | val loss:1.365 acc:66.20\r\n",
      "Epoch:0195 train loss:1.338 acc:52.50 | val loss:1.367 acc:66.40\r\n",
      "Epoch:0196 train loss:1.122 acc:62.50 | val loss:1.363 acc:66.80\r\n",
      "Epoch:0197 train loss:1.309 acc:52.50 | val loss:1.360 acc:67.40\r\n",
      "Epoch:0198 train loss:1.206 acc:60.00 | val loss:1.356 acc:67.60\r\n",
      "Epoch:0199 train loss:1.321 acc:65.00 | val loss:1.353 acc:66.60\r\n",
      "Epoch:0200 train loss:1.171 acc:64.17 | val loss:1.351 acc:68.20\r\n",
      "Epoch:0201 train loss:1.141 acc:70.83 | val loss:1.350 acc:69.20\r\n",
      "Epoch:0202 train loss:1.227 acc:63.33 | val loss:1.352 acc:69.00\r\n",
      "Epoch:0203 train loss:1.244 acc:62.50 | val loss:1.353 acc:68.60\r\n",
      "Epoch:0204 train loss:1.267 acc:58.33 | val loss:1.358 acc:67.60\r\n",
      "Epoch:0205 train loss:1.205 acc:61.67 | val loss:1.365 acc:67.00\r\n",
      "Epoch:0206 train loss:1.173 acc:55.00 | val loss:1.374 acc:64.60\r\n",
      "Epoch:0207 train loss:1.208 acc:62.50 | val loss:1.377 acc:65.20\r\n",
      "Epoch:0208 train loss:1.094 acc:66.67 | val loss:1.377 acc:65.40\r\n",
      "Epoch:0209 train loss:1.080 acc:69.17 | val loss:1.372 acc:66.20\r\n",
      "Epoch:0210 train loss:1.142 acc:65.83 | val loss:1.365 acc:66.60\r\n",
      "Epoch:0211 train loss:1.222 acc:67.50 | val loss:1.356 acc:68.20\r\n",
      "Epoch:0212 train loss:1.198 acc:64.17 | val loss:1.354 acc:68.40\r\n",
      "Epoch:0213 train loss:1.200 acc:65.00 | val loss:1.350 acc:68.40\r\n",
      "Epoch:0214 train loss:1.218 acc:62.50 | val loss:1.351 acc:68.00\r\n",
      "Epoch:0215 train loss:1.140 acc:67.50 | val loss:1.348 acc:68.40\r\n",
      "Epoch:0216 train loss:1.198 acc:63.33 | val loss:1.346 acc:69.00\r\n",
      "Epoch:0217 train loss:1.142 acc:66.67 | val loss:1.341 acc:68.20\r\n",
      "Epoch:0218 train loss:1.083 acc:67.50 | val loss:1.335 acc:68.40\r\n",
      "Epoch:0219 train loss:1.110 acc:65.00 | val loss:1.328 acc:69.00\r\n",
      "Epoch:0220 train loss:1.252 acc:58.33 | val loss:1.316 acc:69.80\r\n",
      "Epoch:0221 train loss:1.280 acc:59.17 | val loss:1.301 acc:70.20\r\n",
      "Epoch:0222 train loss:1.226 acc:63.33 | val loss:1.287 acc:69.80\r\n",
      "Epoch:0223 train loss:1.134 acc:65.00 | val loss:1.278 acc:70.60\r\n",
      "Epoch:0224 train loss:1.067 acc:66.67 | val loss:1.271 acc:71.20\r\n",
      "Epoch:0225 train loss:1.162 acc:61.67 | val loss:1.266 acc:71.40\r\n",
      "Epoch:0226 train loss:1.179 acc:58.33 | val loss:1.266 acc:71.00\r\n",
      "Epoch:0227 train loss:1.229 acc:62.50 | val loss:1.271 acc:69.80\r\n",
      "Epoch:0228 train loss:1.125 acc:64.17 | val loss:1.275 acc:69.80\r\n",
      "Epoch:0229 train loss:1.132 acc:64.17 | val loss:1.278 acc:69.40\r\n",
      "Epoch:0230 train loss:1.161 acc:63.33 | val loss:1.280 acc:68.60\r\n",
      "Epoch:0231 train loss:1.105 acc:65.00 | val loss:1.279 acc:69.40\r\n",
      "Epoch:0232 train loss:1.293 acc:58.33 | val loss:1.281 acc:69.40\r\n",
      "Epoch:0233 train loss:1.139 acc:64.17 | val loss:1.288 acc:69.80\r\n",
      "Epoch:0234 train loss:1.237 acc:51.67 | val loss:1.292 acc:69.60\r\n",
      "Epoch:0235 train loss:1.083 acc:68.33 | val loss:1.294 acc:69.80\r\n",
      "Epoch:0236 train loss:1.259 acc:58.33 | val loss:1.297 acc:70.40\r\n",
      "Epoch:0237 train loss:1.226 acc:59.17 | val loss:1.304 acc:70.60\r\n",
      "Epoch:0238 train loss:1.213 acc:60.00 | val loss:1.314 acc:68.80\r\n",
      "Epoch:0239 train loss:1.085 acc:65.00 | val loss:1.321 acc:69.20\r\n",
      "Epoch:0240 train loss:1.305 acc:65.83 | val loss:1.328 acc:69.40\r\n",
      "Epoch:0241 train loss:1.084 acc:65.00 | val loss:1.331 acc:69.40\r\n",
      "Epoch:0242 train loss:1.143 acc:61.67 | val loss:1.333 acc:68.40\r\n",
      "Epoch:0243 train loss:1.113 acc:65.83 | val loss:1.334 acc:68.00\r\n",
      "Epoch:0244 train loss:1.133 acc:68.33 | val loss:1.330 acc:68.60\r\n",
      "Epoch:0245 train loss:1.406 acc:60.00 | val loss:1.327 acc:67.20\r\n",
      "Epoch:0246 train loss:1.132 acc:64.17 | val loss:1.322 acc:66.60\r\n",
      "Epoch:0247 train loss:1.092 acc:68.33 | val loss:1.322 acc:65.00\r\n",
      "Epoch:0248 train loss:1.214 acc:60.00 | val loss:1.325 acc:64.80\r\n",
      "Epoch:0249 train loss:1.223 acc:59.17 | val loss:1.327 acc:64.00\r\n",
      "Epoch:0250 train loss:1.259 acc:60.00 | val loss:1.321 acc:66.00\r\n",
      "Epoch:0251 train loss:1.330 acc:58.33 | val loss:1.323 acc:67.20\r\n",
      "Epoch:0252 train loss:1.238 acc:64.17 | val loss:1.329 acc:67.00\r\n",
      "Epoch:0253 train loss:1.168 acc:57.50 | val loss:1.334 acc:67.40\r\n",
      "Epoch:0254 train loss:1.196 acc:65.00 | val loss:1.333 acc:69.00\r\n",
      "Epoch:0255 train loss:1.140 acc:58.33 | val loss:1.330 acc:69.40\r\n",
      "Epoch:0256 train loss:1.329 acc:60.00 | val loss:1.329 acc:69.40\r\n",
      "Epoch:0257 train loss:1.134 acc:60.83 | val loss:1.327 acc:69.40\r\n",
      "Epoch:0258 train loss:1.092 acc:65.00 | val loss:1.325 acc:70.00\r\n",
      "Epoch:0259 train loss:1.208 acc:59.17 | val loss:1.326 acc:69.40\r\n",
      "Epoch:0260 train loss:1.725 acc:62.50 | val loss:1.331 acc:68.60\r\n",
      "Epoch:0261 train loss:1.406 acc:55.83 | val loss:1.341 acc:66.60\r\n",
      "Epoch:0262 train loss:1.178 acc:63.33 | val loss:1.347 acc:64.60\r\n",
      "Epoch:0263 train loss:1.147 acc:61.67 | val loss:1.349 acc:64.20\r\n",
      "Epoch:0264 train loss:1.299 acc:58.33 | val loss:1.349 acc:66.20\r\n",
      "Epoch:0265 train loss:1.155 acc:70.00 | val loss:1.347 acc:68.00\r\n",
      "Epoch:0266 train loss:1.278 acc:59.17 | val loss:1.347 acc:68.20\r\n",
      "Epoch:0267 train loss:1.219 acc:67.50 | val loss:1.348 acc:66.40\r\n",
      "Epoch:0268 train loss:1.282 acc:61.67 | val loss:1.354 acc:65.00\r\n",
      "Epoch:0269 train loss:1.174 acc:62.50 | val loss:1.356 acc:64.80\r\n",
      "Epoch:0270 train loss:1.271 acc:59.17 | val loss:1.363 acc:63.20\r\n",
      "Epoch:0271 train loss:1.191 acc:60.83 | val loss:1.368 acc:63.40\r\n",
      "Epoch:0272 train loss:1.206 acc:57.50 | val loss:1.372 acc:63.60\r\n",
      "Epoch:0273 train loss:1.242 acc:58.33 | val loss:1.374 acc:64.60\r\n",
      "Epoch:0274 train loss:1.234 acc:54.17 | val loss:1.376 acc:65.60\r\n",
      "Epoch:0275 train loss:1.164 acc:59.17 | val loss:1.379 acc:65.80\r\n",
      "Epoch:0276 train loss:1.285 acc:55.83 | val loss:1.377 acc:67.40\r\n",
      "Epoch:0277 train loss:1.319 acc:55.83 | val loss:1.379 acc:68.60\r\n",
      "Epoch:0278 train loss:1.252 acc:58.33 | val loss:1.379 acc:69.00\r\n",
      "Epoch:0279 train loss:1.208 acc:59.17 | val loss:1.376 acc:69.00\r\n",
      "Epoch:0280 train loss:1.236 acc:60.83 | val loss:1.376 acc:69.20\r\n",
      "Epoch:0281 train loss:1.120 acc:63.33 | val loss:1.371 acc:68.20\r\n",
      "Epoch:0282 train loss:1.330 acc:55.00 | val loss:1.369 acc:69.20\r\n",
      "Epoch:0283 train loss:1.144 acc:62.50 | val loss:1.367 acc:69.20\r\n",
      "Epoch:0284 train loss:1.224 acc:61.67 | val loss:1.370 acc:68.20\r\n",
      "Epoch:0285 train loss:1.385 acc:61.67 | val loss:1.376 acc:67.40\r\n",
      "Epoch:0286 train loss:1.199 acc:56.67 | val loss:1.383 acc:66.60\r\n",
      "Epoch:0287 train loss:1.176 acc:62.50 | val loss:1.383 acc:65.80\r\n",
      "Epoch:0288 train loss:1.205 acc:67.50 | val loss:1.378 acc:66.40\r\n",
      "Epoch:0289 train loss:1.241 acc:60.83 | val loss:1.375 acc:66.40\r\n",
      "Epoch:0290 train loss:1.147 acc:63.33 | val loss:1.368 acc:67.60\r\n",
      "Epoch:0291 train loss:1.181 acc:65.00 | val loss:1.362 acc:67.60\r\n",
      "Epoch:0292 train loss:1.297 acc:60.83 | val loss:1.361 acc:68.00\r\n",
      "Epoch:0293 train loss:1.206 acc:60.00 | val loss:1.359 acc:68.00\r\n",
      "Epoch:0294 train loss:1.129 acc:67.50 | val loss:1.352 acc:69.00\r\n",
      "Epoch:0295 train loss:1.525 acc:65.83 | val loss:1.354 acc:69.40\r\n",
      "Epoch:0296 train loss:1.164 acc:65.83 | val loss:1.356 acc:69.60\r\n",
      "Epoch:0297 train loss:1.193 acc:67.50 | val loss:1.355 acc:69.40\r\n",
      "Epoch:0298 train loss:1.194 acc:61.67 | val loss:1.353 acc:69.40\r\n",
      "Epoch:0299 train loss:1.322 acc:61.67 | val loss:1.352 acc:70.00\r\n",
      "Epoch:0300 train loss:1.092 acc:67.50 | val loss:1.350 acc:69.20\r\n",
      "Epoch:0301 train loss:1.121 acc:63.33 | val loss:1.347 acc:69.20\r\n",
      "Epoch:0302 train loss:1.186 acc:68.33 | val loss:1.345 acc:69.00\r\n",
      "Epoch:0303 train loss:1.139 acc:70.83 | val loss:1.338 acc:69.20\r\n",
      "Epoch:0304 train loss:1.220 acc:58.33 | val loss:1.331 acc:69.40\r\n",
      "Epoch:0305 train loss:1.234 acc:64.17 | val loss:1.326 acc:68.40\r\n",
      "Epoch:0306 train loss:1.214 acc:62.50 | val loss:1.323 acc:68.80\r\n",
      "Epoch:0307 train loss:1.157 acc:62.50 | val loss:1.321 acc:68.20\r\n",
      "Epoch:0308 train loss:1.063 acc:72.50 | val loss:1.319 acc:68.60\r\n",
      "Epoch:0309 train loss:1.246 acc:65.00 | val loss:1.319 acc:68.60\r\n",
      "Epoch:0310 train loss:1.159 acc:67.50 | val loss:1.318 acc:68.80\r\n",
      "Epoch:0311 train loss:1.082 acc:71.67 | val loss:1.316 acc:69.20\r\n",
      "Epoch:0312 train loss:1.265 acc:59.17 | val loss:1.318 acc:69.20\r\n",
      "Epoch:0313 train loss:1.063 acc:60.83 | val loss:1.320 acc:69.20\r\n",
      "Epoch:0314 train loss:1.080 acc:68.33 | val loss:1.321 acc:69.00\r\n",
      "Epoch:0315 train loss:1.442 acc:60.83 | val loss:1.321 acc:69.20\r\n",
      "Epoch:0316 train loss:1.559 acc:64.17 | val loss:1.321 acc:69.60\r\n",
      "Epoch:0317 train loss:1.154 acc:69.17 | val loss:1.319 acc:69.40\r\n",
      "Epoch:0318 train loss:1.266 acc:61.67 | val loss:1.318 acc:69.00\r\n",
      "Epoch:0319 train loss:1.101 acc:62.50 | val loss:1.317 acc:68.80\r\n",
      "Epoch:0320 train loss:1.161 acc:64.17 | val loss:1.313 acc:69.20\r\n",
      "Epoch:0321 train loss:1.140 acc:62.50 | val loss:1.308 acc:69.60\r\n",
      "Epoch:0322 train loss:1.546 acc:65.00 | val loss:1.304 acc:69.60\r\n",
      "Epoch:0323 train loss:1.285 acc:56.67 | val loss:1.306 acc:70.00\r\n",
      "Epoch:0324 train loss:1.194 acc:63.33 | val loss:1.310 acc:69.00\r\n",
      "Epoch:0325 train loss:1.261 acc:57.50 | val loss:1.318 acc:68.60\r\n",
      "Epoch:0326 train loss:1.095 acc:65.00 | val loss:1.323 acc:68.40\r\n",
      "Epoch:0327 train loss:1.259 acc:61.67 | val loss:1.333 acc:67.80\r\n",
      "Epoch:0328 train loss:1.097 acc:68.33 | val loss:1.340 acc:67.20\r\n",
      "Epoch:0329 train loss:1.207 acc:65.00 | val loss:1.350 acc:67.00\r\n",
      "Epoch:0330 train loss:1.058 acc:69.17 | val loss:1.354 acc:67.00\r\n",
      "Epoch:0331 train loss:1.298 acc:62.50 | val loss:1.360 acc:66.40\r\n",
      "Epoch:0332 train loss:1.149 acc:63.33 | val loss:1.364 acc:65.80\r\n",
      "Epoch:0333 train loss:1.152 acc:65.00 | val loss:1.363 acc:66.00\r\n",
      "Epoch:0334 train loss:1.189 acc:66.67 | val loss:1.357 acc:66.60\r\n",
      "Epoch:0335 train loss:1.168 acc:64.17 | val loss:1.351 acc:68.00\r\n",
      "Epoch:0336 train loss:1.166 acc:58.33 | val loss:1.344 acc:68.20\r\n",
      "Epoch:0337 train loss:1.023 acc:65.00 | val loss:1.338 acc:68.60\r\n",
      "Epoch:0338 train loss:1.053 acc:65.83 | val loss:1.330 acc:69.00\r\n",
      "Epoch:0339 train loss:1.194 acc:68.33 | val loss:1.325 acc:69.20\r\n",
      "Epoch:0340 train loss:1.135 acc:69.17 | val loss:1.323 acc:67.60\r\n",
      "Epoch:0341 train loss:1.162 acc:62.50 | val loss:1.320 acc:66.80\r\n",
      "Epoch:0342 train loss:1.142 acc:61.67 | val loss:1.318 acc:65.20\r\n",
      "Epoch:0343 train loss:1.199 acc:60.83 | val loss:1.319 acc:65.00\r\n",
      "Epoch:0344 train loss:1.133 acc:64.17 | val loss:1.317 acc:64.60\r\n",
      "Epoch:0345 train loss:1.127 acc:59.17 | val loss:1.313 acc:65.00\r\n",
      "Epoch:0346 train loss:1.198 acc:59.17 | val loss:1.310 acc:65.00\r\n",
      "Epoch:0347 train loss:1.484 acc:53.33 | val loss:1.312 acc:64.40\r\n",
      "Epoch:0348 train loss:1.208 acc:70.83 | val loss:1.318 acc:65.00\r\n",
      "Epoch:0349 train loss:1.088 acc:71.67 | val loss:1.322 acc:64.80\r\n",
      "Epoch:0350 train loss:1.209 acc:55.83 | val loss:1.327 acc:65.00\r\n",
      "Epoch:0351 train loss:1.211 acc:64.17 | val loss:1.331 acc:64.40\r\n",
      "Epoch:0352 train loss:1.193 acc:63.33 | val loss:1.332 acc:64.40\r\n",
      "Epoch:0353 train loss:1.132 acc:68.33 | val loss:1.332 acc:65.20\r\n",
      "Epoch:0354 train loss:1.336 acc:60.83 | val loss:1.331 acc:65.00\r\n",
      "Epoch:0355 train loss:1.058 acc:70.00 | val loss:1.326 acc:65.60\r\n",
      "Epoch:0356 train loss:1.110 acc:66.67 | val loss:1.320 acc:67.60\r\n",
      "Epoch:0357 train loss:1.204 acc:57.50 | val loss:1.324 acc:68.00\r\n",
      "Epoch:0358 train loss:1.194 acc:67.50 | val loss:1.333 acc:67.80\r\n",
      "Epoch:0359 train loss:1.135 acc:65.83 | val loss:1.341 acc:66.60\r\n",
      "Epoch:0360 train loss:1.035 acc:70.83 | val loss:1.344 acc:66.20\r\n",
      "Epoch:0361 train loss:1.236 acc:64.17 | val loss:1.351 acc:65.20\r\n",
      "Epoch:0362 train loss:1.132 acc:62.50 | val loss:1.352 acc:66.20\r\n",
      "Epoch:0363 train loss:1.225 acc:56.67 | val loss:1.350 acc:67.60\r\n",
      "Epoch:0364 train loss:1.193 acc:64.17 | val loss:1.346 acc:68.20\r\n",
      "Epoch:0365 train loss:1.147 acc:65.00 | val loss:1.340 acc:68.40\r\n",
      "Epoch:0366 train loss:1.041 acc:66.67 | val loss:1.334 acc:69.00\r\n",
      "Epoch:0367 train loss:1.151 acc:61.67 | val loss:1.326 acc:69.00\r\n",
      "Epoch:0368 train loss:1.297 acc:63.33 | val loss:1.320 acc:70.00\r\n",
      "Epoch:0369 train loss:1.099 acc:65.83 | val loss:1.321 acc:71.00\r\n",
      "Epoch:0370 train loss:1.164 acc:57.50 | val loss:1.321 acc:71.00\r\n",
      "Epoch:0371 train loss:1.156 acc:61.67 | val loss:1.321 acc:70.00\r\n",
      "Epoch:0372 train loss:1.239 acc:59.17 | val loss:1.323 acc:70.20\r\n",
      "Epoch:0373 train loss:1.237 acc:59.17 | val loss:1.327 acc:69.80\r\n",
      "Epoch:0374 train loss:1.138 acc:64.17 | val loss:1.332 acc:68.40\r\n",
      "Epoch:0375 train loss:1.063 acc:59.17 | val loss:1.340 acc:66.40\r\n",
      "Epoch:0376 train loss:1.265 acc:59.17 | val loss:1.353 acc:65.40\r\n",
      "Epoch:0377 train loss:1.169 acc:56.67 | val loss:1.363 acc:62.80\r\n",
      "Epoch:0378 train loss:1.690 acc:66.67 | val loss:1.376 acc:60.20\r\n",
      "Epoch:0379 train loss:1.148 acc:66.67 | val loss:1.377 acc:59.40\r\n",
      "Epoch:0380 train loss:1.165 acc:65.83 | val loss:1.373 acc:60.40\r\n",
      "Epoch:0381 train loss:1.149 acc:67.50 | val loss:1.362 acc:61.80\r\n",
      "Epoch:0382 train loss:1.151 acc:61.67 | val loss:1.352 acc:63.60\r\n",
      "Epoch:0383 train loss:1.089 acc:69.17 | val loss:1.342 acc:65.80\r\n",
      "Epoch:0384 train loss:1.146 acc:61.67 | val loss:1.328 acc:67.00\r\n",
      "Epoch:0385 train loss:1.106 acc:65.83 | val loss:1.315 acc:68.80\r\n",
      "Epoch:0386 train loss:1.110 acc:70.00 | val loss:1.303 acc:69.40\r\n",
      "Epoch:0387 train loss:1.059 acc:64.17 | val loss:1.293 acc:69.80\r\n",
      "Epoch:0388 train loss:1.116 acc:64.17 | val loss:1.284 acc:71.00\r\n",
      "Epoch:0389 train loss:1.162 acc:67.50 | val loss:1.275 acc:70.20\r\n",
      "Epoch:0390 train loss:1.016 acc:71.67 | val loss:1.262 acc:70.80\r\n",
      "Epoch:0391 train loss:1.086 acc:60.83 | val loss:1.252 acc:71.00\r\n",
      "Epoch:0392 train loss:1.109 acc:65.83 | val loss:1.243 acc:71.80\r\n",
      "Epoch:0393 train loss:1.133 acc:66.67 | val loss:1.237 acc:71.80\r\n",
      "Epoch:0394 train loss:1.172 acc:62.50 | val loss:1.235 acc:72.00\r\n",
      "Epoch:0395 train loss:1.243 acc:63.33 | val loss:1.238 acc:71.40\r\n",
      "Epoch:0396 train loss:1.108 acc:60.00 | val loss:1.244 acc:71.40\r\n",
      "Epoch:0397 train loss:1.382 acc:55.83 | val loss:1.254 acc:71.00\r\n",
      "Epoch:0398 train loss:1.104 acc:69.17 | val loss:1.265 acc:70.40\r\n",
      "Epoch:0399 train loss:1.129 acc:65.00 | val loss:1.276 acc:69.40\r\n",
      "Epoch:0400 train loss:1.010 acc:65.00 | val loss:1.285 acc:69.20\r\n",
      "Epoch:0401 train loss:1.330 acc:60.83 | val loss:1.303 acc:67.80\r\n",
      "Epoch:0402 train loss:1.353 acc:55.00 | val loss:1.316 acc:65.80\r\n",
      "Epoch:0403 train loss:1.138 acc:64.17 | val loss:1.326 acc:65.60\r\n",
      "Epoch:0404 train loss:2.466 acc:63.33 | val loss:1.344 acc:65.00\r\n",
      "Epoch:0405 train loss:1.127 acc:70.83 | val loss:1.353 acc:66.40\r\n",
      "Epoch:0406 train loss:1.245 acc:59.17 | val loss:1.358 acc:68.20\r\n",
      "Epoch:0407 train loss:1.204 acc:50.83 | val loss:1.364 acc:67.00\r\n",
      "Epoch:0408 train loss:1.131 acc:66.67 | val loss:1.367 acc:66.60\r\n",
      "Epoch:0409 train loss:1.249 acc:60.00 | val loss:1.369 acc:65.40\r\n",
      "Epoch:0410 train loss:1.303 acc:62.50 | val loss:1.371 acc:64.40\r\n",
      "Epoch:0411 train loss:1.143 acc:63.33 | val loss:1.369 acc:63.20\r\n",
      "Epoch:0412 train loss:1.427 acc:57.50 | val loss:1.370 acc:63.60\r\n",
      "Epoch:0413 train loss:1.223 acc:66.67 | val loss:1.370 acc:63.80\r\n",
      "Epoch:0414 train loss:1.122 acc:66.67 | val loss:1.367 acc:64.20\r\n",
      "Epoch:0415 train loss:1.185 acc:60.00 | val loss:1.361 acc:65.40\r\n",
      "Epoch:0416 train loss:1.218 acc:64.17 | val loss:1.364 acc:66.60\r\n",
      "Epoch:0417 train loss:1.132 acc:69.17 | val loss:1.370 acc:66.60\r\n",
      "Epoch:0418 train loss:1.263 acc:63.33 | val loss:1.376 acc:67.60\r\n",
      "Epoch:0419 train loss:1.183 acc:60.83 | val loss:1.379 acc:67.40\r\n",
      "Epoch:0420 train loss:1.404 acc:66.67 | val loss:1.381 acc:67.80\r\n",
      "Epoch:0421 train loss:1.199 acc:66.67 | val loss:1.383 acc:69.20\r\n",
      "Epoch:0422 train loss:1.298 acc:63.33 | val loss:1.390 acc:68.20\r\n",
      "Epoch:0423 train loss:1.151 acc:63.33 | val loss:1.393 acc:68.40\r\n",
      "Epoch:0424 train loss:1.111 acc:70.00 | val loss:1.398 acc:66.80\r\n",
      "Epoch:0425 train loss:1.190 acc:60.83 | val loss:1.399 acc:66.80\r\n",
      "Epoch:0426 train loss:1.097 acc:63.33 | val loss:1.401 acc:65.20\r\n",
      "Epoch:0427 train loss:1.274 acc:65.00 | val loss:1.400 acc:64.60\r\n",
      "Epoch:0428 train loss:1.337 acc:62.50 | val loss:1.408 acc:63.80\r\n",
      "Epoch:0429 train loss:1.228 acc:65.83 | val loss:1.412 acc:62.40\r\n",
      "Epoch:0430 train loss:1.128 acc:69.17 | val loss:1.406 acc:62.40\r\n",
      "Epoch:0431 train loss:1.319 acc:51.67 | val loss:1.402 acc:62.60\r\n",
      "Epoch:0432 train loss:1.289 acc:58.33 | val loss:1.396 acc:63.40\r\n",
      "Epoch:0433 train loss:1.217 acc:62.50 | val loss:1.391 acc:61.40\r\n",
      "Epoch:0434 train loss:1.189 acc:62.50 | val loss:1.387 acc:60.60\r\n",
      "Epoch:0435 train loss:1.206 acc:55.83 | val loss:1.380 acc:61.20\r\n",
      "Epoch:0436 train loss:1.151 acc:62.50 | val loss:1.371 acc:61.40\r\n",
      "Epoch:0437 train loss:1.222 acc:57.50 | val loss:1.360 acc:61.80\r\n",
      "Epoch:0438 train loss:1.233 acc:65.00 | val loss:1.353 acc:62.40\r\n",
      "Epoch:0439 train loss:1.226 acc:66.67 | val loss:1.351 acc:62.80\r\n",
      "Epoch:0440 train loss:1.088 acc:62.50 | val loss:1.344 acc:63.00\r\n",
      "Epoch:0441 train loss:1.106 acc:66.67 | val loss:1.339 acc:63.60\r\n",
      "Epoch:0442 train loss:1.249 acc:68.33 | val loss:1.334 acc:64.80\r\n",
      "Epoch:0443 train loss:1.238 acc:70.00 | val loss:1.331 acc:65.80\r\n",
      "Epoch:0444 train loss:1.157 acc:65.00 | val loss:1.328 acc:65.80\r\n",
      "Epoch:0445 train loss:1.161 acc:64.17 | val loss:1.322 acc:65.80\r\n",
      "Epoch:0446 train loss:1.214 acc:64.17 | val loss:1.318 acc:66.40\r\n",
      "Epoch:0447 train loss:1.329 acc:58.33 | val loss:1.318 acc:67.20\r\n",
      "Epoch:0448 train loss:1.133 acc:60.83 | val loss:1.318 acc:67.20\r\n",
      "Epoch:0449 train loss:1.372 acc:55.83 | val loss:1.327 acc:68.20\r\n",
      "Epoch:0450 train loss:1.082 acc:68.33 | val loss:1.331 acc:68.40\r\n",
      "Epoch:0451 train loss:1.160 acc:64.17 | val loss:1.331 acc:69.20\r\n",
      "Epoch:0452 train loss:1.261 acc:60.00 | val loss:1.334 acc:69.60\r\n",
      "Epoch:0453 train loss:1.228 acc:63.33 | val loss:1.338 acc:68.80\r\n",
      "Epoch:0454 train loss:1.218 acc:60.83 | val loss:1.344 acc:68.40\r\n",
      "Epoch:0455 train loss:1.165 acc:63.33 | val loss:1.351 acc:68.40\r\n",
      "Epoch:0456 train loss:1.073 acc:68.33 | val loss:1.357 acc:67.20\r\n",
      "Epoch:0457 train loss:1.193 acc:59.17 | val loss:1.361 acc:66.60\r\n",
      "Epoch:0458 train loss:1.249 acc:60.83 | val loss:1.366 acc:66.40\r\n",
      "Epoch:0459 train loss:1.200 acc:58.33 | val loss:1.368 acc:66.40\r\n",
      "Epoch:0460 train loss:1.582 acc:60.83 | val loss:1.370 acc:67.00\r\n",
      "Epoch:0461 train loss:1.087 acc:66.67 | val loss:1.372 acc:67.00\r\n",
      "Epoch:0462 train loss:1.092 acc:58.33 | val loss:1.372 acc:67.60\r\n",
      "Epoch:0463 train loss:1.279 acc:61.67 | val loss:1.374 acc:67.20\r\n",
      "Epoch:0464 train loss:1.153 acc:61.67 | val loss:1.378 acc:66.40\r\n",
      "Epoch:0465 train loss:1.085 acc:70.00 | val loss:1.378 acc:66.80\r\n",
      "Epoch:0466 train loss:1.231 acc:61.67 | val loss:1.376 acc:67.40\r\n",
      "Epoch:0467 train loss:1.217 acc:60.00 | val loss:1.373 acc:67.40\r\n",
      "Epoch:0468 train loss:1.127 acc:63.33 | val loss:1.368 acc:67.40\r\n",
      "Epoch:0469 train loss:1.154 acc:61.67 | val loss:1.367 acc:68.20\r\n",
      "Epoch:0470 train loss:1.245 acc:56.67 | val loss:1.366 acc:66.80\r\n",
      "Epoch:0471 train loss:1.105 acc:68.33 | val loss:1.368 acc:66.40\r\n",
      "Epoch:0472 train loss:1.329 acc:55.00 | val loss:1.371 acc:65.40\r\n",
      "Epoch:0473 train loss:1.397 acc:61.67 | val loss:1.373 acc:65.20\r\n",
      "Epoch:0474 train loss:1.253 acc:62.50 | val loss:1.372 acc:65.20\r\n",
      "Epoch:0475 train loss:1.318 acc:57.50 | val loss:1.374 acc:65.00\r\n",
      "Epoch:0476 train loss:1.129 acc:66.67 | val loss:1.378 acc:64.20\r\n",
      "Epoch:0477 train loss:1.237 acc:59.17 | val loss:1.376 acc:64.60\r\n",
      "Epoch:0478 train loss:1.211 acc:57.50 | val loss:1.375 acc:64.20\r\n",
      "Epoch:0479 train loss:1.095 acc:69.17 | val loss:1.372 acc:63.80\r\n",
      "Epoch:0480 train loss:1.166 acc:59.17 | val loss:1.369 acc:64.00\r\n",
      "Epoch:0481 train loss:1.154 acc:63.33 | val loss:1.364 acc:64.40\r\n",
      "Epoch:0482 train loss:1.107 acc:65.00 | val loss:1.356 acc:65.80\r\n",
      "Epoch:0483 train loss:1.273 acc:55.00 | val loss:1.351 acc:65.40\r\n",
      "Epoch:0484 train loss:1.200 acc:65.83 | val loss:1.349 acc:65.40\r\n",
      "Epoch:0485 train loss:1.073 acc:69.17 | val loss:1.342 acc:66.60\r\n",
      "Epoch:0486 train loss:1.175 acc:65.00 | val loss:1.334 acc:66.60\r\n",
      "Epoch:0487 train loss:1.186 acc:63.33 | val loss:1.331 acc:67.40\r\n",
      "Epoch:0488 train loss:1.196 acc:61.67 | val loss:1.331 acc:67.40\r\n",
      "Epoch:0489 train loss:1.200 acc:58.33 | val loss:1.329 acc:67.20\r\n",
      "Epoch:0490 train loss:1.216 acc:60.83 | val loss:1.331 acc:67.60\r\n",
      "Epoch:0491 train loss:1.213 acc:65.83 | val loss:1.331 acc:68.00\r\n",
      "Epoch:0492 train loss:1.413 acc:60.00 | val loss:1.328 acc:69.00\r\n",
      "Epoch:0493 train loss:1.227 acc:60.00 | val loss:1.328 acc:70.60\r\n",
      "Epoch:0494 train loss:1.104 acc:64.17 | val loss:1.326 acc:70.40\r\n",
      "Epoch:0495 train loss:1.164 acc:67.50 | val loss:1.325 acc:70.80\r\n",
      "Epoch:0496 train loss:1.246 acc:60.83 | val loss:1.323 acc:71.20\r\n",
      "Epoch:0497 train loss:1.341 acc:64.17 | val loss:1.324 acc:71.00\r\n",
      "Epoch:0498 train loss:1.195 acc:60.83 | val loss:1.327 acc:70.80\r\n",
      "Epoch:0499 train loss:1.332 acc:59.17 | val loss:1.333 acc:69.20\r\n",
      "Epoch:0500 train loss:1.168 acc:61.67 | val loss:1.343 acc:69.20\r\n",
      "Epoch:0501 train loss:1.201 acc:57.50 | val loss:1.349 acc:68.20\r\n",
      "Epoch:0502 train loss:1.215 acc:66.67 | val loss:1.351 acc:68.80\r\n",
      "Epoch:0503 train loss:1.159 acc:68.33 | val loss:1.352 acc:68.60\r\n",
      "Epoch:0504 train loss:1.296 acc:59.17 | val loss:1.349 acc:67.20\r\n",
      "Epoch:0505 train loss:1.250 acc:56.67 | val loss:1.353 acc:65.00\r\n",
      "Epoch:0506 train loss:1.282 acc:57.50 | val loss:1.356 acc:62.00\r\n",
      "Epoch:0507 train loss:1.494 acc:54.17 | val loss:1.361 acc:61.40\r\n",
      "Epoch:0508 train loss:1.178 acc:60.00 | val loss:1.361 acc:61.40\r\n",
      "Epoch:0509 train loss:1.357 acc:58.33 | val loss:1.359 acc:61.80\r\n",
      "Epoch:0510 train loss:1.334 acc:52.50 | val loss:1.355 acc:63.40\r\n",
      "Epoch:0511 train loss:1.271 acc:59.17 | val loss:1.356 acc:63.40\r\n",
      "Epoch:0512 train loss:1.101 acc:65.83 | val loss:1.357 acc:64.60\r\n",
      "Epoch:0513 train loss:1.199 acc:65.00 | val loss:1.357 acc:65.20\r\n",
      "Epoch:0514 train loss:1.182 acc:56.67 | val loss:1.358 acc:68.00\r\n",
      "Epoch:0515 train loss:1.179 acc:64.17 | val loss:1.356 acc:68.60\r\n",
      "Epoch:0516 train loss:1.404 acc:61.67 | val loss:1.361 acc:68.40\r\n",
      "Epoch:0517 train loss:1.249 acc:62.50 | val loss:1.365 acc:68.40\r\n",
      "Epoch:0518 train loss:1.203 acc:60.00 | val loss:1.369 acc:67.60\r\n",
      "Epoch:0519 train loss:1.312 acc:55.83 | val loss:1.376 acc:66.60\r\n",
      "Epoch:0520 train loss:1.122 acc:60.00 | val loss:1.374 acc:66.20\r\n",
      "Epoch:0521 train loss:1.199 acc:55.83 | val loss:1.369 acc:67.00\r\n",
      "Epoch:0522 train loss:1.343 acc:60.00 | val loss:1.365 acc:66.40\r\n",
      "Epoch:0523 train loss:1.255 acc:58.33 | val loss:1.366 acc:66.00\r\n",
      "Epoch:0524 train loss:1.218 acc:61.67 | val loss:1.364 acc:66.60\r\n",
      "Epoch:0525 train loss:1.102 acc:65.00 | val loss:1.360 acc:66.80\r\n",
      "Epoch:0526 train loss:1.193 acc:60.83 | val loss:1.356 acc:66.80\r\n",
      "Epoch:0527 train loss:1.205 acc:61.67 | val loss:1.354 acc:67.00\r\n",
      "Epoch:0528 train loss:1.183 acc:65.83 | val loss:1.354 acc:67.40\r\n",
      "Epoch:0529 train loss:1.235 acc:59.17 | val loss:1.354 acc:68.00\r\n",
      "Epoch:0530 train loss:1.230 acc:64.17 | val loss:1.357 acc:67.40\r\n",
      "Epoch:0531 train loss:1.220 acc:60.00 | val loss:1.359 acc:68.20\r\n",
      "Epoch:0532 train loss:1.157 acc:64.17 | val loss:1.358 acc:67.00\r\n",
      "Epoch:0533 train loss:1.167 acc:66.67 | val loss:1.356 acc:67.00\r\n",
      "Epoch:0534 train loss:1.258 acc:55.83 | val loss:1.356 acc:66.20\r\n",
      "Epoch:0535 train loss:1.332 acc:56.67 | val loss:1.359 acc:67.20\r\n",
      "Epoch:0536 train loss:1.239 acc:60.00 | val loss:1.366 acc:67.40\r\n",
      "Epoch:0537 train loss:1.187 acc:70.83 | val loss:1.373 acc:66.40\r\n",
      "Epoch:0538 train loss:1.204 acc:57.50 | val loss:1.381 acc:65.60\r\n",
      "Epoch:0539 train loss:1.190 acc:57.50 | val loss:1.387 acc:64.80\r\n",
      "Epoch:0540 train loss:1.206 acc:60.00 | val loss:1.391 acc:64.20\r\n",
      "Epoch:0541 train loss:1.457 acc:56.67 | val loss:1.387 acc:65.80\r\n",
      "Epoch:0542 train loss:1.188 acc:55.83 | val loss:1.383 acc:67.20\r\n",
      "Epoch:0543 train loss:1.275 acc:55.83 | val loss:1.381 acc:67.80\r\n",
      "Epoch:0544 train loss:1.170 acc:62.50 | val loss:1.378 acc:68.80\r\n",
      "Epoch:0545 train loss:1.126 acc:67.50 | val loss:1.371 acc:70.20\r\n",
      "Epoch:0546 train loss:1.184 acc:65.83 | val loss:1.359 acc:70.60\r\n",
      "Epoch:0547 train loss:1.206 acc:58.33 | val loss:1.351 acc:71.00\r\n",
      "Epoch:0548 train loss:1.215 acc:65.00 | val loss:1.351 acc:70.20\r\n",
      "Epoch:0549 train loss:1.235 acc:62.50 | val loss:1.350 acc:69.60\r\n",
      "Epoch:0550 train loss:1.223 acc:60.83 | val loss:1.349 acc:70.00\r\n",
      "Epoch:0551 train loss:1.321 acc:50.83 | val loss:1.351 acc:69.80\r\n",
      "Epoch:0552 train loss:1.148 acc:65.00 | val loss:1.352 acc:70.40\r\n",
      "Epoch:0553 train loss:1.282 acc:60.00 | val loss:1.355 acc:70.20\r\n",
      "Epoch:0554 train loss:1.219 acc:54.17 | val loss:1.357 acc:70.60\r\n",
      "Epoch:0555 train loss:1.253 acc:55.00 | val loss:1.360 acc:70.60\r\n",
      "Epoch:0556 train loss:1.301 acc:61.67 | val loss:1.366 acc:70.20\r\n",
      "Epoch:0557 train loss:1.123 acc:64.17 | val loss:1.367 acc:69.60\r\n",
      "Epoch:0558 train loss:1.191 acc:71.67 | val loss:1.368 acc:70.00\r\n",
      "Epoch:0559 train loss:1.126 acc:60.83 | val loss:1.367 acc:69.20\r\n",
      "Epoch:0560 train loss:1.242 acc:60.83 | val loss:1.368 acc:69.00\r\n",
      "Epoch:0561 train loss:1.124 acc:63.33 | val loss:1.367 acc:68.60\r\n",
      "Epoch:0562 train loss:1.365 acc:60.83 | val loss:1.375 acc:68.00\r\n",
      "Epoch:0563 train loss:1.162 acc:65.00 | val loss:1.374 acc:67.80\r\n",
      "Epoch:0564 train loss:1.291 acc:50.83 | val loss:1.371 acc:66.60\r\n",
      "Epoch:0565 train loss:1.241 acc:62.50 | val loss:1.366 acc:66.80\r\n",
      "Epoch:0566 train loss:1.148 acc:64.17 | val loss:1.361 acc:67.40\r\n",
      "Epoch:0567 train loss:1.121 acc:63.33 | val loss:1.354 acc:66.80\r\n",
      "Epoch:0568 train loss:1.201 acc:55.83 | val loss:1.346 acc:68.20\r\n",
      "Epoch:0569 train loss:1.251 acc:58.33 | val loss:1.340 acc:68.80\r\n",
      "Epoch:0570 train loss:1.678 acc:59.17 | val loss:1.343 acc:68.60\r\n",
      "Epoch:0571 train loss:1.140 acc:63.33 | val loss:1.348 acc:68.60\r\n",
      "Epoch:0572 train loss:1.218 acc:62.50 | val loss:1.356 acc:67.60\r\n",
      "Epoch:0573 train loss:1.148 acc:62.50 | val loss:1.360 acc:66.60\r\n",
      "Epoch:0574 train loss:1.241 acc:59.17 | val loss:1.362 acc:65.60\r\n",
      "Epoch:0575 train loss:1.239 acc:65.00 | val loss:1.360 acc:66.00\r\n",
      "Epoch:0576 train loss:1.172 acc:62.50 | val loss:1.359 acc:66.00\r\n",
      "Epoch:0577 train loss:1.203 acc:58.33 | val loss:1.361 acc:67.20\r\n",
      "Epoch:0578 train loss:1.274 acc:58.33 | val loss:1.362 acc:67.40\r\n",
      "Epoch:0579 train loss:1.166 acc:62.50 | val loss:1.365 acc:68.80\r\n",
      "Epoch:0580 train loss:1.139 acc:69.17 | val loss:1.366 acc:68.60\r\n",
      "Epoch:0581 train loss:1.384 acc:56.67 | val loss:1.369 acc:68.80\r\n",
      "Epoch:0582 train loss:1.199 acc:60.83 | val loss:1.373 acc:67.60\r\n",
      "Epoch:0583 train loss:1.242 acc:60.83 | val loss:1.377 acc:67.40\r\n",
      "Epoch:0584 train loss:1.309 acc:62.50 | val loss:1.376 acc:67.60\r\n",
      "Epoch:0585 train loss:1.380 acc:62.50 | val loss:1.375 acc:68.00\r\n",
      "Epoch:0586 train loss:1.192 acc:65.83 | val loss:1.375 acc:67.80\r\n",
      "Epoch:0587 train loss:1.208 acc:61.67 | val loss:1.377 acc:66.80\r\n",
      "Epoch:0588 train loss:1.216 acc:60.00 | val loss:1.376 acc:66.00\r\n",
      "Epoch:0589 train loss:1.540 acc:59.17 | val loss:1.383 acc:66.00\r\n",
      "Epoch:0590 train loss:1.487 acc:59.17 | val loss:1.390 acc:65.20\r\n",
      "Epoch:0591 train loss:1.304 acc:56.67 | val loss:1.395 acc:65.60\r\n",
      "Epoch:0592 train loss:1.258 acc:50.83 | val loss:1.400 acc:66.60\r\n",
      "Epoch:0593 train loss:1.220 acc:63.33 | val loss:1.404 acc:68.80\r\n",
      "Epoch:0594 train loss:1.209 acc:60.00 | val loss:1.408 acc:69.00\r\n",
      "Epoch:0595 train loss:1.205 acc:59.17 | val loss:1.403 acc:69.20\r\n",
      "Epoch:0596 train loss:1.220 acc:60.83 | val loss:1.396 acc:69.80\r\n",
      "Epoch:0597 train loss:1.460 acc:57.50 | val loss:1.397 acc:68.80\r\n",
      "Epoch:0598 train loss:1.306 acc:56.67 | val loss:1.397 acc:69.20\r\n",
      "Epoch:0599 train loss:1.277 acc:57.50 | val loss:1.396 acc:69.00\r\n",
      "Epoch:0600 train loss:1.243 acc:57.50 | val loss:1.393 acc:69.00\r\n",
      "Epoch:0601 train loss:1.640 acc:59.17 | val loss:1.401 acc:68.40\r\n",
      "Epoch:0602 train loss:1.330 acc:53.33 | val loss:1.409 acc:67.60\r\n",
      "Epoch:0603 train loss:1.302 acc:58.33 | val loss:1.414 acc:67.00\r\n",
      "Epoch:0604 train loss:1.275 acc:56.67 | val loss:1.415 acc:67.60\r\n",
      "Epoch:0605 train loss:1.359 acc:49.17 | val loss:1.416 acc:66.80\r\n",
      "Epoch:0606 train loss:1.154 acc:65.83 | val loss:1.414 acc:67.00\r\n",
      "Epoch:0607 train loss:1.330 acc:56.67 | val loss:1.417 acc:66.40\r\n",
      "Epoch:0608 train loss:1.267 acc:58.33 | val loss:1.417 acc:65.40\r\n",
      "Epoch:0609 train loss:1.137 acc:62.50 | val loss:1.416 acc:65.60\r\n",
      "Epoch:0610 train loss:1.148 acc:67.50 | val loss:1.413 acc:64.60\r\n",
      "Epoch:0611 train loss:1.353 acc:59.17 | val loss:1.410 acc:64.40\r\n",
      "Epoch:0612 train loss:1.184 acc:70.83 | val loss:1.405 acc:65.20\r\n",
      "Epoch:0613 train loss:1.311 acc:61.67 | val loss:1.400 acc:65.60\r\n",
      "Epoch:0614 train loss:1.275 acc:60.00 | val loss:1.397 acc:64.20\r\n",
      "Epoch:0615 train loss:1.258 acc:59.17 | val loss:1.392 acc:64.20\r\n",
      "Epoch:0616 train loss:1.352 acc:54.17 | val loss:1.394 acc:64.20\r\n",
      "Epoch:0617 train loss:1.214 acc:60.00 | val loss:1.397 acc:64.40\r\n",
      "Epoch:0618 train loss:1.390 acc:59.17 | val loss:1.400 acc:64.60\r\n",
      "Epoch:0619 train loss:1.211 acc:62.50 | val loss:1.401 acc:66.80\r\n",
      "Epoch:0620 train loss:1.248 acc:63.33 | val loss:1.400 acc:69.00\r\n",
      "Epoch:0621 train loss:1.106 acc:66.67 | val loss:1.397 acc:69.80\r\n",
      "Epoch:0622 train loss:1.284 acc:62.50 | val loss:1.398 acc:69.00\r\n",
      "Epoch:0623 train loss:1.064 acc:70.00 | val loss:1.397 acc:69.00\r\n",
      "Epoch:0624 train loss:1.286 acc:60.00 | val loss:1.395 acc:67.40\r\n",
      "Epoch:0625 train loss:1.315 acc:59.17 | val loss:1.390 acc:68.60\r\n",
      "Epoch:0626 train loss:1.392 acc:56.67 | val loss:1.391 acc:70.00\r\n",
      "Epoch:0627 train loss:1.188 acc:61.67 | val loss:1.388 acc:70.20\r\n",
      "Epoch:0628 train loss:1.302 acc:64.17 | val loss:1.388 acc:69.80\r\n",
      "Epoch:0629 train loss:1.304 acc:55.83 | val loss:1.389 acc:69.00\r\n",
      "Epoch:0630 train loss:1.274 acc:63.33 | val loss:1.392 acc:68.20\r\n",
      "Epoch:0631 train loss:2.530 acc:60.83 | val loss:1.400 acc:67.80\r\n",
      "Epoch:0632 train loss:1.445 acc:56.67 | val loss:1.411 acc:66.60\r\n",
      "Epoch:0633 train loss:1.307 acc:60.00 | val loss:1.424 acc:64.20\r\n",
      "Epoch:0634 train loss:1.318 acc:54.17 | val loss:1.437 acc:61.20\r\n",
      "Epoch:0635 train loss:1.243 acc:65.83 | val loss:1.448 acc:59.00\r\n",
      "Epoch:0636 train loss:1.384 acc:61.67 | val loss:1.448 acc:59.40\r\n",
      "Epoch:0637 train loss:1.276 acc:59.17 | val loss:1.446 acc:59.40\r\n",
      "Epoch:0638 train loss:1.434 acc:60.00 | val loss:1.447 acc:59.20\r\n",
      "Epoch:0639 train loss:1.273 acc:58.33 | val loss:1.444 acc:60.20\r\n",
      "Epoch:0640 train loss:1.209 acc:58.33 | val loss:1.440 acc:61.60\r\n",
      "Epoch:0641 train loss:1.284 acc:55.00 | val loss:1.434 acc:62.60\r\n",
      "Epoch:0642 train loss:1.247 acc:65.83 | val loss:1.430 acc:63.60\r\n",
      "Epoch:0643 train loss:1.243 acc:55.83 | val loss:1.425 acc:65.40\r\n",
      "Epoch:0644 train loss:1.352 acc:55.00 | val loss:1.419 acc:65.20\r\n",
      "Epoch:0645 train loss:1.294 acc:66.67 | val loss:1.412 acc:65.60\r\n",
      "Epoch:0646 train loss:1.391 acc:50.00 | val loss:1.406 acc:65.60\r\n",
      "Epoch:0647 train loss:1.100 acc:63.33 | val loss:1.402 acc:66.20\r\n",
      "Epoch:0648 train loss:1.323 acc:57.50 | val loss:1.402 acc:66.80\r\n",
      "Epoch:0649 train loss:1.199 acc:64.17 | val loss:1.406 acc:66.60\r\n",
      "Epoch:0650 train loss:1.260 acc:57.50 | val loss:1.407 acc:66.80\r\n",
      "Epoch:0651 train loss:1.397 acc:50.00 | val loss:1.407 acc:66.80\r\n",
      "Epoch:0652 train loss:1.305 acc:59.17 | val loss:1.405 acc:67.60\r\n",
      "Epoch:0653 train loss:1.185 acc:62.50 | val loss:1.403 acc:67.60\r\n",
      "Epoch:0654 train loss:1.228 acc:60.00 | val loss:1.401 acc:68.60\r\n",
      "Epoch:0655 train loss:1.258 acc:61.67 | val loss:1.398 acc:68.40\r\n",
      "Epoch:0656 train loss:1.282 acc:69.17 | val loss:1.398 acc:69.00\r\n",
      "Epoch:0657 train loss:1.180 acc:63.33 | val loss:1.398 acc:70.00\r\n",
      "Epoch:0658 train loss:1.341 acc:55.00 | val loss:1.397 acc:70.60\r\n",
      "Epoch:0659 train loss:1.214 acc:64.17 | val loss:1.394 acc:70.40\r\n",
      "Epoch:0660 train loss:1.174 acc:63.33 | val loss:1.392 acc:71.00\r\n",
      "Epoch:0661 train loss:1.160 acc:64.17 | val loss:1.389 acc:69.40\r\n",
      "Epoch:0662 train loss:1.352 acc:53.33 | val loss:1.390 acc:69.00\r\n",
      "Epoch:0663 train loss:1.430 acc:54.17 | val loss:1.397 acc:69.20\r\n",
      "Epoch:0664 train loss:1.197 acc:60.83 | val loss:1.407 acc:68.20\r\n",
      "Epoch:0665 train loss:1.116 acc:63.33 | val loss:1.413 acc:67.80\r\n",
      "Epoch:0666 train loss:1.200 acc:60.00 | val loss:1.414 acc:67.00\r\n",
      "Epoch:0667 train loss:1.302 acc:50.83 | val loss:1.417 acc:67.20\r\n",
      "Epoch:0668 train loss:1.175 acc:70.83 | val loss:1.416 acc:67.80\r\n",
      "Epoch:0669 train loss:1.580 acc:60.00 | val loss:1.420 acc:68.60\r\n",
      "Epoch:0670 train loss:1.327 acc:55.83 | val loss:1.424 acc:68.60\r\n",
      "Epoch:0671 train loss:1.415 acc:56.67 | val loss:1.423 acc:70.60\r\n",
      "Epoch:0672 train loss:1.207 acc:58.33 | val loss:1.420 acc:72.00\r\n",
      "Epoch:0673 train loss:1.155 acc:65.00 | val loss:1.414 acc:71.80\r\n",
      "Epoch:0674 train loss:1.351 acc:47.50 | val loss:1.409 acc:71.00\r\n",
      "Epoch:0675 train loss:1.673 acc:52.50 | val loss:1.412 acc:69.80\r\n",
      "Epoch:0676 train loss:1.280 acc:60.83 | val loss:1.413 acc:68.80\r\n",
      "Epoch:0677 train loss:1.163 acc:65.83 | val loss:1.408 acc:69.20\r\n",
      "Epoch:0678 train loss:1.342 acc:58.33 | val loss:1.407 acc:68.80\r\n",
      "Epoch:0679 train loss:1.368 acc:60.83 | val loss:1.413 acc:69.00\r\n",
      "Epoch:0680 train loss:1.216 acc:58.33 | val loss:1.417 acc:68.80\r\n",
      "Epoch:0681 train loss:1.218 acc:64.17 | val loss:1.419 acc:68.20\r\n",
      "Epoch:0682 train loss:1.253 acc:59.17 | val loss:1.419 acc:68.40\r\n",
      "Epoch:0683 train loss:1.232 acc:58.33 | val loss:1.417 acc:67.80\r\n",
      "Epoch:0684 train loss:1.475 acc:50.00 | val loss:1.415 acc:67.80\r\n",
      "Epoch:0685 train loss:1.296 acc:54.17 | val loss:1.416 acc:69.00\r\n",
      "Epoch:0686 train loss:1.374 acc:60.83 | val loss:1.415 acc:68.60\r\n",
      "Epoch:0687 train loss:1.400 acc:52.50 | val loss:1.414 acc:68.80\r\n",
      "Epoch:0688 train loss:1.281 acc:59.17 | val loss:1.414 acc:69.20\r\n",
      "Epoch:0689 train loss:1.316 acc:60.00 | val loss:1.415 acc:68.80\r\n",
      "Epoch:0690 train loss:1.190 acc:61.67 | val loss:1.417 acc:67.80\r\n",
      "Epoch:0691 train loss:1.256 acc:51.67 | val loss:1.419 acc:65.60\r\n",
      "Epoch:0692 train loss:1.228 acc:56.67 | val loss:1.418 acc:64.80\r\n",
      "Epoch:0693 train loss:1.327 acc:47.50 | val loss:1.418 acc:64.60\r\n",
      "Epoch:0694 train loss:1.276 acc:58.33 | val loss:1.415 acc:65.60\r\n",
      "Epoch:0695 train loss:1.288 acc:62.50 | val loss:1.412 acc:65.00\r\n",
      "Epoch:0696 train loss:1.293 acc:60.83 | val loss:1.406 acc:65.60\r\n",
      "Epoch:0697 train loss:1.343 acc:55.83 | val loss:1.405 acc:66.20\r\n",
      "Epoch:0698 train loss:1.313 acc:55.83 | val loss:1.407 acc:67.00\r\n",
      "Epoch:0699 train loss:1.265 acc:63.33 | val loss:1.408 acc:66.80\r\n",
      "Epoch:0700 train loss:1.366 acc:55.83 | val loss:1.410 acc:66.80\r\n",
      "Epoch:0701 train loss:1.137 acc:61.67 | val loss:1.409 acc:66.40\r\n",
      "Epoch:0702 train loss:1.439 acc:55.83 | val loss:1.417 acc:66.20\r\n",
      "Epoch:0703 train loss:1.351 acc:50.83 | val loss:1.426 acc:65.20\r\n",
      "Epoch:0704 train loss:1.166 acc:65.83 | val loss:1.426 acc:63.80\r\n",
      "Epoch:0705 train loss:1.159 acc:65.00 | val loss:1.423 acc:63.60\r\n",
      "Epoch:0706 train loss:1.254 acc:56.67 | val loss:1.417 acc:64.80\r\n",
      "Epoch:0707 train loss:1.390 acc:62.50 | val loss:1.417 acc:64.80\r\n",
      "Epoch:0708 train loss:1.239 acc:56.67 | val loss:1.414 acc:65.00\r\n",
      "Epoch:0709 train loss:1.378 acc:55.83 | val loss:1.405 acc:68.80\r\n",
      "Epoch:0710 train loss:1.319 acc:53.33 | val loss:1.400 acc:69.20\r\n",
      "Epoch:0711 train loss:1.261 acc:55.83 | val loss:1.397 acc:70.20\r\n",
      "Epoch:0712 train loss:1.237 acc:64.17 | val loss:1.394 acc:70.60\r\n",
      "Epoch:0713 train loss:1.301 acc:60.83 | val loss:1.392 acc:71.00\r\n",
      "Epoch:0714 train loss:1.255 acc:60.00 | val loss:1.392 acc:70.60\r\n",
      "Epoch:0715 train loss:1.291 acc:58.33 | val loss:1.392 acc:70.00\r\n",
      "Epoch:0716 train loss:1.303 acc:54.17 | val loss:1.394 acc:69.40\r\n",
      "Epoch:0717 train loss:1.182 acc:65.83 | val loss:1.395 acc:69.60\r\n",
      "Epoch:0718 train loss:1.241 acc:60.00 | val loss:1.396 acc:68.60\r\n",
      "Epoch:0719 train loss:1.282 acc:55.83 | val loss:1.398 acc:67.60\r\n",
      "Epoch:0720 train loss:1.141 acc:63.33 | val loss:1.397 acc:66.20\r\n",
      "Epoch:0721 train loss:1.238 acc:64.17 | val loss:1.398 acc:65.80\r\n",
      "Epoch:0722 train loss:1.254 acc:67.50 | val loss:1.401 acc:65.80\r\n",
      "Epoch:0723 train loss:1.275 acc:50.83 | val loss:1.401 acc:65.60\r\n",
      "Epoch:0724 train loss:1.638 acc:55.83 | val loss:1.403 acc:65.40\r\n",
      "Epoch:0725 train loss:1.192 acc:58.33 | val loss:1.401 acc:65.80\r\n",
      "Epoch:0726 train loss:1.442 acc:54.17 | val loss:1.409 acc:64.00\r\n",
      "Epoch:0727 train loss:1.276 acc:60.83 | val loss:1.414 acc:64.00\r\n",
      "Epoch:0728 train loss:1.228 acc:54.17 | val loss:1.414 acc:64.80\r\n",
      "Epoch:0729 train loss:1.280 acc:61.67 | val loss:1.417 acc:65.00\r\n",
      "Epoch:0730 train loss:1.275 acc:54.17 | val loss:1.423 acc:65.00\r\n",
      "Epoch:0731 train loss:1.344 acc:50.83 | val loss:1.428 acc:65.80\r\n",
      "Epoch:0732 train loss:1.254 acc:62.50 | val loss:1.429 acc:66.00\r\n",
      "Epoch:0733 train loss:1.302 acc:58.33 | val loss:1.432 acc:66.40\r\n",
      "Epoch:0734 train loss:1.228 acc:59.17 | val loss:1.437 acc:65.60\r\n",
      "Epoch:0735 train loss:1.186 acc:64.17 | val loss:1.441 acc:65.40\r\n",
      "Epoch:0736 train loss:1.928 acc:57.50 | val loss:1.446 acc:66.40\r\n",
      "Epoch:0737 train loss:1.361 acc:62.50 | val loss:1.449 acc:65.00\r\n",
      "Epoch:0738 train loss:1.217 acc:60.83 | val loss:1.449 acc:64.80\r\n",
      "Epoch:0739 train loss:1.318 acc:58.33 | val loss:1.446 acc:65.20\r\n",
      "Epoch:0740 train loss:1.245 acc:65.83 | val loss:1.441 acc:64.80\r\n",
      "Epoch:0741 train loss:1.169 acc:55.00 | val loss:1.435 acc:65.60\r\n",
      "Epoch:0742 train loss:1.234 acc:55.83 | val loss:1.425 acc:66.80\r\n",
      "Epoch:0743 train loss:1.269 acc:55.83 | val loss:1.415 acc:67.40\r\n",
      "Epoch:0744 train loss:1.297 acc:60.00 | val loss:1.404 acc:68.20\r\n",
      "Epoch:0745 train loss:1.331 acc:60.83 | val loss:1.396 acc:69.40\r\n",
      "Epoch:0746 train loss:1.193 acc:60.83 | val loss:1.385 acc:70.60\r\n",
      "Epoch:0747 train loss:1.229 acc:63.33 | val loss:1.374 acc:70.20\r\n",
      "Epoch:0748 train loss:1.429 acc:55.00 | val loss:1.370 acc:70.60\r\n",
      "Epoch:0749 train loss:1.387 acc:56.67 | val loss:1.369 acc:71.60\r\n",
      "Epoch:0750 train loss:1.238 acc:56.67 | val loss:1.366 acc:71.20\r\n",
      "Epoch:0751 train loss:1.218 acc:58.33 | val loss:1.361 acc:71.20\r\n",
      "Epoch:0752 train loss:1.229 acc:57.50 | val loss:1.357 acc:71.00\r\n",
      "Epoch:0753 train loss:1.266 acc:56.67 | val loss:1.353 acc:71.00\r\n",
      "Epoch:0754 train loss:1.378 acc:61.67 | val loss:1.353 acc:70.80\r\n",
      "Epoch:0755 train loss:1.289 acc:55.00 | val loss:1.355 acc:71.20\r\n",
      "Epoch:0756 train loss:1.244 acc:55.83 | val loss:1.359 acc:71.80\r\n",
      "Epoch:0757 train loss:1.292 acc:56.67 | val loss:1.363 acc:71.00\r\n",
      "Epoch:0758 train loss:1.370 acc:55.00 | val loss:1.372 acc:69.60\r\n",
      "Epoch:0759 train loss:1.200 acc:60.83 | val loss:1.384 acc:67.80\r\n",
      "Epoch:0760 train loss:1.244 acc:55.00 | val loss:1.395 acc:66.80\r\n",
      "Epoch:0761 train loss:1.332 acc:55.83 | val loss:1.400 acc:67.20\r\n",
      "Epoch:0762 train loss:1.137 acc:62.50 | val loss:1.406 acc:67.40\r\n",
      "Epoch:0763 train loss:1.116 acc:69.17 | val loss:1.407 acc:67.00\r\n",
      "Epoch:0764 train loss:1.298 acc:61.67 | val loss:1.404 acc:67.40\r\n",
      "Epoch:0765 train loss:1.194 acc:54.17 | val loss:1.404 acc:67.80\r\n",
      "Epoch:0766 train loss:1.222 acc:59.17 | val loss:1.404 acc:68.40\r\n",
      "Epoch:0767 train loss:1.253 acc:60.83 | val loss:1.403 acc:69.20\r\n",
      "Epoch:0768 train loss:1.344 acc:47.50 | val loss:1.406 acc:69.20\r\n",
      "Epoch:0769 train loss:1.312 acc:60.00 | val loss:1.408 acc:69.80\r\n",
      "Epoch:0770 train loss:1.249 acc:58.33 | val loss:1.411 acc:70.20\r\n",
      "Epoch:0771 train loss:1.243 acc:65.00 | val loss:1.414 acc:69.40\r\n",
      "Epoch:0772 train loss:1.114 acc:69.17 | val loss:1.414 acc:68.40\r\n",
      "Epoch:0773 train loss:1.251 acc:55.00 | val loss:1.412 acc:67.20\r\n",
      "Epoch:0774 train loss:1.220 acc:56.67 | val loss:1.413 acc:66.40\r\n",
      "Epoch:0775 train loss:1.276 acc:57.50 | val loss:1.414 acc:66.20\r\n",
      "Epoch:0776 train loss:1.142 acc:60.83 | val loss:1.410 acc:66.20\r\n",
      "Epoch:0777 train loss:1.237 acc:60.00 | val loss:1.403 acc:67.20\r\n",
      "Epoch:0778 train loss:1.182 acc:66.67 | val loss:1.395 acc:68.20\r\n",
      "Epoch:0779 train loss:1.206 acc:61.67 | val loss:1.386 acc:68.80\r\n",
      "Epoch:0780 train loss:1.340 acc:55.83 | val loss:1.384 acc:69.40\r\n",
      "Epoch:0781 train loss:1.339 acc:49.17 | val loss:1.385 acc:68.60\r\n",
      "Epoch:0782 train loss:1.098 acc:59.17 | val loss:1.386 acc:68.20\r\n",
      "Epoch:0783 train loss:1.233 acc:55.00 | val loss:1.388 acc:68.20\r\n",
      "Epoch:0784 train loss:1.397 acc:60.83 | val loss:1.400 acc:68.00\r\n",
      "Epoch:0785 train loss:1.176 acc:63.33 | val loss:1.407 acc:67.60\r\n",
      "Epoch:0786 train loss:1.164 acc:64.17 | val loss:1.414 acc:67.20\r\n",
      "Epoch:0787 train loss:1.140 acc:62.50 | val loss:1.413 acc:67.20\r\n",
      "Epoch:0788 train loss:1.605 acc:50.83 | val loss:1.413 acc:67.00\r\n",
      "Epoch:0789 train loss:1.299 acc:59.17 | val loss:1.416 acc:66.20\r\n",
      "Epoch:0790 train loss:1.139 acc:64.17 | val loss:1.417 acc:65.40\r\n",
      "Epoch:0791 train loss:1.257 acc:58.33 | val loss:1.416 acc:65.80\r\n",
      "Epoch:0792 train loss:1.209 acc:55.83 | val loss:1.416 acc:66.40\r\n",
      "Epoch:0793 train loss:1.220 acc:58.33 | val loss:1.412 acc:66.80\r\n",
      "Epoch:0794 train loss:1.265 acc:60.00 | val loss:1.406 acc:67.40\r\n",
      "Epoch:0795 train loss:1.249 acc:61.67 | val loss:1.400 acc:69.40\r\n",
      "Epoch:0796 train loss:1.382 acc:58.33 | val loss:1.401 acc:70.00\r\n",
      "Epoch:0797 train loss:1.212 acc:57.50 | val loss:1.400 acc:70.20\r\n",
      "Epoch:0798 train loss:1.369 acc:52.50 | val loss:1.408 acc:70.40\r\n",
      "Epoch:0799 train loss:1.127 acc:64.17 | val loss:1.415 acc:68.80\r\n",
      "Epoch:0800 train loss:1.233 acc:63.33 | val loss:1.420 acc:67.60\r\n",
      "Epoch:0801 train loss:1.295 acc:58.33 | val loss:1.429 acc:64.40\r\n",
      "Epoch:0802 train loss:1.326 acc:54.17 | val loss:1.436 acc:62.60\r\n",
      "Epoch:0803 train loss:1.223 acc:56.67 | val loss:1.440 acc:62.80\r\n",
      "Epoch:0804 train loss:1.377 acc:57.50 | val loss:1.454 acc:60.60\r\n",
      "Epoch:0805 train loss:1.297 acc:54.17 | val loss:1.464 acc:58.80\r\n",
      "Epoch:0806 train loss:1.157 acc:65.83 | val loss:1.468 acc:58.20\r\n",
      "Epoch:0807 train loss:1.217 acc:60.00 | val loss:1.467 acc:60.00\r\n",
      "Epoch:0808 train loss:1.190 acc:60.83 | val loss:1.459 acc:60.40\r\n",
      "Epoch:0809 train loss:1.341 acc:50.00 | val loss:1.449 acc:62.00\r\n",
      "Epoch:0810 train loss:1.245 acc:60.00 | val loss:1.439 acc:62.60\r\n",
      "Epoch:0811 train loss:1.329 acc:65.83 | val loss:1.431 acc:64.60\r\n",
      "Epoch:0812 train loss:1.259 acc:68.33 | val loss:1.425 acc:66.00\r\n",
      "Epoch:0813 train loss:1.289 acc:55.83 | val loss:1.419 acc:68.40\r\n",
      "Epoch:0814 train loss:1.389 acc:60.83 | val loss:1.416 acc:68.80\r\n",
      "Epoch:0815 train loss:1.195 acc:66.67 | val loss:1.412 acc:69.60\r\n",
      "Epoch:0816 train loss:1.195 acc:61.67 | val loss:1.408 acc:70.00\r\n",
      "Epoch:0817 train loss:1.221 acc:70.00 | val loss:1.402 acc:69.80\r\n",
      "Epoch:0818 train loss:1.193 acc:55.83 | val loss:1.396 acc:70.20\r\n",
      "Epoch:0819 train loss:1.262 acc:64.17 | val loss:1.391 acc:69.40\r\n",
      "Epoch:0820 train loss:1.233 acc:60.83 | val loss:1.385 acc:69.00\r\n",
      "Epoch:0821 train loss:1.269 acc:59.17 | val loss:1.382 acc:68.80\r\n",
      "Epoch:0822 train loss:1.269 acc:58.33 | val loss:1.381 acc:67.20\r\n",
      "Epoch:0823 train loss:1.262 acc:55.00 | val loss:1.378 acc:67.20\r\n",
      "Epoch:0824 train loss:1.268 acc:58.33 | val loss:1.375 acc:67.40\r\n",
      "Epoch:0825 train loss:1.265 acc:55.83 | val loss:1.373 acc:67.80\r\n",
      "Epoch:0826 train loss:1.383 acc:57.50 | val loss:1.376 acc:67.60\r\n",
      "Epoch:0827 train loss:1.227 acc:62.50 | val loss:1.378 acc:67.20\r\n",
      "Epoch:0828 train loss:1.287 acc:53.33 | val loss:1.381 acc:66.20\r\n",
      "Epoch:0829 train loss:1.297 acc:49.17 | val loss:1.383 acc:65.80\r\n",
      "Epoch:0830 train loss:1.185 acc:54.17 | val loss:1.387 acc:65.60\r\n",
      "Epoch:0831 train loss:1.422 acc:52.50 | val loss:1.395 acc:65.40\r\n",
      "Epoch:0832 train loss:1.217 acc:54.17 | val loss:1.401 acc:63.60\r\n",
      "Epoch:0833 train loss:1.196 acc:65.83 | val loss:1.406 acc:63.00\r\n",
      "Epoch:0834 train loss:1.212 acc:58.33 | val loss:1.411 acc:60.80\r\n",
      "Epoch:0835 train loss:1.290 acc:49.17 | val loss:1.413 acc:60.20\r\n",
      "Epoch:0836 train loss:1.132 acc:64.17 | val loss:1.412 acc:59.40\r\n",
      "Epoch:0837 train loss:1.223 acc:57.50 | val loss:1.409 acc:58.80\r\n",
      "Epoch:0838 train loss:1.245 acc:55.00 | val loss:1.405 acc:60.40\r\n",
      "Epoch:0839 train loss:1.147 acc:60.00 | val loss:1.399 acc:60.80\r\n",
      "Epoch:0840 train loss:1.323 acc:60.00 | val loss:1.399 acc:62.40\r\n",
      "Epoch:0841 train loss:1.199 acc:65.00 | val loss:1.396 acc:63.40\r\n",
      "Epoch:0842 train loss:1.243 acc:55.00 | val loss:1.391 acc:65.00\r\n",
      "Epoch:0843 train loss:1.284 acc:65.00 | val loss:1.386 acc:67.40\r\n",
      "Epoch:0844 train loss:1.293 acc:59.17 | val loss:1.383 acc:68.80\r\n",
      "Epoch:0845 train loss:1.155 acc:62.50 | val loss:1.379 acc:68.80\r\n",
      "Epoch:0846 train loss:1.129 acc:64.17 | val loss:1.373 acc:68.20\r\n",
      "Epoch:0847 train loss:1.151 acc:59.17 | val loss:1.368 acc:68.80\r\n",
      "Epoch:0848 train loss:1.252 acc:65.00 | val loss:1.367 acc:70.40\r\n",
      "Epoch:0849 train loss:1.245 acc:59.17 | val loss:1.371 acc:68.80\r\n",
      "Epoch:0850 train loss:1.190 acc:60.00 | val loss:1.374 acc:67.80\r\n",
      "Epoch:0851 train loss:1.399 acc:60.83 | val loss:1.379 acc:67.20\r\n",
      "Epoch:0852 train loss:1.213 acc:60.00 | val loss:1.379 acc:67.00\r\n",
      "Epoch:0853 train loss:1.190 acc:63.33 | val loss:1.379 acc:66.80\r\n",
      "Epoch:0854 train loss:1.236 acc:55.00 | val loss:1.376 acc:66.00\r\n",
      "Epoch:0855 train loss:1.178 acc:58.33 | val loss:1.372 acc:66.80\r\n",
      "Epoch:0856 train loss:1.330 acc:57.50 | val loss:1.371 acc:69.00\r\n",
      "Epoch:0857 train loss:1.250 acc:60.00 | val loss:1.370 acc:69.80\r\n",
      "Epoch:0858 train loss:1.204 acc:61.67 | val loss:1.369 acc:70.80\r\n",
      "Epoch:0859 train loss:1.220 acc:60.83 | val loss:1.369 acc:71.20\r\n",
      "Epoch:0860 train loss:1.179 acc:64.17 | val loss:1.370 acc:71.00\r\n",
      "Epoch:0861 train loss:1.205 acc:60.83 | val loss:1.369 acc:71.20\r\n",
      "Epoch:0862 train loss:1.334 acc:59.17 | val loss:1.373 acc:70.60\r\n",
      "Epoch:0863 train loss:1.212 acc:61.67 | val loss:1.377 acc:70.60\r\n",
      "Epoch:0864 train loss:1.279 acc:57.50 | val loss:1.380 acc:69.60\r\n",
      "Epoch:0865 train loss:1.215 acc:55.83 | val loss:1.380 acc:69.00\r\n",
      "Epoch:0866 train loss:1.085 acc:68.33 | val loss:1.381 acc:67.00\r\n",
      "Epoch:0867 train loss:1.401 acc:55.83 | val loss:1.385 acc:66.20\r\n",
      "Epoch:0868 train loss:1.245 acc:60.00 | val loss:1.388 acc:65.40\r\n",
      "Epoch:0869 train loss:1.193 acc:60.00 | val loss:1.394 acc:64.80\r\n",
      "Epoch:0870 train loss:1.181 acc:60.00 | val loss:1.398 acc:64.60\r\n",
      "Epoch:0871 train loss:1.217 acc:55.83 | val loss:1.402 acc:64.40\r\n",
      "Epoch:0872 train loss:1.184 acc:60.83 | val loss:1.406 acc:63.40\r\n",
      "Epoch:0873 train loss:1.269 acc:55.83 | val loss:1.402 acc:62.60\r\n",
      "Epoch:0874 train loss:1.190 acc:60.00 | val loss:1.395 acc:64.20\r\n",
      "Epoch:0875 train loss:1.218 acc:61.67 | val loss:1.391 acc:64.60\r\n",
      "Epoch:0876 train loss:1.235 acc:63.33 | val loss:1.392 acc:64.20\r\n",
      "Epoch:0877 train loss:1.249 acc:60.83 | val loss:1.392 acc:64.00\r\n",
      "Epoch:0878 train loss:1.608 acc:57.50 | val loss:1.392 acc:64.40\r\n",
      "Epoch:0879 train loss:1.299 acc:53.33 | val loss:1.389 acc:65.00\r\n",
      "Epoch:0880 train loss:1.135 acc:62.50 | val loss:1.382 acc:65.80\r\n",
      "Epoch:0881 train loss:1.162 acc:64.17 | val loss:1.372 acc:66.60\r\n",
      "Epoch:0882 train loss:1.172 acc:60.83 | val loss:1.361 acc:68.00\r\n",
      "Epoch:0883 train loss:1.170 acc:56.67 | val loss:1.352 acc:68.60\r\n",
      "Epoch:0884 train loss:1.359 acc:47.50 | val loss:1.351 acc:70.20\r\n",
      "Epoch:0885 train loss:1.204 acc:56.67 | val loss:1.350 acc:70.80\r\n",
      "Epoch:0886 train loss:1.232 acc:52.50 | val loss:1.348 acc:70.60\r\n",
      "Epoch:0887 train loss:1.333 acc:61.67 | val loss:1.353 acc:70.20\r\n",
      "Epoch:0888 train loss:1.183 acc:59.17 | val loss:1.356 acc:71.20\r\n",
      "Epoch:0889 train loss:1.157 acc:63.33 | val loss:1.359 acc:71.60\r\n",
      "Epoch:0890 train loss:1.280 acc:58.33 | val loss:1.366 acc:72.00\r\n",
      "Epoch:0891 train loss:1.201 acc:54.17 | val loss:1.371 acc:70.40\r\n",
      "Epoch:0892 train loss:1.292 acc:56.67 | val loss:1.376 acc:69.40\r\n",
      "Epoch:0893 train loss:1.069 acc:69.17 | val loss:1.379 acc:69.00\r\n",
      "Epoch:0894 train loss:1.251 acc:56.67 | val loss:1.382 acc:68.20\r\n",
      "Epoch:0895 train loss:1.823 acc:55.83 | val loss:1.389 acc:69.80\r\n",
      "Epoch:0896 train loss:1.276 acc:53.33 | val loss:1.399 acc:68.60\r\n",
      "Epoch:0897 train loss:1.209 acc:62.50 | val loss:1.402 acc:68.40\r\n",
      "Epoch:0898 train loss:1.320 acc:50.83 | val loss:1.405 acc:69.20\r\n",
      "Epoch:0899 train loss:1.208 acc:60.00 | val loss:1.406 acc:69.80\r\n",
      "Epoch:0900 train loss:1.341 acc:54.17 | val loss:1.410 acc:69.40\r\n",
      "Epoch:0901 train loss:1.226 acc:60.83 | val loss:1.412 acc:68.20\r\n",
      "Epoch:0902 train loss:1.343 acc:60.00 | val loss:1.417 acc:67.00\r\n",
      "Epoch:0903 train loss:1.257 acc:59.17 | val loss:1.420 acc:66.00\r\n",
      "Epoch:0904 train loss:1.391 acc:55.83 | val loss:1.435 acc:64.00\r\n",
      "Epoch:0905 train loss:1.517 acc:60.00 | val loss:1.452 acc:59.80\r\n",
      "Epoch:0906 train loss:1.377 acc:54.17 | val loss:1.462 acc:58.20\r\n",
      "Epoch:0907 train loss:1.244 acc:60.00 | val loss:1.463 acc:59.40\r\n",
      "Epoch:0908 train loss:1.247 acc:56.67 | val loss:1.460 acc:59.80\r\n",
      "Epoch:0909 train loss:1.232 acc:55.83 | val loss:1.453 acc:62.20\r\n",
      "Epoch:0910 train loss:1.298 acc:57.50 | val loss:1.443 acc:63.60\r\n",
      "Epoch:0911 train loss:1.410 acc:63.33 | val loss:1.432 acc:66.20\r\n",
      "Epoch:0912 train loss:1.348 acc:50.83 | val loss:1.419 acc:68.00\r\n",
      "Epoch:0913 train loss:1.300 acc:52.50 | val loss:1.408 acc:70.00\r\n",
      "Epoch:0914 train loss:1.344 acc:57.50 | val loss:1.402 acc:71.20\r\n",
      "Epoch:0915 train loss:1.251 acc:64.17 | val loss:1.396 acc:71.20\r\n",
      "Epoch:0916 train loss:1.707 acc:56.67 | val loss:1.394 acc:71.80\r\n",
      "Epoch:0917 train loss:1.261 acc:57.50 | val loss:1.396 acc:71.20\r\n",
      "Epoch:0918 train loss:1.435 acc:54.17 | val loss:1.405 acc:70.20\r\n",
      "Epoch:0919 train loss:1.384 acc:59.17 | val loss:1.420 acc:69.20\r\n",
      "Epoch:0920 train loss:1.228 acc:58.33 | val loss:1.434 acc:66.80\r\n",
      "Epoch:0921 train loss:1.258 acc:62.50 | val loss:1.442 acc:63.80\r\n",
      "Epoch:0922 train loss:1.164 acc:65.83 | val loss:1.444 acc:62.80\r\n",
      "Epoch:0923 train loss:1.375 acc:56.67 | val loss:1.446 acc:61.80\r\n",
      "Epoch:0924 train loss:1.200 acc:55.83 | val loss:1.447 acc:61.60\r\n",
      "Epoch:0925 train loss:1.267 acc:60.83 | val loss:1.446 acc:59.60\r\n",
      "Epoch:0926 train loss:1.144 acc:71.67 | val loss:1.443 acc:60.40\r\n",
      "Epoch:0927 train loss:1.329 acc:59.17 | val loss:1.443 acc:59.40\r\n",
      "Epoch:0928 train loss:1.322 acc:59.17 | val loss:1.442 acc:59.40\r\n",
      "Epoch:0929 train loss:1.227 acc:62.50 | val loss:1.437 acc:60.00\r\n",
      "Epoch:0930 train loss:1.371 acc:48.33 | val loss:1.432 acc:59.80\r\n",
      "Epoch:0931 train loss:1.191 acc:58.33 | val loss:1.425 acc:60.80\r\n",
      "Epoch:0932 train loss:1.463 acc:65.83 | val loss:1.429 acc:61.00\r\n",
      "Epoch:0933 train loss:1.229 acc:67.50 | val loss:1.425 acc:62.00\r\n",
      "Epoch:0934 train loss:1.254 acc:54.17 | val loss:1.418 acc:63.00\r\n",
      "Epoch:0935 train loss:1.320 acc:54.17 | val loss:1.406 acc:66.40\r\n",
      "Epoch:0936 train loss:1.252 acc:55.00 | val loss:1.395 acc:66.60\r\n",
      "Epoch:0937 train loss:1.248 acc:59.17 | val loss:1.388 acc:67.60\r\n",
      "Epoch:0938 train loss:1.279 acc:55.00 | val loss:1.382 acc:69.20\r\n",
      "Epoch:0939 train loss:1.304 acc:50.83 | val loss:1.379 acc:69.20\r\n",
      "Epoch:0940 train loss:1.308 acc:52.50 | val loss:1.379 acc:68.80\r\n",
      "Epoch:0941 train loss:1.243 acc:60.83 | val loss:1.375 acc:70.20\r\n",
      "Epoch:0942 train loss:1.261 acc:55.83 | val loss:1.375 acc:69.80\r\n",
      "Epoch:0943 train loss:1.281 acc:55.00 | val loss:1.373 acc:69.80\r\n",
      "Epoch:0944 train loss:1.319 acc:56.67 | val loss:1.378 acc:70.00\r\n",
      "Epoch:0945 train loss:1.388 acc:58.33 | val loss:1.386 acc:70.00\r\n",
      "Epoch:0946 train loss:1.256 acc:62.50 | val loss:1.397 acc:68.60\r\n",
      "Load 394th epoch\r\n",
      "Test acc.:74.9\r\n"
     ]
    }
   ],
   "source": [
    "best_num_layers = int(a[0])\n",
    "best_optim = int(a[1])\n",
    "best_al = int(a[2])\n",
    "best_act = int(a[3])\n",
    "best_earlystop = int(a[4])\n",
    "best_epoch1 = int(a[5])\n",
    "best_hidden_dim = int(a[6])\n",
    "best_variant = a[7]\n",
    "\n",
    "best_alpha = a[8]\n",
    "best_lamda = a[9]\n",
    "best_dropout = a[10]\n",
    "best_lr = a[11]\n",
    "best_weight_decay_1 = a[12]\n",
    "best_weight_decay_2 = a[13]\n",
    "start_time = time.time()\n",
    "best_test_acc_list=[]\n",
    "for k in range(repeat):\n",
    "    if best_al==0 and best_variant==0:\n",
    "        !python -u trainshow.py --data citeseer --layer {best_num_layers} --hidden {best_hidden_dim} --dropout {best_dropout} --wd1 {best_weight_decay_1} --wd2 {best_weight_decay_2} --lr {best_lr} --op {best_optim}  --act_fn {best_act} --epochs  {best_epoch1} --patience {best_earlystop} --test  \n",
    "    elif best_al==1 and best_variant==0:\n",
    "        !python -u trainshow.py --data citeseer --layer {best_num_layers} --hidden {best_hidden_dim} --dropout {best_dropout} --wd1 {best_weight_decay_1} --wd2 {best_weight_decay_2} --lr {best_lr} --op {best_optim}  --act_fn {best_act} --epochs  {best_epoch1} --patience {best_earlystop} --lamda {best_lamda} --alpha {best_alpha} --test  \n",
    "    elif best_al==0 and best_variant==1:\n",
    "        !python -u trainshow.py --data citeseer --layer {best_num_layers} --hidden {best_hidden_dim} --dropout {best_dropout} --wd1 {best_weight_decay_1} --wd2 {best_weight_decay_2} --lr {best_lr} --op {best_optim}  --act_fn {best_act} --epochs  {best_epoch1} --patience {best_earlystop} --test --variant  \n",
    "    else:\n",
    "        !python -u trainshow.py --data citeseer --layer {best_num_layers} --hidden {best_hidden_dim} --dropout {best_dropout} --wd1 {best_weight_decay_1} --wd2 {best_weight_decay_2} --lr {best_lr} --op {best_optim}  --act_fn {best_act} --epochs  {best_epoch1} --patience {best_earlystop} --lamda {best_lamda} --alpha {best_alpha} --test --variant  \n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f53d882a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T11:58:24.276966Z",
     "iopub.status.busy": "2024-04-21T11:58:24.276623Z",
     "iopub.status.idle": "2024-04-21T11:58:24.284427Z",
     "shell.execute_reply": "2024-04-21T11:58:24.283559Z"
    },
    "papermill": {
     "duration": 0.155829,
     "end_time": "2024-04-21T11:58:24.286458",
     "exception": false,
     "start_time": "2024-04-21T11:58:24.130629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "citeseer\n",
      "best_num_layers: 62\n",
      "best_optim: 0\n",
      "best_al: 1\n",
      "best_act: 0\n",
      "best_earlystop: 552\n",
      "best_epoch1: 1554\n",
      "best_hidden_dim: 121\n",
      "best_variant: 1\n",
      "---------\n",
      "best_alpha: 0.195334309177027\n",
      "best_lamda: 0.48615645105443256\n",
      "best_dropout: 0.7386975650911543\n",
      "best_lr: 0.020170958845385403\n",
      "best_weight_decay_1: 0.01569140756748541\n",
      "best_weight_decay_2: 0.0005012998933592893\n",
      "---------\n",
      ": 121.98792457580566\n"
     ]
    }
   ],
   "source": [
    "print(\"citeseer\")\n",
    "print(f\"best_num_layers: {best_num_layers}\")\n",
    "print(f\"best_optim: {best_optim}\")\n",
    "print(f\"best_al: {best_al}\")\n",
    "print(f\"best_act: {best_act}\")\n",
    "print(f\"best_earlystop: {best_earlystop}\")\n",
    "print(f\"best_epoch1: {best_epoch1}\")\n",
    "print(f\"best_hidden_dim: {best_hidden_dim}\")\n",
    "print(f\"best_variant: {best_variant}\")\n",
    "print(\"---------\")\n",
    "print(f\"best_alpha: {best_alpha}\")\n",
    "print(f\"best_lamda: {best_lamda}\")\n",
    "print(f\"best_dropout: {best_dropout}\")\n",
    "print(f\"best_lr: {best_lr}\")\n",
    "print(f\"best_weight_decay_1: {best_weight_decay_1}\")\n",
    "print(f\"best_weight_decay_2: {best_weight_decay_2}\")\n",
    "print(\"---------\")\n",
    "print(\":\", (end_time-start_time)/repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd20f58c",
   "metadata": {
    "papermill": {
     "duration": 0.144313,
     "end_time": "2024-04-21T11:58:24.574462",
     "exception": false,
     "start_time": "2024-04-21T11:58:24.430149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "for pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66386478",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T11:58:24.866728Z",
     "iopub.status.busy": "2024-04-21T11:58:24.865913Z",
     "iopub.status.idle": "2024-04-21T11:58:24.870854Z",
     "shell.execute_reply": "2024-04-21T11:58:24.869996Z"
    },
    "papermill": {
     "duration": 0.151774,
     "end_time": "2024-04-21T11:58:24.872704",
     "exception": false,
     "start_time": "2024-04-21T11:58:24.720930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a=(28, 0, 0, 1, 91, 576, 291, 0, 0.4916403085983449, 0.13254427692885368, 0.5552673229693162, 0.03943938762434759, 0.003367028684054662, 0.0005004352979650606)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10ee02a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T11:58:25.164431Z",
     "iopub.status.busy": "2024-04-21T11:58:25.164086Z",
     "iopub.status.idle": "2024-04-21T11:59:25.757394Z",
     "shell.execute_reply": "2024-04-21T11:59:25.756487Z"
    },
    "papermill": {
     "duration": 60.742527,
     "end_time": "2024-04-21T11:59:25.759852",
     "exception": false,
     "start_time": "2024-04-21T11:58:25.017325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0000 train loss:1.097 acc:41.67 | val loss:1.116 acc:19.60\r\n",
      "Epoch:0001 train loss:1.087 acc:40.00 | val loss:1.041 acc:73.00\r\n",
      "Epoch:0002 train loss:1.028 acc:55.00 | val loss:0.986 acc:73.40\r\n",
      "Epoch:0003 train loss:0.934 acc:80.00 | val loss:0.939 acc:72.80\r\n",
      "Epoch:0004 train loss:0.872 acc:70.00 | val loss:0.867 acc:73.20\r\n",
      "Epoch:0005 train loss:0.824 acc:70.00 | val loss:0.814 acc:73.20\r\n",
      "Epoch:0006 train loss:0.722 acc:80.00 | val loss:0.736 acc:74.60\r\n",
      "Epoch:0007 train loss:0.548 acc:90.00 | val loss:0.706 acc:76.00\r\n",
      "Epoch:0008 train loss:0.527 acc:88.33 | val loss:0.734 acc:73.20\r\n",
      "Epoch:0009 train loss:0.491 acc:90.00 | val loss:0.644 acc:78.00\r\n",
      "Epoch:0010 train loss:0.396 acc:90.00 | val loss:0.612 acc:77.20\r\n",
      "Epoch:0011 train loss:0.403 acc:93.33 | val loss:0.641 acc:77.20\r\n",
      "Epoch:0012 train loss:0.363 acc:88.33 | val loss:0.642 acc:76.40\r\n",
      "Epoch:0013 train loss:0.391 acc:86.67 | val loss:0.582 acc:80.00\r\n",
      "Epoch:0014 train loss:0.401 acc:86.67 | val loss:0.563 acc:80.60\r\n",
      "Epoch:0015 train loss:0.399 acc:90.00 | val loss:0.610 acc:77.80\r\n",
      "Epoch:0016 train loss:0.327 acc:95.00 | val loss:0.560 acc:81.00\r\n",
      "Epoch:0017 train loss:0.334 acc:93.33 | val loss:0.551 acc:81.00\r\n",
      "Epoch:0018 train loss:0.260 acc:95.00 | val loss:0.579 acc:78.20\r\n",
      "Epoch:0019 train loss:0.372 acc:85.00 | val loss:0.570 acc:80.40\r\n",
      "Epoch:0020 train loss:0.285 acc:95.00 | val loss:0.553 acc:81.20\r\n",
      "Epoch:0021 train loss:0.261 acc:93.33 | val loss:0.556 acc:81.00\r\n",
      "Epoch:0022 train loss:0.240 acc:90.00 | val loss:0.612 acc:77.60\r\n",
      "Epoch:0023 train loss:0.219 acc:95.00 | val loss:0.576 acc:79.20\r\n",
      "Epoch:0024 train loss:0.270 acc:88.33 | val loss:0.538 acc:79.20\r\n",
      "Epoch:0025 train loss:0.224 acc:95.00 | val loss:0.547 acc:80.00\r\n",
      "Epoch:0026 train loss:0.235 acc:95.00 | val loss:0.586 acc:77.40\r\n",
      "Epoch:0027 train loss:0.198 acc:96.67 | val loss:0.549 acc:78.80\r\n",
      "Epoch:0028 train loss:0.286 acc:90.00 | val loss:0.650 acc:75.40\r\n",
      "Epoch:0029 train loss:0.224 acc:91.67 | val loss:0.601 acc:77.80\r\n",
      "Epoch:0030 train loss:0.223 acc:91.67 | val loss:0.574 acc:77.40\r\n",
      "Epoch:0031 train loss:0.150 acc:98.33 | val loss:0.561 acc:78.00\r\n",
      "Epoch:0032 train loss:0.185 acc:95.00 | val loss:0.579 acc:78.00\r\n",
      "Epoch:0033 train loss:0.140 acc:98.33 | val loss:0.590 acc:77.80\r\n",
      "Epoch:0034 train loss:0.215 acc:96.67 | val loss:0.542 acc:82.00\r\n",
      "Epoch:0035 train loss:0.243 acc:91.67 | val loss:0.530 acc:79.80\r\n",
      "Epoch:0036 train loss:0.227 acc:95.00 | val loss:0.552 acc:80.40\r\n",
      "Epoch:0037 train loss:0.230 acc:95.00 | val loss:0.531 acc:81.00\r\n",
      "Epoch:0038 train loss:0.203 acc:95.00 | val loss:0.513 acc:81.80\r\n",
      "Epoch:0039 train loss:0.206 acc:95.00 | val loss:0.673 acc:74.60\r\n",
      "Epoch:0040 train loss:0.202 acc:95.00 | val loss:0.533 acc:80.80\r\n",
      "Epoch:0041 train loss:0.244 acc:93.33 | val loss:0.594 acc:73.20\r\n",
      "Epoch:0042 train loss:0.247 acc:88.33 | val loss:0.634 acc:76.60\r\n",
      "Epoch:0043 train loss:0.212 acc:93.33 | val loss:0.659 acc:74.60\r\n",
      "Epoch:0044 train loss:0.250 acc:91.67 | val loss:0.586 acc:74.40\r\n",
      "Epoch:0045 train loss:0.232 acc:93.33 | val loss:0.541 acc:78.60\r\n",
      "Epoch:0046 train loss:0.233 acc:96.67 | val loss:0.639 acc:76.40\r\n",
      "Epoch:0047 train loss:0.147 acc:98.33 | val loss:0.717 acc:75.00\r\n",
      "Epoch:0048 train loss:0.194 acc:93.33 | val loss:0.576 acc:78.80\r\n",
      "Epoch:0049 train loss:0.158 acc:96.67 | val loss:0.581 acc:77.80\r\n",
      "Epoch:0050 train loss:0.201 acc:95.00 | val loss:0.561 acc:79.00\r\n",
      "Epoch:0051 train loss:0.149 acc:96.67 | val loss:0.579 acc:78.40\r\n",
      "Epoch:0052 train loss:0.185 acc:95.00 | val loss:0.630 acc:77.00\r\n",
      "Epoch:0053 train loss:0.207 acc:90.00 | val loss:0.606 acc:77.80\r\n",
      "Epoch:0054 train loss:0.175 acc:98.33 | val loss:0.546 acc:78.00\r\n",
      "Epoch:0055 train loss:0.136 acc:98.33 | val loss:0.527 acc:79.60\r\n",
      "Epoch:0056 train loss:0.133 acc:98.33 | val loss:0.560 acc:78.20\r\n",
      "Epoch:0057 train loss:0.181 acc:95.00 | val loss:0.659 acc:74.60\r\n",
      "Epoch:0058 train loss:0.199 acc:95.00 | val loss:0.524 acc:80.60\r\n",
      "Epoch:0059 train loss:0.167 acc:93.33 | val loss:0.509 acc:80.00\r\n",
      "Epoch:0060 train loss:0.118 acc:98.33 | val loss:0.506 acc:80.00\r\n",
      "Epoch:0061 train loss:0.231 acc:91.67 | val loss:0.673 acc:75.60\r\n",
      "Epoch:0062 train loss:0.218 acc:91.67 | val loss:0.540 acc:79.80\r\n",
      "Epoch:0063 train loss:0.173 acc:96.67 | val loss:0.506 acc:82.60\r\n",
      "Epoch:0064 train loss:0.161 acc:95.00 | val loss:0.559 acc:79.60\r\n",
      "Epoch:0065 train loss:0.169 acc:96.67 | val loss:0.498 acc:82.20\r\n",
      "Epoch:0066 train loss:0.150 acc:98.33 | val loss:0.529 acc:80.80\r\n",
      "Epoch:0067 train loss:0.099 acc:98.33 | val loss:0.520 acc:81.00\r\n",
      "Epoch:0068 train loss:0.160 acc:95.00 | val loss:0.536 acc:81.40\r\n",
      "Epoch:0069 train loss:0.146 acc:96.67 | val loss:0.632 acc:77.60\r\n",
      "Epoch:0070 train loss:0.244 acc:90.00 | val loss:0.508 acc:80.40\r\n",
      "Epoch:0071 train loss:0.183 acc:93.33 | val loss:0.626 acc:73.20\r\n",
      "Epoch:0072 train loss:0.182 acc:95.00 | val loss:0.524 acc:81.60\r\n",
      "Epoch:0073 train loss:0.150 acc:96.67 | val loss:0.660 acc:76.80\r\n",
      "Epoch:0074 train loss:0.263 acc:88.33 | val loss:0.542 acc:80.00\r\n",
      "Epoch:0075 train loss:0.154 acc:96.67 | val loss:0.545 acc:78.60\r\n",
      "Epoch:0076 train loss:0.195 acc:96.67 | val loss:0.581 acc:78.00\r\n",
      "Epoch:0077 train loss:0.201 acc:93.33 | val loss:0.594 acc:77.40\r\n",
      "Epoch:0078 train loss:0.135 acc:100.00 | val loss:0.533 acc:80.40\r\n",
      "Epoch:0079 train loss:0.086 acc:98.33 | val loss:0.536 acc:79.20\r\n",
      "Epoch:0080 train loss:0.206 acc:95.00 | val loss:0.574 acc:78.00\r\n",
      "Epoch:0081 train loss:0.203 acc:93.33 | val loss:0.602 acc:77.00\r\n",
      "Epoch:0082 train loss:0.206 acc:93.33 | val loss:0.539 acc:80.80\r\n",
      "Epoch:0083 train loss:0.144 acc:98.33 | val loss:0.546 acc:79.00\r\n",
      "Epoch:0084 train loss:0.160 acc:98.33 | val loss:0.555 acc:79.20\r\n",
      "Epoch:0085 train loss:0.137 acc:96.67 | val loss:0.664 acc:74.60\r\n",
      "Epoch:0086 train loss:0.209 acc:96.67 | val loss:0.518 acc:81.20\r\n",
      "Epoch:0087 train loss:0.140 acc:98.33 | val loss:0.516 acc:80.40\r\n",
      "Epoch:0088 train loss:0.213 acc:93.33 | val loss:0.567 acc:77.40\r\n",
      "Epoch:0089 train loss:0.142 acc:96.67 | val loss:0.571 acc:77.80\r\n",
      "Epoch:0090 train loss:0.155 acc:98.33 | val loss:0.549 acc:79.20\r\n",
      "Epoch:0091 train loss:0.105 acc:96.67 | val loss:0.514 acc:81.20\r\n",
      "Epoch:0092 train loss:0.158 acc:93.33 | val loss:0.557 acc:80.20\r\n",
      "Epoch:0093 train loss:0.123 acc:100.00 | val loss:0.569 acc:78.60\r\n",
      "Epoch:0094 train loss:0.174 acc:96.67 | val loss:0.741 acc:73.60\r\n",
      "Epoch:0095 train loss:0.188 acc:93.33 | val loss:0.521 acc:79.40\r\n",
      "Epoch:0096 train loss:0.175 acc:96.67 | val loss:0.611 acc:73.80\r\n",
      "Epoch:0097 train loss:0.250 acc:90.00 | val loss:0.630 acc:76.60\r\n",
      "Epoch:0098 train loss:0.134 acc:98.33 | val loss:0.792 acc:73.00\r\n",
      "Epoch:0099 train loss:0.196 acc:90.00 | val loss:0.548 acc:79.80\r\n",
      "Epoch:0100 train loss:0.128 acc:98.33 | val loss:0.607 acc:74.80\r\n",
      "Epoch:0101 train loss:0.235 acc:93.33 | val loss:0.694 acc:70.00\r\n",
      "Epoch:0102 train loss:0.201 acc:93.33 | val loss:0.565 acc:80.40\r\n",
      "Epoch:0103 train loss:0.093 acc:100.00 | val loss:0.682 acc:76.20\r\n",
      "Epoch:0104 train loss:0.177 acc:93.33 | val loss:0.600 acc:78.00\r\n",
      "Epoch:0105 train loss:0.133 acc:95.00 | val loss:0.523 acc:80.60\r\n",
      "Epoch:0106 train loss:0.116 acc:96.67 | val loss:0.538 acc:80.00\r\n",
      "Epoch:0107 train loss:0.129 acc:95.00 | val loss:0.540 acc:80.80\r\n",
      "Epoch:0108 train loss:0.123 acc:98.33 | val loss:0.629 acc:76.80\r\n",
      "Epoch:0109 train loss:0.187 acc:95.00 | val loss:0.513 acc:82.00\r\n",
      "Epoch:0110 train loss:0.149 acc:95.00 | val loss:0.541 acc:79.20\r\n",
      "Epoch:0111 train loss:0.196 acc:96.67 | val loss:0.525 acc:80.60\r\n",
      "Epoch:0112 train loss:0.122 acc:100.00 | val loss:0.660 acc:75.80\r\n",
      "Epoch:0113 train loss:0.290 acc:93.33 | val loss:0.561 acc:78.00\r\n",
      "Epoch:0114 train loss:0.235 acc:95.00 | val loss:0.526 acc:79.80\r\n",
      "Epoch:0115 train loss:0.132 acc:96.67 | val loss:0.575 acc:77.20\r\n",
      "Epoch:0116 train loss:0.168 acc:95.00 | val loss:0.545 acc:80.60\r\n",
      "Epoch:0117 train loss:0.208 acc:95.00 | val loss:0.628 acc:76.80\r\n",
      "Epoch:0118 train loss:0.135 acc:100.00 | val loss:0.512 acc:80.00\r\n",
      "Epoch:0119 train loss:0.130 acc:98.33 | val loss:0.537 acc:79.80\r\n",
      "Epoch:0120 train loss:0.205 acc:96.67 | val loss:0.570 acc:78.40\r\n",
      "Epoch:0121 train loss:0.150 acc:98.33 | val loss:0.565 acc:79.60\r\n",
      "Epoch:0122 train loss:0.158 acc:96.67 | val loss:0.526 acc:80.40\r\n",
      "Epoch:0123 train loss:0.167 acc:96.67 | val loss:0.558 acc:79.20\r\n",
      "Epoch:0124 train loss:0.215 acc:95.00 | val loss:0.703 acc:76.40\r\n",
      "Epoch:0125 train loss:0.158 acc:96.67 | val loss:0.627 acc:78.00\r\n",
      "Epoch:0126 train loss:0.167 acc:96.67 | val loss:0.537 acc:80.00\r\n",
      "Epoch:0127 train loss:0.166 acc:93.33 | val loss:0.524 acc:80.60\r\n",
      "Epoch:0128 train loss:0.141 acc:96.67 | val loss:0.653 acc:77.60\r\n",
      "Epoch:0129 train loss:0.160 acc:96.67 | val loss:0.577 acc:80.20\r\n",
      "Epoch:0130 train loss:0.133 acc:100.00 | val loss:0.545 acc:80.00\r\n",
      "Epoch:0131 train loss:0.194 acc:93.33 | val loss:0.560 acc:79.80\r\n",
      "Epoch:0132 train loss:0.124 acc:98.33 | val loss:0.606 acc:79.80\r\n",
      "Epoch:0133 train loss:0.092 acc:98.33 | val loss:0.735 acc:75.80\r\n",
      "Epoch:0134 train loss:0.222 acc:91.67 | val loss:0.562 acc:79.00\r\n",
      "Epoch:0135 train loss:0.139 acc:98.33 | val loss:0.664 acc:70.80\r\n",
      "Epoch:0136 train loss:0.259 acc:90.00 | val loss:0.567 acc:79.60\r\n",
      "Epoch:0137 train loss:0.129 acc:100.00 | val loss:0.711 acc:75.80\r\n",
      "Epoch:0138 train loss:0.172 acc:95.00 | val loss:0.597 acc:78.00\r\n",
      "Epoch:0139 train loss:0.148 acc:98.33 | val loss:0.565 acc:78.60\r\n",
      "Epoch:0140 train loss:0.151 acc:96.67 | val loss:0.582 acc:77.00\r\n",
      "Epoch:0141 train loss:0.216 acc:93.33 | val loss:0.619 acc:77.80\r\n",
      "Epoch:0142 train loss:0.125 acc:96.67 | val loss:0.909 acc:70.00\r\n",
      "Epoch:0143 train loss:0.226 acc:91.67 | val loss:0.596 acc:78.00\r\n",
      "Epoch:0144 train loss:0.148 acc:93.33 | val loss:0.651 acc:70.80\r\n",
      "Epoch:0145 train loss:0.195 acc:95.00 | val loss:0.549 acc:78.40\r\n",
      "Epoch:0146 train loss:0.149 acc:96.67 | val loss:0.596 acc:78.00\r\n",
      "Epoch:0147 train loss:0.170 acc:95.00 | val loss:0.857 acc:71.80\r\n",
      "Epoch:0148 train loss:0.282 acc:90.00 | val loss:0.577 acc:80.00\r\n",
      "Epoch:0149 train loss:0.192 acc:93.33 | val loss:0.657 acc:70.20\r\n",
      "Epoch:0150 train loss:0.203 acc:95.00 | val loss:0.529 acc:80.20\r\n",
      "Epoch:0151 train loss:0.180 acc:96.67 | val loss:0.647 acc:76.60\r\n",
      "Epoch:0152 train loss:0.136 acc:96.67 | val loss:0.714 acc:74.80\r\n",
      "Epoch:0153 train loss:0.255 acc:91.67 | val loss:0.554 acc:80.20\r\n",
      "Epoch:0154 train loss:0.206 acc:95.00 | val loss:0.560 acc:78.80\r\n",
      "Epoch:0155 train loss:0.319 acc:90.00 | val loss:0.571 acc:79.20\r\n",
      "Epoch:0156 train loss:0.136 acc:98.33 | val loss:0.679 acc:75.40\r\n",
      "Load 65th epoch\r\n",
      "Test acc.:81.3\r\n"
     ]
    }
   ],
   "source": [
    "best_num_layers = int(a[0])\n",
    "best_optim = int(a[1])\n",
    "best_al = int(a[2])\n",
    "best_act = int(a[3])\n",
    "best_earlystop = int(a[4])\n",
    "best_epoch1 = int(a[5])\n",
    "best_hidden_dim = int(a[6])\n",
    "best_variant = a[7]\n",
    "\n",
    "best_alpha = a[8]\n",
    "best_lamda = a[9]\n",
    "best_dropout = a[10]\n",
    "best_lr = a[11]\n",
    "best_weight_decay_1 = a[12]\n",
    "best_weight_decay_2 = a[13]\n",
    "start_time = time.time()\n",
    "best_test_acc_list=[]\n",
    "for k in range(repeat):\n",
    "    if best_al==0 and best_variant==0:\n",
    "        !python -u trainshow.py --data pubmed --layer {best_num_layers} --hidden {best_hidden_dim} --dropout {best_dropout} --wd1 {best_weight_decay_1} --wd2 {best_weight_decay_2} --lr {best_lr} --op {best_optim}  --act_fn {best_act} --epochs  {best_epoch1} --patience {best_earlystop} --test  \n",
    "    elif best_al==1 and best_variant==0:\n",
    "        !python -u trainshow.py --data pubmed --layer {best_num_layers} --hidden {best_hidden_dim} --dropout {best_dropout} --wd1 {best_weight_decay_1} --wd2 {best_weight_decay_2} --lr {best_lr} --op {best_optim}  --act_fn {best_act} --epochs  {best_epoch1} --patience {best_earlystop} --lamda {best_lamda} --alpha {best_alpha} --test  \n",
    "    elif best_al==0 and best_variant==1:\n",
    "        !python -u trainshow.py --data pubmed --layer {best_num_layers} --hidden {best_hidden_dim} --dropout {best_dropout} --wd1 {best_weight_decay_1} --wd2 {best_weight_decay_2} --lr {best_lr} --op {best_optim}  --act_fn {best_act} --epochs  {best_epoch1} --patience {best_earlystop} --test --variant  \n",
    "    else:\n",
    "        !python -u trainshow.py --data pubmed --layer {best_num_layers} --hidden {best_hidden_dim} --dropout {best_dropout} --wd1 {best_weight_decay_1} --wd2 {best_weight_decay_2} --lr {best_lr} --op {best_optim}  --act_fn {best_act} --epochs  {best_epoch1} --patience {best_earlystop} --lamda {best_lamda} --alpha {best_alpha} --test --variant  \n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "237fd080",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T11:59:26.079393Z",
     "iopub.status.busy": "2024-04-21T11:59:26.078616Z",
     "iopub.status.idle": "2024-04-21T11:59:26.086695Z",
     "shell.execute_reply": "2024-04-21T11:59:26.085867Z"
    },
    "papermill": {
     "duration": 0.170786,
     "end_time": "2024-04-21T11:59:26.089118",
     "exception": false,
     "start_time": "2024-04-21T11:59:25.918332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pubmed\n",
      "best_num_layers: 28\n",
      "best_optim: 0\n",
      "best_al: 0\n",
      "best_act: 1\n",
      "best_earlystop: 91\n",
      "best_epoch1: 576\n",
      "best_hidden_dim: 291\n",
      "best_variant: 0\n",
      "---------\n",
      "best_alpha: 0.4916403085983449\n",
      "best_lamda: 0.13254427692885368\n",
      "best_dropout: 0.5552673229693162\n",
      "best_lr: 0.03943938762434759\n",
      "best_weight_decay_1: 0.003367028684054662\n",
      "best_weight_decay_2: 0.0005004352979650606\n",
      "---------\n",
      ": 60.562479972839355\n"
     ]
    }
   ],
   "source": [
    "print(\"pubmed\")\n",
    "print(f\"best_num_layers: {best_num_layers}\")\n",
    "print(f\"best_optim: {best_optim}\")\n",
    "print(f\"best_al: {best_al}\")\n",
    "print(f\"best_act: {best_act}\")\n",
    "print(f\"best_earlystop: {best_earlystop}\")\n",
    "print(f\"best_epoch1: {best_epoch1}\")\n",
    "print(f\"best_hidden_dim: {best_hidden_dim}\")\n",
    "print(f\"best_variant: {best_variant}\")\n",
    "print(\"---------\")\n",
    "print(f\"best_alpha: {best_alpha}\")\n",
    "print(f\"best_lamda: {best_lamda}\")\n",
    "print(f\"best_dropout: {best_dropout}\")\n",
    "print(f\"best_lr: {best_lr}\")\n",
    "print(f\"best_weight_decay_1: {best_weight_decay_1}\")\n",
    "print(f\"best_weight_decay_2: {best_weight_decay_2}\")\n",
    "print(\"---------\")\n",
    "import numpy as np\n",
    "print(\":\", (end_time-start_time)/repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b3196",
   "metadata": {
    "papermill": {
     "duration": 0.157293,
     "end_time": "2024-04-21T11:59:26.404001",
     "exception": false,
     "start_time": "2024-04-21T11:59:26.246708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "for chale"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4019076,
     "sourceId": 6992470,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3992311,
     "sourceId": 7047491,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4437867,
     "sourceId": 7619250,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 256.975508,
   "end_time": "2024-04-21T11:59:26.780461",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-21T11:55:09.804953",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
